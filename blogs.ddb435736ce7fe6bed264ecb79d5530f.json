{"title":"Stories by Jason on Medium","description":"Stories by Jason on Medium","link":"https://medium.com/@xuzhusheng?source=rss-41bd992616fb------2","image":"https://cdn-images-1.medium.com/fit/c/150/150/1*WvSeAJwGVusKLkQSyDG6qw.jpeg","category":[],"items":[{"id":"https://medium.com/p/20d849be6d5d","title":"Covariance and Correlation","link":"https://python.plainenglish.io/covariance-and-correlation-20d849be6d5d?source=rss-41bd992616fb------2","author":"Jason","published":1714644088000,"created":1714644088000,"category":["statistics","data-analysis","data-science","machine-learning","python"],"content":"<h4>Machine Learning</h4><h4>Revealing Hidden Connections between Variables in YourÂ Dataset</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*DxKN3PxZNPfOQCN_\" /><figcaption>Photo by <a href=\"https://unsplash.com/@kommumikation?utm_source=medium&amp;utm_medium=referral\">Mika Baumeister</a> onÂ <a href=\"https://unsplash.com?utm_source=medium&amp;utm_medium=referral\">Unsplash</a></figcaption></figure><p>Covariance and correlation are two of the most fundamental statistics and probability theory concepts. Both covariance and correlation have high utility in machine learning and data analysis.</p><p>In this article, we are going to discover the concepts of covariance and correlation. We will cover this topic with below sections:</p><ul><li><em>Covariance<br>- What is covariance<br>- Calculating covariance withÂ NumPy</em></li><li><em>Correlation<br>- Pearson Correlation Coefficient<br>- Calculating Pearson correlation coefficient withÂ NumPy</em></li><li><em>Covariance VS. Correlation</em></li></ul><p>Letâ€™s start.</p><h3><strong>Covariance</strong></h3><p>Covariance is a measure of the joint variability of two random variables. It describes how the two variables change together. The sign of the covariance shows the tendency in the linear relationship between the variables.</p><ul><li><em>Positive covariance: Both variables tend to move in the same direction.</em></li><li><em>Negative covariance: Two variables tend to move in inverse directions.</em></li><li><em>Zero covarianceï¼šTwo variables are completely independent.</em></li></ul><h4><strong>Corvarance Formula</strong></h4><p>Covariance is calculated as expected value or average of the product of the differences of each random variable from their expected values. Given by two random variables X and Y, the covariance is denoted by cov(X,Y). The formula is givenÂ below:</p><p><strong>Population covariance</strong></p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/642/1*Iaq8ggKmBs3QElbVGTH10Q.png\" /></figure><p>where:</p><ul><li><em>cov is the covariance</em></li><li><em>x_i and y_i is the ith value of X orÂ Y</em></li><li><em>x-bar and y-bar is the mean of X orÂ Y</em></li><li><em>N is the number of x and y in the population</em></li></ul><p><strong>Sample covariance</strong></p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/642/1*kXERbK1EGsKKYKby8nuiRg.png\" /></figure><p>where:</p><ul><li><em>n is sample size. nâ€Šâ€”â€Š1 is degrees of freedom and the use of the term n âˆ’ 1 is called Besselâ€™s correction</em></li></ul><h4><strong>Calculating Covariance withÂ NumPy</strong></h4><p>According to the formula, covariance can be calculated asÂ below:</p><pre>import numpy as np<br><br>np.random.seed(0)<br><br>x, y = np.random.randint(10, size = (2,7))<br>print(x) # [5 0 3 3 7 9 3]<br>print(y) # [5 2 4 7 6 8 8]<br><br>def covariance(x, y, *, bias = False):<br>    num = len(x) if bias else len(x) - 1<br>    return ((x - x.mean()) * (y - y.mean())).sum() / num<br><br># Unbiased sample covariance<br>print(covariance(x, y)) # 4.095238095238096<br><br># Population covariance or biased sample covariance<br>print(covariance(x, y, bias=True)) # 3.510204081632654</pre><h3><strong>Correlation</strong></h3><p>A correlation reflects the strength and/or direction of the relationship between two (or more) variables. It usually refers to the degree to which a pair of variables are linearly related. The direction of a correlation can be positive, negative orÂ zero:</p><ul><li><em>Positive correlation: Both variables change in the same direction (i.e., one variable increases as the other increases. Or, one decreases as the other decreases).</em></li><li><em>Negative correlation: The variables change in opposite directions (i.e., one variable increases as the other decreases, and viceÂ versa)</em></li><li><em>Zero correlation: There is no relationship between the variables.</em></li></ul><p>There are several correlation coefficients measuring the degree of correlation. The most common one is the Pearson correlation coefficient.</p><h4><strong>Pearson Correlation Coefficient (PCC)</strong></h4><p>Pearson correlation coefficient is a correlation coefficient that measures linear correlation between two sets of data. It is the ratio between the covariance of two variables and the product of their standard deviations. Thus, it is essentially a normalized measurement of the covariance, the result always has a value between âˆ’1 andÂ 1.</p><p>Pearson correlation coefficient is commonly represented by the r. The formulaÂ is:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/642/1*E9OEPW9JtqphvQ6UAw71UQ.png\" /></figure><p>where</p><ul><li><em>cov is the covariance</em></li><li><em>S_x and S_y is the standard deviation</em></li></ul><p>The value of r ranges between -1 and 1. We Interpret r asÂ below:</p><iframe src=\"\" width=\"0\" height=\"0\" frameborder=\"0\" scrolling=\"no\"><a href=\"https://medium.com/media/e3ccf1ac78aec83aecebf2968a8b0604/href\">https://medium.com/media/e3ccf1ac78aec83aecebf2968a8b0604/href</a></iframe><h4><strong>Calculating pearson correlation coefficient withÂ NumPy</strong></h4><p>According to the formula, pearson correlation coefficient can be calculated asÂ below:</p><pre>def correlation_coefficient(x, y):<br>    return covariance(x, y) / (np.std(x, ddof=1) * np.std(y, ddof=1))<br><br>print(correlation_coefficient(x, y))    # 0.6196679516337091</pre><h3><strong>Corvarance VS. Correlation</strong></h3><p>Covariance reveals how two variables change together while correlation determines how closely two variables are related to eachÂ other.</p><ul><li><em>Both covariance and correlation measure the relationship and the dependency between two variables.</em></li><li><em>Covariance indicates the direction of the linear relationship between variables.</em></li><li><em>Correlation measures both the strength and direction of the linear relationship between two variables.</em></li><li><em>Correlation values are standardized.</em></li><li><em>Covariance values are not standardized.</em></li></ul><h3>Jason ğŸš€</h3><p><em>Thank you for reading until the end. Before youÂ go:</em></p><p><em>ğŸ‘ Please </em><strong><em>clap</em></strong><em> and </em><strong><em>follow</em></strong><em>Â me.</em></p><p><em>ğŸ“¬ </em><a href=\"https://medium.com/@xuzhusheng/subscribe\"><em>Subscribe</em></a><em> to my Medium newsletter for emailÂ updates!</em></p><p><em>â˜• or just </em><a href=\"https://www.buymeacoffee.com/jason.xu\"><em>buy me aÂ coffee</em></a><em>.</em></p><h3>In Plain EnglishÂ ğŸš€</h3><p><em>Thank you for being a part of the </em><a href=\"https://plainenglish.io\"><strong><em>In Plain English</em></strong></a><em> community! Before youÂ go:</em></p><ul><li>Be sure to <strong>clap</strong> and <strong>follow</strong> the writerÂ ï¸ğŸ‘<strong>ï¸ï¸</strong></li><li>Follow us: <a href=\"https://twitter.com/inPlainEngHQ\"><strong>X</strong></a><strong> | </strong><a href=\"https://www.linkedin.com/company/inplainenglish/\"><strong>LinkedIn</strong></a><strong> | </strong><a href=\"https://www.youtube.com/channel/UCtipWUghju290NWcn8jhyAw\"><strong>YouTube</strong></a><strong> | </strong><a href=\"https://discord.gg/in-plain-english-709094664682340443\"><strong>Discord</strong></a><strong> | </strong><a href=\"https://newsletter.plainenglish.io/\"><strong>Newsletter</strong></a></li><li>Visit our other platforms: <a href=\"https://stackademic.com/\"><strong>Stackademic</strong></a><strong> | </strong><a href=\"https://cofeed.app/\"><strong>CoFeed</strong></a><strong> | </strong><a href=\"https://venturemagazine.net/\"><strong>Venture</strong></a><strong> |Â </strong><a href=\"https://blog.cubed.run\"><strong>Cubed</strong></a></li><li>More content at <a href=\"https://plainenglish.io\"><strong>PlainEnglish.io</strong></a></li></ul><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=20d849be6d5d\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://python.plainenglish.io/covariance-and-correlation-20d849be6d5d\">Covariance and Correlation</a> was originally published in <a href=\"https://python.plainenglish.io\">Python in Plain English</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>","enclosures":[],"content_encoded":"<h4>Machine Learning</h4><h4>Revealing Hidden Connections between Variables in YourÂ Dataset</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*DxKN3PxZNPfOQCN_\" /><figcaption>Photo by <a href=\"https://unsplash.com/@kommumikation?utm_source=medium&amp;utm_medium=referral\">Mika Baumeister</a> onÂ <a href=\"https://unsplash.com?utm_source=medium&amp;utm_medium=referral\">Unsplash</a></figcaption></figure><p>Covariance and correlation are two of the most fundamental statistics and probability theory concepts. Both covariance and correlation have high utility in machine learning and data analysis.</p><p>In this article, we are going to discover the concepts of covariance and correlation. We will cover this topic with below sections:</p><ul><li><em>Covariance<br>- What is covariance<br>- Calculating covariance withÂ NumPy</em></li><li><em>Correlation<br>- Pearson Correlation Coefficient<br>- Calculating Pearson correlation coefficient withÂ NumPy</em></li><li><em>Covariance VS. Correlation</em></li></ul><p>Letâ€™s start.</p><h3><strong>Covariance</strong></h3><p>Covariance is a measure of the joint variability of two random variables. It describes how the two variables change together. The sign of the covariance shows the tendency in the linear relationship between the variables.</p><ul><li><em>Positive covariance: Both variables tend to move in the same direction.</em></li><li><em>Negative covariance: Two variables tend to move in inverse directions.</em></li><li><em>Zero covarianceï¼šTwo variables are completely independent.</em></li></ul><h4><strong>Corvarance Formula</strong></h4><p>Covariance is calculated as expected value or average of the product of the differences of each random variable from their expected values. Given by two random variables X and Y, the covariance is denoted by cov(X,Y). The formula is givenÂ below:</p><p><strong>Population covariance</strong></p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/642/1*Iaq8ggKmBs3QElbVGTH10Q.png\" /></figure><p>where:</p><ul><li><em>cov is the covariance</em></li><li><em>x_i and y_i is the ith value of X orÂ Y</em></li><li><em>x-bar and y-bar is the mean of X orÂ Y</em></li><li><em>N is the number of x and y in the population</em></li></ul><p><strong>Sample covariance</strong></p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/642/1*kXERbK1EGsKKYKby8nuiRg.png\" /></figure><p>where:</p><ul><li><em>n is sample size. nâ€Šâ€”â€Š1 is degrees of freedom and the use of the term n âˆ’ 1 is called Besselâ€™s correction</em></li></ul><h4><strong>Calculating Covariance withÂ NumPy</strong></h4><p>According to the formula, covariance can be calculated asÂ below:</p><pre>import numpy as np<br><br>np.random.seed(0)<br><br>x, y = np.random.randint(10, size = (2,7))<br>print(x) # [5 0 3 3 7 9 3]<br>print(y) # [5 2 4 7 6 8 8]<br><br>def covariance(x, y, *, bias = False):<br>    num = len(x) if bias else len(x) - 1<br>    return ((x - x.mean()) * (y - y.mean())).sum() / num<br><br># Unbiased sample covariance<br>print(covariance(x, y)) # 4.095238095238096<br><br># Population covariance or biased sample covariance<br>print(covariance(x, y, bias=True)) # 3.510204081632654</pre><h3><strong>Correlation</strong></h3><p>A correlation reflects the strength and/or direction of the relationship between two (or more) variables. It usually refers to the degree to which a pair of variables are linearly related. The direction of a correlation can be positive, negative orÂ zero:</p><ul><li><em>Positive correlation: Both variables change in the same direction (i.e., one variable increases as the other increases. Or, one decreases as the other decreases).</em></li><li><em>Negative correlation: The variables change in opposite directions (i.e., one variable increases as the other decreases, and viceÂ versa)</em></li><li><em>Zero correlation: There is no relationship between the variables.</em></li></ul><p>There are several correlation coefficients measuring the degree of correlation. The most common one is the Pearson correlation coefficient.</p><h4><strong>Pearson Correlation Coefficient (PCC)</strong></h4><p>Pearson correlation coefficient is a correlation coefficient that measures linear correlation between two sets of data. It is the ratio between the covariance of two variables and the product of their standard deviations. Thus, it is essentially a normalized measurement of the covariance, the result always has a value between âˆ’1 andÂ 1.</p><p>Pearson correlation coefficient is commonly represented by the r. The formulaÂ is:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/642/1*E9OEPW9JtqphvQ6UAw71UQ.png\" /></figure><p>where</p><ul><li><em>cov is the covariance</em></li><li><em>S_x and S_y is the standard deviation</em></li></ul><p>The value of r ranges between -1 and 1. We Interpret r asÂ below:</p><iframe src=\"\" width=\"0\" height=\"0\" frameborder=\"0\" scrolling=\"no\"><a href=\"https://medium.com/media/e3ccf1ac78aec83aecebf2968a8b0604/href\">https://medium.com/media/e3ccf1ac78aec83aecebf2968a8b0604/href</a></iframe><h4><strong>Calculating pearson correlation coefficient withÂ NumPy</strong></h4><p>According to the formula, pearson correlation coefficient can be calculated asÂ below:</p><pre>def correlation_coefficient(x, y):<br>    return covariance(x, y) / (np.std(x, ddof=1) * np.std(y, ddof=1))<br><br>print(correlation_coefficient(x, y))    # 0.6196679516337091</pre><h3><strong>Corvarance VS. Correlation</strong></h3><p>Covariance reveals how two variables change together while correlation determines how closely two variables are related to eachÂ other.</p><ul><li><em>Both covariance and correlation measure the relationship and the dependency between two variables.</em></li><li><em>Covariance indicates the direction of the linear relationship between variables.</em></li><li><em>Correlation measures both the strength and direction of the linear relationship between two variables.</em></li><li><em>Correlation values are standardized.</em></li><li><em>Covariance values are not standardized.</em></li></ul><h3>Jason ğŸš€</h3><p><em>Thank you for reading until the end. Before youÂ go:</em></p><p><em>ğŸ‘ Please </em><strong><em>clap</em></strong><em> and </em><strong><em>follow</em></strong><em>Â me.</em></p><p><em>ğŸ“¬ </em><a href=\"https://medium.com/@xuzhusheng/subscribe\"><em>Subscribe</em></a><em> to my Medium newsletter for emailÂ updates!</em></p><p><em>â˜• or just </em><a href=\"https://www.buymeacoffee.com/jason.xu\"><em>buy me aÂ coffee</em></a><em>.</em></p><h3>In Plain EnglishÂ ğŸš€</h3><p><em>Thank you for being a part of the </em><a href=\"https://plainenglish.io\"><strong><em>In Plain English</em></strong></a><em> community! Before youÂ go:</em></p><ul><li>Be sure to <strong>clap</strong> and <strong>follow</strong> the writerÂ ï¸ğŸ‘<strong>ï¸ï¸</strong></li><li>Follow us: <a href=\"https://twitter.com/inPlainEngHQ\"><strong>X</strong></a><strong> | </strong><a href=\"https://www.linkedin.com/company/inplainenglish/\"><strong>LinkedIn</strong></a><strong> | </strong><a href=\"https://www.youtube.com/channel/UCtipWUghju290NWcn8jhyAw\"><strong>YouTube</strong></a><strong> | </strong><a href=\"https://discord.gg/in-plain-english-709094664682340443\"><strong>Discord</strong></a><strong> | </strong><a href=\"https://newsletter.plainenglish.io/\"><strong>Newsletter</strong></a></li><li>Visit our other platforms: <a href=\"https://stackademic.com/\"><strong>Stackademic</strong></a><strong> | </strong><a href=\"https://cofeed.app/\"><strong>CoFeed</strong></a><strong> | </strong><a href=\"https://venturemagazine.net/\"><strong>Venture</strong></a><strong> |Â </strong><a href=\"https://blog.cubed.run\"><strong>Cubed</strong></a></li><li>More content at <a href=\"https://plainenglish.io\"><strong>PlainEnglish.io</strong></a></li></ul><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=20d849be6d5d\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://python.plainenglish.io/covariance-and-correlation-20d849be6d5d\">Covariance and Correlation</a> was originally published in <a href=\"https://python.plainenglish.io\">Python in Plain English</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>","media":{}},{"id":"https://medium.com/p/e8cd434645bf","title":"Variance and Standard Deviation","link":"https://python.plainenglish.io/calculates-variance-and-standard-deviation-with-python-e8cd434645bf?source=rss-41bd992616fb------2","author":"Jason","published":1713139330000,"created":1713139330000,"category":["data-analysis","data-science","machine-learning","statistics","python"],"content":"<h4>Machine Learning</h4><h4>What variance and standard deviation are and how to calculate them.</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*vSWCAp4xDrKWelgx\" /><figcaption>Photo by <a href=\"https://unsplash.com/@bash__profile?utm_source=medium&amp;utm_medium=referral\">Nicholas Cappello</a> onÂ <a href=\"https://unsplash.com?utm_source=medium&amp;utm_medium=referral\">Unsplash</a></figcaption></figure><p><strong>Variance</strong> and <strong>standard deviation</strong> and are two basic mathematical concepts. Both measure the variability of figures within a data set using the mean of a certain group of numbers. They are important to help determine volatility and the distribution ofÂ returns.</p><p>In this article, we are going to explore variance and standard deviation and how to calculate withÂ NumPy.</p><p>At the end of this article, we will comprehend:</p><ul><li><em>What the expected value or arthmetic mean is and how to calculate it</em></li><li><em>What the variance is and how to calculate it</em></li><li><em>What the standard diviation is and how to calcualte it</em></li></ul><p>Letâ€™s start with the most basic mean and expectedÂ value.</p><h3><strong>Arithmetic Mean and ExpectedÂ Value</strong></h3><h4><strong>Arithmetic Mean (SampleÂ Mean)</strong></h4><p>In mathematics and statistics, the arithmetic mean of a set of observed data is equal to the sum of the numerical values of each observation, divided by the total number of observations. The arithmetic mean calculated from observed sample is symbolized as x-bar. It is defined by theÂ formula:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/682/1*meyblNvsdxElBI90rBxs4w.png\" /></figure><h4><strong>Expected Value (Population Mean)</strong></h4><p>The expected value of a discrete random variable X, symbolized as E(X), is often referred to as the long-term mean, population mean, symbolized as Î¼ to differentiate the sample mean. The Expected Value difined by theÂ formula:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/682/1*SOWeJ7TWG3XTW8eIG2m8Mw.png\" /></figure><h4><strong>Calculating mean withÂ NumPy</strong></h4><p>We can use the `mean()` function in NumPy to calculate mean for vector and matrix. Letâ€™s see how to doÂ it:</p><pre>import numpy as np<br><br>np.random.seed(202404)<br><br><br>vector = np.random.randint(10, size = 7)<br>print(vector) # [2 1 1 6 5 5 0]<br><br># mean for vector<br>vector.mean()<br><br><br>matrix = np.random.randint(10, size=(3,5))<br>print(matrix)<br># [[0 6 9 8 9]<br>#  [1 2 0 8 1]<br>#  [5 1 5 8 7]]<br><br># column mean<br>print(matrix.mean(axis=0))  # [2.         3.         4.66666667 8.         5.66666667]<br><br># row mean<br>print(matrix.mean(axis=1))  # [6.4 2.4 5.2]<br><br># mean for all element<br>print(matrix.mean())    # 4.666666666666667</pre><h3><strong>Variance</strong></h3><p>In probability theory and statistics, variance is the expected value of the squared deviation from the mean of a random variable. Variance is a measure of dispersion, meaning it is a measure of how far a set of numbers is spread out from their averageÂ value.</p><h4><strong>Population Variance</strong></h4><p>The population variance of a finite population givenÂ by:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/682/1*Ant7t14LDv3mIPAtskzXGg.png\" /></figure><ul><li><em>ÏƒÂ² is population variance</em></li><li><em>x_i is observed value from the population</em></li><li><em>Î¼ is the mean of allÂ x</em></li><li><em>N is the number of x in the population</em></li></ul><h4><strong>Sample Variance</strong></h4><p>In many practical situations, the true variance of a population is not known a priori and must be computed somehow. Variance is usually estimated from a sample drawn from a population. The unbiased estimate of population variance calculated from a sampleÂ is:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/682/1*KPwFtcmP3cwn0IYHVmJbxg.png\" /></figure><h4><strong>Calculating Variance withÂ NumPy</strong></h4><p>According to the formulas, we could calculate the variance asÂ below:</p><pre>import numpy as np<br><br>np.random.seed(202404)<br><br>data = np.random.randint(10, size = 7)<br>print(data) # [2 1 1 6 5 5 0]<br><br>def variance(data, *, bias = False):<br>    num = len(data) if bias else len(data) - 1<br>    return ((data - data.mean()) ** 2).sum() / num<br><br># unbiased sample variance<br>print(variance(data))   # 5.809523809523809<br><br># population variance or biased sample variance<br>print(variance(data, bias=True))    # 4.979591836734693</pre><p>In real pratice, We use the `var()` function in NumPy to calculate variance asÂ below:</p><pre>import numpy as np<br><br>np.random.seed(202404)<br><br>vector = np.random.randint(10, size = 7)<br>print(vector) # [2 1 1 6 5 5 0]<br><br># unbiased sample variance<br>print(vector.var(ddof=1)) # 5.809523809523809<br><br># population variance or biased sample variance<br>print(vector.var(ddof=0)) # 4.979591836734693<br><br>matrix = np.random.randint(10, size=(3, 5))<br>print(matrix)<br># [[0 6 9 8 9]<br>#  [1 2 0 8 1]<br>#  [5 1 5 8 7]]<br><br># unbiased sample variance<br># column variance<br>print(matrix.var(axis=0, ddof=1))   # [ 7.          7.         20.33333333  0.         17.33333333]<br># row variance<br>print(matrix.var(axis=1, ddof=1))   # [14.3 10.3  7.2]<br># variance for all elements<br>print(matrix.var( ddof=1))  # 12.095238095238098<br><br># population variance or biased sample variance<br># column variance<br>print(matrix.var(axis=0))   # [ 4.66666667  4.66666667 13.55555556  0.         11.55555556]<br># row variance<br>print(matrix.var(axis=1))   # [11.44  8.24  5.76]<br># variance for all elements<br>print(matrix.var()) # 11.288888888888891</pre><h3><strong>Standard Deviation</strong></h3><p>The standard deviation (SD) is a statistic that measures the dispersion of a dataset relative to its mean and is calculated as the square root of the variance. If the data points are further from the mean, there is a higher deviation within the data set. The more spread out the data, the higher the standard deviation. Like the variance, there are population standard deviation and sample standard deviation.</p><h4><strong>Population standard deviation</strong></h4><p>The formula of population standard deviation is:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/682/1*GXlVE8QqZBA4Af2f150ihg.png\" /></figure><h4><strong>Sample standard deviation</strong></h4><p>The sample of population standard deviation is:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/682/1*GXlVE8QqZBA4Af2f150ihg.png\" /></figure><h4><strong>Calculating Standard Deviation withÂ NumPy</strong></h4><p>We use the `std()` function in NumPy to calculate standard deviation like we calculate variance above. Letâ€™s see how to do it with examples:</p><pre>import numpy as np<br><br>np.random.seed(202404)<br><br>vector = np.random.randint(10, size = 7)<br>print(vector) # [2 1 1 6 5 5 0]<br><br># unbiased sample variance<br>print(vector.std(ddof=1)) # 2.410295378065479<br><br># population standard deviation or biased sample standard deviation<br>print(vector.std(ddof=0)) # 2.231499907401901<br><br>matrix = np.random.randint(10, size=(3, 5))<br>print(matrix)<br># [[0 6 9 8 9]<br>#  [1 2 0 8 1]<br>#  [5 1 5 8 7]]<br><br># unbiased sample standard deviation<br># column standard deviation<br>print(matrix.std(axis=0, ddof=1))   # [2.64575131 2.64575131 4.50924975 0.         4.163332  ]<br># row standard deviation<br>print(matrix.std(axis=1, ddof=1))   # [3.78153408 3.20936131 2.68328157]<br># standard deviation for all elements<br>print(matrix.std( ddof=1))  # 3.477820883144803<br><br># population standard deviation or biased sample standard deviation<br># column standard deviation<br>print(matrix.std(axis=0))   # [2.1602469  2.1602469  3.68178701 0.         3.39934634]<br># row standard deviation<br>print(matrix.std(axis=1))   # [3.38230691 2.87054002 2.4       ]<br># standard deviation for all elements<br>print(matrix.std()) # 3.3598941782277745</pre><h3><strong>Conclusion</strong></h3><p>The variance measures the average degree to which each point differs from the mean. While standard deviation is the square root of the variance. They are both important to help determine volatility and the distribution ofÂ returns.</p><p>In many practical situations, we usually estimate variance and standard deviation from a sample drawn from a population. When estimate variance and standard deviation from a sample, we use Besselâ€™s correction to adjust the divisor to n (sample size) -Â 1.</p><p>We can use the var() and std() functions to calculate variance and standard deviation withÂ NumPy</p><h3>Jason ğŸš€</h3><p><em>Thank you for reading until the end. Before youÂ go:</em></p><p>ğŸ‘ Please <strong><em>clap</em></strong> and <strong><em>follow</em></strong>Â me</p><p>ğŸ“¬ <a href=\"https://medium.com/@xuzhusheng/subscribe\">Subscribe</a> to my Medium newsletter for emailÂ updates!</p><p>â˜• or just <a href=\"https://www.buymeacoffee.com/jason.xu\">buy me aÂ coffee</a></p><h3>In Plain EnglishÂ ğŸš€</h3><p><em>Thank you for being a part of the </em><a href=\"https://plainenglish.io\"><strong><em>In Plain English</em></strong></a><em> community! Before youÂ go:</em></p><ul><li>Be sure to <strong>clap</strong> and <strong>follow</strong> the writerÂ ï¸ğŸ‘<strong>ï¸ï¸</strong></li><li>Follow us: <a href=\"https://twitter.com/inPlainEngHQ\"><strong>X</strong></a><strong> | </strong><a href=\"https://www.linkedin.com/company/inplainenglish/\"><strong>LinkedIn</strong></a><strong> | </strong><a href=\"https://www.youtube.com/channel/UCtipWUghju290NWcn8jhyAw\"><strong>YouTube</strong></a><strong> | </strong><a href=\"https://discord.gg/in-plain-english-709094664682340443\"><strong>Discord</strong></a><strong> | </strong><a href=\"https://newsletter.plainenglish.io/\"><strong>Newsletter</strong></a></li><li>Visit our other platforms: <a href=\"https://stackademic.com/\"><strong>Stackademic</strong></a><strong> | </strong><a href=\"https://cofeed.app/\"><strong>CoFeed</strong></a><strong> | </strong><a href=\"https://venturemagazine.net/\"><strong>Venture</strong></a><strong> |Â </strong><a href=\"https://blog.cubed.run\"><strong>Cubed</strong></a></li><li>More content at <a href=\"https://plainenglish.io\"><strong>PlainEnglish.io</strong></a></li></ul><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=e8cd434645bf\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://python.plainenglish.io/calculates-variance-and-standard-deviation-with-python-e8cd434645bf\">Variance and Standard Deviation</a> was originally published in <a href=\"https://python.plainenglish.io\">Python in Plain English</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>","enclosures":[],"content_encoded":"<h4>Machine Learning</h4><h4>What variance and standard deviation are and how to calculate them.</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*vSWCAp4xDrKWelgx\" /><figcaption>Photo by <a href=\"https://unsplash.com/@bash__profile?utm_source=medium&amp;utm_medium=referral\">Nicholas Cappello</a> onÂ <a href=\"https://unsplash.com?utm_source=medium&amp;utm_medium=referral\">Unsplash</a></figcaption></figure><p><strong>Variance</strong> and <strong>standard deviation</strong> and are two basic mathematical concepts. Both measure the variability of figures within a data set using the mean of a certain group of numbers. They are important to help determine volatility and the distribution ofÂ returns.</p><p>In this article, we are going to explore variance and standard deviation and how to calculate withÂ NumPy.</p><p>At the end of this article, we will comprehend:</p><ul><li><em>What the expected value or arthmetic mean is and how to calculate it</em></li><li><em>What the variance is and how to calculate it</em></li><li><em>What the standard diviation is and how to calcualte it</em></li></ul><p>Letâ€™s start with the most basic mean and expectedÂ value.</p><h3><strong>Arithmetic Mean and ExpectedÂ Value</strong></h3><h4><strong>Arithmetic Mean (SampleÂ Mean)</strong></h4><p>In mathematics and statistics, the arithmetic mean of a set of observed data is equal to the sum of the numerical values of each observation, divided by the total number of observations. The arithmetic mean calculated from observed sample is symbolized as x-bar. It is defined by theÂ formula:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/682/1*meyblNvsdxElBI90rBxs4w.png\" /></figure><h4><strong>Expected Value (Population Mean)</strong></h4><p>The expected value of a discrete random variable X, symbolized as E(X), is often referred to as the long-term mean, population mean, symbolized as Î¼ to differentiate the sample mean. The Expected Value difined by theÂ formula:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/682/1*SOWeJ7TWG3XTW8eIG2m8Mw.png\" /></figure><h4><strong>Calculating mean withÂ NumPy</strong></h4><p>We can use the `mean()` function in NumPy to calculate mean for vector and matrix. Letâ€™s see how to doÂ it:</p><pre>import numpy as np<br><br>np.random.seed(202404)<br><br><br>vector = np.random.randint(10, size = 7)<br>print(vector) # [2 1 1 6 5 5 0]<br><br># mean for vector<br>vector.mean()<br><br><br>matrix = np.random.randint(10, size=(3,5))<br>print(matrix)<br># [[0 6 9 8 9]<br>#  [1 2 0 8 1]<br>#  [5 1 5 8 7]]<br><br># column mean<br>print(matrix.mean(axis=0))  # [2.         3.         4.66666667 8.         5.66666667]<br><br># row mean<br>print(matrix.mean(axis=1))  # [6.4 2.4 5.2]<br><br># mean for all element<br>print(matrix.mean())    # 4.666666666666667</pre><h3><strong>Variance</strong></h3><p>In probability theory and statistics, variance is the expected value of the squared deviation from the mean of a random variable. Variance is a measure of dispersion, meaning it is a measure of how far a set of numbers is spread out from their averageÂ value.</p><h4><strong>Population Variance</strong></h4><p>The population variance of a finite population givenÂ by:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/682/1*Ant7t14LDv3mIPAtskzXGg.png\" /></figure><ul><li><em>ÏƒÂ² is population variance</em></li><li><em>x_i is observed value from the population</em></li><li><em>Î¼ is the mean of allÂ x</em></li><li><em>N is the number of x in the population</em></li></ul><h4><strong>Sample Variance</strong></h4><p>In many practical situations, the true variance of a population is not known a priori and must be computed somehow. Variance is usually estimated from a sample drawn from a population. The unbiased estimate of population variance calculated from a sampleÂ is:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/682/1*KPwFtcmP3cwn0IYHVmJbxg.png\" /></figure><h4><strong>Calculating Variance withÂ NumPy</strong></h4><p>According to the formulas, we could calculate the variance asÂ below:</p><pre>import numpy as np<br><br>np.random.seed(202404)<br><br>data = np.random.randint(10, size = 7)<br>print(data) # [2 1 1 6 5 5 0]<br><br>def variance(data, *, bias = False):<br>    num = len(data) if bias else len(data) - 1<br>    return ((data - data.mean()) ** 2).sum() / num<br><br># unbiased sample variance<br>print(variance(data))   # 5.809523809523809<br><br># population variance or biased sample variance<br>print(variance(data, bias=True))    # 4.979591836734693</pre><p>In real pratice, We use the `var()` function in NumPy to calculate variance asÂ below:</p><pre>import numpy as np<br><br>np.random.seed(202404)<br><br>vector = np.random.randint(10, size = 7)<br>print(vector) # [2 1 1 6 5 5 0]<br><br># unbiased sample variance<br>print(vector.var(ddof=1)) # 5.809523809523809<br><br># population variance or biased sample variance<br>print(vector.var(ddof=0)) # 4.979591836734693<br><br>matrix = np.random.randint(10, size=(3, 5))<br>print(matrix)<br># [[0 6 9 8 9]<br>#  [1 2 0 8 1]<br>#  [5 1 5 8 7]]<br><br># unbiased sample variance<br># column variance<br>print(matrix.var(axis=0, ddof=1))   # [ 7.          7.         20.33333333  0.         17.33333333]<br># row variance<br>print(matrix.var(axis=1, ddof=1))   # [14.3 10.3  7.2]<br># variance for all elements<br>print(matrix.var( ddof=1))  # 12.095238095238098<br><br># population variance or biased sample variance<br># column variance<br>print(matrix.var(axis=0))   # [ 4.66666667  4.66666667 13.55555556  0.         11.55555556]<br># row variance<br>print(matrix.var(axis=1))   # [11.44  8.24  5.76]<br># variance for all elements<br>print(matrix.var()) # 11.288888888888891</pre><h3><strong>Standard Deviation</strong></h3><p>The standard deviation (SD) is a statistic that measures the dispersion of a dataset relative to its mean and is calculated as the square root of the variance. If the data points are further from the mean, there is a higher deviation within the data set. The more spread out the data, the higher the standard deviation. Like the variance, there are population standard deviation and sample standard deviation.</p><h4><strong>Population standard deviation</strong></h4><p>The formula of population standard deviation is:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/682/1*GXlVE8QqZBA4Af2f150ihg.png\" /></figure><h4><strong>Sample standard deviation</strong></h4><p>The sample of population standard deviation is:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/682/1*GXlVE8QqZBA4Af2f150ihg.png\" /></figure><h4><strong>Calculating Standard Deviation withÂ NumPy</strong></h4><p>We use the `std()` function in NumPy to calculate standard deviation like we calculate variance above. Letâ€™s see how to do it with examples:</p><pre>import numpy as np<br><br>np.random.seed(202404)<br><br>vector = np.random.randint(10, size = 7)<br>print(vector) # [2 1 1 6 5 5 0]<br><br># unbiased sample variance<br>print(vector.std(ddof=1)) # 2.410295378065479<br><br># population standard deviation or biased sample standard deviation<br>print(vector.std(ddof=0)) # 2.231499907401901<br><br>matrix = np.random.randint(10, size=(3, 5))<br>print(matrix)<br># [[0 6 9 8 9]<br>#  [1 2 0 8 1]<br>#  [5 1 5 8 7]]<br><br># unbiased sample standard deviation<br># column standard deviation<br>print(matrix.std(axis=0, ddof=1))   # [2.64575131 2.64575131 4.50924975 0.         4.163332  ]<br># row standard deviation<br>print(matrix.std(axis=1, ddof=1))   # [3.78153408 3.20936131 2.68328157]<br># standard deviation for all elements<br>print(matrix.std( ddof=1))  # 3.477820883144803<br><br># population standard deviation or biased sample standard deviation<br># column standard deviation<br>print(matrix.std(axis=0))   # [2.1602469  2.1602469  3.68178701 0.         3.39934634]<br># row standard deviation<br>print(matrix.std(axis=1))   # [3.38230691 2.87054002 2.4       ]<br># standard deviation for all elements<br>print(matrix.std()) # 3.3598941782277745</pre><h3><strong>Conclusion</strong></h3><p>The variance measures the average degree to which each point differs from the mean. While standard deviation is the square root of the variance. They are both important to help determine volatility and the distribution ofÂ returns.</p><p>In many practical situations, we usually estimate variance and standard deviation from a sample drawn from a population. When estimate variance and standard deviation from a sample, we use Besselâ€™s correction to adjust the divisor to n (sample size) -Â 1.</p><p>We can use the var() and std() functions to calculate variance and standard deviation withÂ NumPy</p><h3>Jason ğŸš€</h3><p><em>Thank you for reading until the end. Before youÂ go:</em></p><p>ğŸ‘ Please <strong><em>clap</em></strong> and <strong><em>follow</em></strong>Â me</p><p>ğŸ“¬ <a href=\"https://medium.com/@xuzhusheng/subscribe\">Subscribe</a> to my Medium newsletter for emailÂ updates!</p><p>â˜• or just <a href=\"https://www.buymeacoffee.com/jason.xu\">buy me aÂ coffee</a></p><h3>In Plain EnglishÂ ğŸš€</h3><p><em>Thank you for being a part of the </em><a href=\"https://plainenglish.io\"><strong><em>In Plain English</em></strong></a><em> community! Before youÂ go:</em></p><ul><li>Be sure to <strong>clap</strong> and <strong>follow</strong> the writerÂ ï¸ğŸ‘<strong>ï¸ï¸</strong></li><li>Follow us: <a href=\"https://twitter.com/inPlainEngHQ\"><strong>X</strong></a><strong> | </strong><a href=\"https://www.linkedin.com/company/inplainenglish/\"><strong>LinkedIn</strong></a><strong> | </strong><a href=\"https://www.youtube.com/channel/UCtipWUghju290NWcn8jhyAw\"><strong>YouTube</strong></a><strong> | </strong><a href=\"https://discord.gg/in-plain-english-709094664682340443\"><strong>Discord</strong></a><strong> | </strong><a href=\"https://newsletter.plainenglish.io/\"><strong>Newsletter</strong></a></li><li>Visit our other platforms: <a href=\"https://stackademic.com/\"><strong>Stackademic</strong></a><strong> | </strong><a href=\"https://cofeed.app/\"><strong>CoFeed</strong></a><strong> | </strong><a href=\"https://venturemagazine.net/\"><strong>Venture</strong></a><strong> |Â </strong><a href=\"https://blog.cubed.run\"><strong>Cubed</strong></a></li><li>More content at <a href=\"https://plainenglish.io\"><strong>PlainEnglish.io</strong></a></li></ul><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=e8cd434645bf\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://python.plainenglish.io/calculates-variance-and-standard-deviation-with-python-e8cd434645bf\">Variance and Standard Deviation</a> was originally published in <a href=\"https://python.plainenglish.io\">Python in Plain English</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>","media":{}},{"id":"https://medium.com/p/044401094749","title":"Testing for Stationarity in Time Series Data","link":"https://python.plainenglish.io/testing-for-stationarity-in-time-series-data-044401094749?source=rss-41bd992616fb------2","author":"Jason","published":1712024612000,"created":1712024612000,"category":["data-science","python","time-series-analysis","data-analysis","machine-learning"],"content":"<h4>Machine Learning</h4><h4>Explore stationarity and the most common ways to test stationarity inÂ python.</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*eqs_lEJTW9WI1Ulo\" /><figcaption>Photo by <a href=\"https://unsplash.com/@lukechesser?utm_source=medium&amp;utm_medium=referral\">Luke Chesser</a> onÂ <a href=\"https://unsplash.com?utm_source=medium&amp;utm_medium=referral\">Unsplash</a></figcaption></figure><p>Stationarity is a crucial concept in time series analysis. It influencing how data is perceived and predicted. Stationarity is a fundamental assumption for many time series analysis techniques. Non-stationary data are often transformed to become stationary.</p><p>In this article, we are going to explore what is stationarity, how to test stationarity inÂ python.</p><h3><strong>Stationarity</strong></h3><p>Stationarity means statistical properties do not change over time. Stationary data must meet the following assumptions:</p><ul><li><strong>Constant Mean</strong>. The average value of the data remains consistent over time. No any significant trend or fluctuation is crucial for reliable data analysis and modeling.</li><li><strong>Constant Variance</strong>. The dispersion of data points remains constant over time. The absence of drastic changes in variance ensures that the data behaves predictably, allowing for better model accuracy.</li><li><strong>Constant Autocorrelation</strong>. The relationship between data points at different time lags remains constant over time. The constant correlated pattern between data points is pivotal for understanding the time series structure.</li><li><strong>No Trend or Seasonality.</strong> Trend refers to a long-term upward or downward movement in the data, while seasonality involves repeating patterns at fixed intervals. The absence of these patterns in stationary data simplifies modeling and prediction tasks.</li></ul><h3><strong>Testing for Stationarity</strong></h3><p>There are several ways to test stationarity. We are going to explore three of the most commonÂ ones.</p><h4><strong>visualization</strong></h4><p>visualizationâ€Šâ€”â€Šplotting the data and checking for statistical properties is he most basic one to test stationarity. We can looks at the data and the Autocorrelation functions(ACF) plots for checking statical properties.</p><ul><li><strong>Looking at theÂ Data</strong></li></ul><p>Some properties that can be detected very easily from the plot of the data. For example, if the data has an upward or downward trend, and if the variance appears consistent over time. Letâ€™s take a look at the plots of a series of white noise and randowwalk.</p><pre>import numpy as np<br>import matplotlib.pyplot as plt<br><br>np.random.seed(202404)<br><br>num_of_samples = 100<br><br>def white_norse(num_of_samples):<br>    return np.random.standard_normal(num_of_samples)<br><br>def randomwalk(n):<br>    x = 0<br>    start = x<br>    xposition = []<br>    probabilities = [-1, 1]<br>    for _ in range(n):<br>        x += np.random.choice(probabilities)<br>        xposition.append(x)<br>    return np.array(xposition)<br><br>white_norse_samples = white_norse(num_of_samples)<br>randomwalk_samples = randomwalk(num_of_samples)<br>fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True)<br>ax1.set_title(&quot;White Noise&quot;)<br>ax1.plot(white_norse_samples)<br>ax2.set_title(&quot;Romdanwalk&quot;)<br>ax2.plot(randomwalk_samples)</pre><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/554/1*vnygzQyjE2X7JcoRMewgpw.png\" /></figure><p>Obviously, the while noise has consistent mean and various over time. It is stationary data. On the other hand, the randomwalk has a downward trend, does not have a consistent mean or variance over time. It is non-stationary data.</p><ul><li><strong>Looking at the Autocorrelation functions(ACF) plots</strong></li></ul><p>Letâ€™s see the ACF plots of aboveÂ data.</p><pre>from statsmodels.graphics.tsaplots import plot_acf<br><br>fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True)<br><br>plot_acf(white_norse_samples, ax1, lags = 99)<br>ax1.set_title(&quot;ACF Plot for White Norse&quot;)<br><br>plot_acf(randomwalk_samples, ax2, lags = 99)<br>ax2.set_title(&quot;ACF Plot for Randomwalk&quot;)</pre><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/559/1*TJ8Qy7yFfeW6neTI9HXvNw.png\" /></figure><p>The plot for white noise, the value of ACF drops to zero quikly. It is the case of stationary data. However, the plot for randomwalk, the value of ACF decreases slowly. It is non-stationary data.</p><p>Visualization is usually used to get a preliminary idea of stationarity in data. A more rigorous approach is using statistical tests developed to detect specific types of stationarity. The two of common statistical tests are <strong>Augmented Dickey-Fuller Test (ADF)</strong> and <strong>Kwiatkowski-Phillips-Schmidt-Shin Test (KPSS)</strong>. Letâ€™s confirm our above visualization test with ADF andÂ KPSS.</p><h4><strong>Augmented Dickey-Fuller TestÂ (ADF)</strong></h4><p>Augmented Dickey-Fuller test is one of the most used tests for stationarity. It tests the following hypothesis:</p><ul><li><em>Null hypothesis, H0â€Šâ€”â€Šthe time series is not stationary.</em></li><li><em>Alternative Hypothesis, H1â€Šâ€”â€Šthe time series is stationary.</em></li></ul><p>We can use the adfuller method from the statsmodels library to perform this test in Python. Then, compares the value of the <strong>test statistics</strong> or the <strong>p-value</strong>. The test result list asÂ follows:</p><p>1. Compares the value of the test statistics:</p><ul><li><em>Stationaryâ€Šâ€”â€Šthe absolute value is greater than the criticalÂ value</em></li><li><em>Non-stationaryâ€Šâ€”â€Šthe absolute value is less than the crucialÂ value</em></li></ul><p>2. ComparesÂ p-value:</p><ul><li><em>Stationaryâ€Šâ€”â€Šp-value &lt;=Â 0.05</em></li><li><em>Non-stationaryâ€Šâ€”â€Šp-value &gt;Â 0.05</em></li></ul><p>Here is the pythonÂ scripts:</p><pre>from statsmodels.tsa.stattools import adfuller<br>from pprint import pprint<br><br>def adf_test(samples):<br> <br> <br> test_statistic, p_value, *_ = adfuller(samples)<br> print(f&#39;Test Statistic: {test_statistic}&#39;)<br> print(f&#39;P-value: {p_value}&#39;)<br><br> # interpret the results<br> if p_value &lt;= 0.05:<br>  print(&#39;Reject the null hypothesis: The time series is stationary.&#39;)<br> else:<br>  print(&#39;Fail to reject the null hypothesis: The time series is non-stationary.&#39;)<br><br>adf_test(white_norse_samples)<br># Test Statistic: -6.416288343797171<br># P-value: 1.8378154405121545e-08<br># Reject the null hypothesis: The time series is stationary.<br><br>adf_test(randomwalk_samples)<br># Test Statistic: -2.2091400629727627<br># P-value: 0.20294488186347692<br># Fail to reject the null hypothesis: The time series is non-stationary.</pre><h4><strong>Kwiatkowski-Phillips-Schmidt-Shin Test (KPSSÂ Test)</strong></h4><p>The KPSS test is another hypothesis test used to check for stationarity in a timeÂ series.</p><p>It tests the following hypothesis:</p><ul><li><em>Null hypothesis, H0â€Šâ€”â€Šthe time series is stationary.</em></li><li><em>Alternative Hypothesis, H1â€Šâ€”â€Šthe time series is not stationary.</em></li></ul><p>We can use the kpss method from the statsmodels library to perform this test in Python. Then, compares the value of the test statistics or the p-value. Since the hypothesis is the opposite of the ADF test, the interpretation of the p-value is also opposite:</p><p>1. Compares the value of the test statistics:</p><ul><li><em>Stationaryâ€Šâ€”â€Šthe absolute value is less than the crucialÂ value</em></li><li><em>Non-stationaryâ€Šâ€”â€Šthe absolute value is greater than the criticalÂ value</em></li></ul><p>2. ComparesÂ p-value:</p><ul><li><em>Stationaryâ€Šâ€”â€Šp-value &gt;Â 0.05</em></li><li><em>Non-stationaryâ€Šâ€”â€Šp-value &lt;=Â 0.05</em></li></ul><p>Here is the pythonÂ scripts:</p><pre>from statsmodels.tsa.stattools import kpss<br>import warnings<br>from statsmodels.tools.sm_exceptions import InterpolationWarning<br>warnings.simplefilter(&#39;ignore&#39;, InterpolationWarning)<br><br>def kpss_test(samples):<br> test_statistic, p_value, *_ = kpss(samples, regression=&#39;c&#39;)<br><br> print(f&#39;Test Statistic: {test_statistic}&#39;)<br> print(f&#39;P-value: {p_value}&#39;)<br><br> if p_value &gt; 0.05:<br>  print(&#39;Fail to reject the null hypothesis: The time series is stationary.&#39;)<br> else:<br>  print(&#39;Reject the null hypothesis: The time series is non-stationary.&#39;)<br><br>kpss_test(white_norse_samples)<br># Test Statistic: 0.10503398480585609<br># P-value: 0.1<br># Fail to reject the null hypothesis: The time series is stationary.<br><br>kpss_test(randomwalk_samples)<br># Test Statistic: 1.5771286573497258<br># P-value: 0.01<br># Reject the null hypothesis: The time series is non-stationary.</pre><h3>Conclusion</h3><p>Stationarity is crucial in time series analysis. Stationarity is a fundamental assumption for many time series analysis techniques. The three of most common ways for testing stationarity is Visualization, ADF test and KPSS test. For ADF test and KPSS test, we compares the p-value or statistics value to determine the stationarity. Itâ€™s often beneficial to perform both ADF and KPSS tests and interpret their results in combination.</p><h3>Jason ğŸš€</h3><p><em>Thank you for reading until the end. Before youÂ go:</em></p><p>ğŸ‘ Please <strong><em>clap</em></strong> and <strong><em>follow</em></strong>Â me</p><p>ğŸ“¬ <a href=\"https://medium.com/@xuzhusheng/subscribe\">Subscribe</a> to my Medium newsletter for emailÂ updates!</p><p>â˜• or just <a href=\"https://www.buymeacoffee.com/jason.xu\">buy me aÂ coffee</a></p><h3>In Plain EnglishÂ ğŸš€</h3><p><em>Thank you for being a part of the </em><a href=\"https://plainenglish.io\"><strong><em>In Plain English</em></strong></a><em> community! Before youÂ go:</em></p><ul><li>Be sure to <strong>clap</strong> and <strong>follow</strong> the writerÂ ï¸ğŸ‘<strong>ï¸ï¸</strong></li><li>Follow us: <a href=\"https://twitter.com/inPlainEngHQ\"><strong>X</strong></a><strong> | </strong><a href=\"https://www.linkedin.com/company/inplainenglish/\"><strong>LinkedIn</strong></a><strong> | </strong><a href=\"https://www.youtube.com/channel/UCtipWUghju290NWcn8jhyAw\"><strong>YouTube</strong></a><strong> | </strong><a href=\"https://discord.gg/in-plain-english-709094664682340443\"><strong>Discord</strong></a><strong> | </strong><a href=\"https://newsletter.plainenglish.io/\"><strong>Newsletter</strong></a></li><li>Visit our other platforms: <a href=\"https://stackademic.com/\"><strong>Stackademic</strong></a><strong> | </strong><a href=\"https://cofeed.app/\"><strong>CoFeed</strong></a><strong> | </strong><a href=\"https://venturemagazine.net/\"><strong>Venture</strong></a><strong> |Â </strong><a href=\"https://blog.cubed.run\"><strong>Cubed</strong></a></li><li>More content at <a href=\"https://plainenglish.io\"><strong>PlainEnglish.io</strong></a></li></ul><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=044401094749\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://python.plainenglish.io/testing-for-stationarity-in-time-series-data-044401094749\">Testing for Stationarity in Time Series Data</a> was originally published in <a href=\"https://python.plainenglish.io\">Python in Plain English</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>","enclosures":[],"content_encoded":"<h4>Machine Learning</h4><h4>Explore stationarity and the most common ways to test stationarity inÂ python.</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*eqs_lEJTW9WI1Ulo\" /><figcaption>Photo by <a href=\"https://unsplash.com/@lukechesser?utm_source=medium&amp;utm_medium=referral\">Luke Chesser</a> onÂ <a href=\"https://unsplash.com?utm_source=medium&amp;utm_medium=referral\">Unsplash</a></figcaption></figure><p>Stationarity is a crucial concept in time series analysis. It influencing how data is perceived and predicted. Stationarity is a fundamental assumption for many time series analysis techniques. Non-stationary data are often transformed to become stationary.</p><p>In this article, we are going to explore what is stationarity, how to test stationarity inÂ python.</p><h3><strong>Stationarity</strong></h3><p>Stationarity means statistical properties do not change over time. Stationary data must meet the following assumptions:</p><ul><li><strong>Constant Mean</strong>. The average value of the data remains consistent over time. No any significant trend or fluctuation is crucial for reliable data analysis and modeling.</li><li><strong>Constant Variance</strong>. The dispersion of data points remains constant over time. The absence of drastic changes in variance ensures that the data behaves predictably, allowing for better model accuracy.</li><li><strong>Constant Autocorrelation</strong>. The relationship between data points at different time lags remains constant over time. The constant correlated pattern between data points is pivotal for understanding the time series structure.</li><li><strong>No Trend or Seasonality.</strong> Trend refers to a long-term upward or downward movement in the data, while seasonality involves repeating patterns at fixed intervals. The absence of these patterns in stationary data simplifies modeling and prediction tasks.</li></ul><h3><strong>Testing for Stationarity</strong></h3><p>There are several ways to test stationarity. We are going to explore three of the most commonÂ ones.</p><h4><strong>visualization</strong></h4><p>visualizationâ€Šâ€”â€Šplotting the data and checking for statistical properties is he most basic one to test stationarity. We can looks at the data and the Autocorrelation functions(ACF) plots for checking statical properties.</p><ul><li><strong>Looking at theÂ Data</strong></li></ul><p>Some properties that can be detected very easily from the plot of the data. For example, if the data has an upward or downward trend, and if the variance appears consistent over time. Letâ€™s take a look at the plots of a series of white noise and randowwalk.</p><pre>import numpy as np<br>import matplotlib.pyplot as plt<br><br>np.random.seed(202404)<br><br>num_of_samples = 100<br><br>def white_norse(num_of_samples):<br>    return np.random.standard_normal(num_of_samples)<br><br>def randomwalk(n):<br>    x = 0<br>    start = x<br>    xposition = []<br>    probabilities = [-1, 1]<br>    for _ in range(n):<br>        x += np.random.choice(probabilities)<br>        xposition.append(x)<br>    return np.array(xposition)<br><br>white_norse_samples = white_norse(num_of_samples)<br>randomwalk_samples = randomwalk(num_of_samples)<br>fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True)<br>ax1.set_title(&quot;White Noise&quot;)<br>ax1.plot(white_norse_samples)<br>ax2.set_title(&quot;Romdanwalk&quot;)<br>ax2.plot(randomwalk_samples)</pre><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/554/1*vnygzQyjE2X7JcoRMewgpw.png\" /></figure><p>Obviously, the while noise has consistent mean and various over time. It is stationary data. On the other hand, the randomwalk has a downward trend, does not have a consistent mean or variance over time. It is non-stationary data.</p><ul><li><strong>Looking at the Autocorrelation functions(ACF) plots</strong></li></ul><p>Letâ€™s see the ACF plots of aboveÂ data.</p><pre>from statsmodels.graphics.tsaplots import plot_acf<br><br>fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True)<br><br>plot_acf(white_norse_samples, ax1, lags = 99)<br>ax1.set_title(&quot;ACF Plot for White Norse&quot;)<br><br>plot_acf(randomwalk_samples, ax2, lags = 99)<br>ax2.set_title(&quot;ACF Plot for Randomwalk&quot;)</pre><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/559/1*TJ8Qy7yFfeW6neTI9HXvNw.png\" /></figure><p>The plot for white noise, the value of ACF drops to zero quikly. It is the case of stationary data. However, the plot for randomwalk, the value of ACF decreases slowly. It is non-stationary data.</p><p>Visualization is usually used to get a preliminary idea of stationarity in data. A more rigorous approach is using statistical tests developed to detect specific types of stationarity. The two of common statistical tests are <strong>Augmented Dickey-Fuller Test (ADF)</strong> and <strong>Kwiatkowski-Phillips-Schmidt-Shin Test (KPSS)</strong>. Letâ€™s confirm our above visualization test with ADF andÂ KPSS.</p><h4><strong>Augmented Dickey-Fuller TestÂ (ADF)</strong></h4><p>Augmented Dickey-Fuller test is one of the most used tests for stationarity. It tests the following hypothesis:</p><ul><li><em>Null hypothesis, H0â€Šâ€”â€Šthe time series is not stationary.</em></li><li><em>Alternative Hypothesis, H1â€Šâ€”â€Šthe time series is stationary.</em></li></ul><p>We can use the adfuller method from the statsmodels library to perform this test in Python. Then, compares the value of the <strong>test statistics</strong> or the <strong>p-value</strong>. The test result list asÂ follows:</p><p>1. Compares the value of the test statistics:</p><ul><li><em>Stationaryâ€Šâ€”â€Šthe absolute value is greater than the criticalÂ value</em></li><li><em>Non-stationaryâ€Šâ€”â€Šthe absolute value is less than the crucialÂ value</em></li></ul><p>2. ComparesÂ p-value:</p><ul><li><em>Stationaryâ€Šâ€”â€Šp-value &lt;=Â 0.05</em></li><li><em>Non-stationaryâ€Šâ€”â€Šp-value &gt;Â 0.05</em></li></ul><p>Here is the pythonÂ scripts:</p><pre>from statsmodels.tsa.stattools import adfuller<br>from pprint import pprint<br><br>def adf_test(samples):<br> <br> <br> test_statistic, p_value, *_ = adfuller(samples)<br> print(f&#39;Test Statistic: {test_statistic}&#39;)<br> print(f&#39;P-value: {p_value}&#39;)<br><br> # interpret the results<br> if p_value &lt;= 0.05:<br>  print(&#39;Reject the null hypothesis: The time series is stationary.&#39;)<br> else:<br>  print(&#39;Fail to reject the null hypothesis: The time series is non-stationary.&#39;)<br><br>adf_test(white_norse_samples)<br># Test Statistic: -6.416288343797171<br># P-value: 1.8378154405121545e-08<br># Reject the null hypothesis: The time series is stationary.<br><br>adf_test(randomwalk_samples)<br># Test Statistic: -2.2091400629727627<br># P-value: 0.20294488186347692<br># Fail to reject the null hypothesis: The time series is non-stationary.</pre><h4><strong>Kwiatkowski-Phillips-Schmidt-Shin Test (KPSSÂ Test)</strong></h4><p>The KPSS test is another hypothesis test used to check for stationarity in a timeÂ series.</p><p>It tests the following hypothesis:</p><ul><li><em>Null hypothesis, H0â€Šâ€”â€Šthe time series is stationary.</em></li><li><em>Alternative Hypothesis, H1â€Šâ€”â€Šthe time series is not stationary.</em></li></ul><p>We can use the kpss method from the statsmodels library to perform this test in Python. Then, compares the value of the test statistics or the p-value. Since the hypothesis is the opposite of the ADF test, the interpretation of the p-value is also opposite:</p><p>1. Compares the value of the test statistics:</p><ul><li><em>Stationaryâ€Šâ€”â€Šthe absolute value is less than the crucialÂ value</em></li><li><em>Non-stationaryâ€Šâ€”â€Šthe absolute value is greater than the criticalÂ value</em></li></ul><p>2. ComparesÂ p-value:</p><ul><li><em>Stationaryâ€Šâ€”â€Šp-value &gt;Â 0.05</em></li><li><em>Non-stationaryâ€Šâ€”â€Šp-value &lt;=Â 0.05</em></li></ul><p>Here is the pythonÂ scripts:</p><pre>from statsmodels.tsa.stattools import kpss<br>import warnings<br>from statsmodels.tools.sm_exceptions import InterpolationWarning<br>warnings.simplefilter(&#39;ignore&#39;, InterpolationWarning)<br><br>def kpss_test(samples):<br> test_statistic, p_value, *_ = kpss(samples, regression=&#39;c&#39;)<br><br> print(f&#39;Test Statistic: {test_statistic}&#39;)<br> print(f&#39;P-value: {p_value}&#39;)<br><br> if p_value &gt; 0.05:<br>  print(&#39;Fail to reject the null hypothesis: The time series is stationary.&#39;)<br> else:<br>  print(&#39;Reject the null hypothesis: The time series is non-stationary.&#39;)<br><br>kpss_test(white_norse_samples)<br># Test Statistic: 0.10503398480585609<br># P-value: 0.1<br># Fail to reject the null hypothesis: The time series is stationary.<br><br>kpss_test(randomwalk_samples)<br># Test Statistic: 1.5771286573497258<br># P-value: 0.01<br># Reject the null hypothesis: The time series is non-stationary.</pre><h3>Conclusion</h3><p>Stationarity is crucial in time series analysis. Stationarity is a fundamental assumption for many time series analysis techniques. The three of most common ways for testing stationarity is Visualization, ADF test and KPSS test. For ADF test and KPSS test, we compares the p-value or statistics value to determine the stationarity. Itâ€™s often beneficial to perform both ADF and KPSS tests and interpret their results in combination.</p><h3>Jason ğŸš€</h3><p><em>Thank you for reading until the end. Before youÂ go:</em></p><p>ğŸ‘ Please <strong><em>clap</em></strong> and <strong><em>follow</em></strong>Â me</p><p>ğŸ“¬ <a href=\"https://medium.com/@xuzhusheng/subscribe\">Subscribe</a> to my Medium newsletter for emailÂ updates!</p><p>â˜• or just <a href=\"https://www.buymeacoffee.com/jason.xu\">buy me aÂ coffee</a></p><h3>In Plain EnglishÂ ğŸš€</h3><p><em>Thank you for being a part of the </em><a href=\"https://plainenglish.io\"><strong><em>In Plain English</em></strong></a><em> community! Before youÂ go:</em></p><ul><li>Be sure to <strong>clap</strong> and <strong>follow</strong> the writerÂ ï¸ğŸ‘<strong>ï¸ï¸</strong></li><li>Follow us: <a href=\"https://twitter.com/inPlainEngHQ\"><strong>X</strong></a><strong> | </strong><a href=\"https://www.linkedin.com/company/inplainenglish/\"><strong>LinkedIn</strong></a><strong> | </strong><a href=\"https://www.youtube.com/channel/UCtipWUghju290NWcn8jhyAw\"><strong>YouTube</strong></a><strong> | </strong><a href=\"https://discord.gg/in-plain-english-709094664682340443\"><strong>Discord</strong></a><strong> | </strong><a href=\"https://newsletter.plainenglish.io/\"><strong>Newsletter</strong></a></li><li>Visit our other platforms: <a href=\"https://stackademic.com/\"><strong>Stackademic</strong></a><strong> | </strong><a href=\"https://cofeed.app/\"><strong>CoFeed</strong></a><strong> | </strong><a href=\"https://venturemagazine.net/\"><strong>Venture</strong></a><strong> |Â </strong><a href=\"https://blog.cubed.run\"><strong>Cubed</strong></a></li><li>More content at <a href=\"https://plainenglish.io\"><strong>PlainEnglish.io</strong></a></li></ul><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=044401094749\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://python.plainenglish.io/testing-for-stationarity-in-time-series-data-044401094749\">Testing for Stationarity in Time Series Data</a> was originally published in <a href=\"https://python.plainenglish.io\">Python in Plain English</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>","media":{}},{"id":"https://medium.com/p/614e00f5c15c","title":"Accuracy, Precision, Recall and F-score in Machine Learning","link":"https://python.plainenglish.io/precision-recall-and-f-score-614e00f5c15c?source=rss-41bd992616fb------2","author":"Jason","published":1711427717000,"created":1711427717000,"category":["data-science","data-analysis","statistics","machine-learning","python"],"content":"<h4>Machine Learning</h4><h4>What is the differnet? Which one should weÂ choose?</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*QTkItc7UFREV0umY\" /><figcaption>Photo by <a href=\"https://unsplash.com/@javaistan?utm_source=medium&amp;utm_medium=referral\">Afif Ramdhasuma</a> onÂ <a href=\"https://unsplash.com?utm_source=medium&amp;utm_medium=referral\">Unsplash</a></figcaption></figure><p>In machine learning, there are various metrics, such as accuracy, precision, recall, and the F1 score for evaluating the performance of a classification model. What is the difference? Which one should weÂ choose?</p><p>In This article, we are going to explore the metrics: accuracy, precision, recall, and F-score. Before we start, we need to comprehend the confusion matrixÂ first.</p><h3>Confusion Matrix</h3><p>A confusion matrix represents the predictive performance of a classification model on a dataset. Here is a confusion matrix structure:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/421/1*eRytmm4XurqgAvZbo01FBg.png\" /></figure><p>For classification tasks, the terms positive and negative refer to the classifierâ€™s prediction, and the terms true and false refer to whether that prediction is correct. The combinations of these terms are the four essential components of a confusion matrix:</p><ul><li><em>True Positives (TP): Number of items correctly predicted as positive.</em></li><li><em>False Positives (FP): Number of items wrongly predicted as positive.</em></li><li><em>True Negatives (TN): Number of items correctly predicted as negative.</em></li><li><em>False Negatives (FN): Number of items wrongly predicted as negative.</em></li></ul><h4><strong>Compute </strong>Confusion Matrix<strong> inÂ Python</strong></h4><p>We could compute confusion matrix in 3Â steps:</p><ol><li>Maps TP, FP, TN, FN to binary 11, 01, 00,Â 10</li><li>marks which quadrant a item belong by bitwise operation y_true &lt; 1 |Â y_pred</li><li>counts marks for eachÂ quadrant</li></ol><p>Here is theÂ scripts:</p><pre>from collections import Counter<br>import sklearn.metrics as metrics<br>import numpy as np<br><br>np.random.seed(202403)<br><br># preparing data<br>y_true, y_pred = np.random.randint(0, 2, size=[2, 100])<br><br><br>MATRIX_TP_INDEX = 1,1<br>MATRIX_FP_INDEX = 0,1<br>MATRIX_TN_INDEX = 0,0<br>MATRIX_FN_INDEX = 1,0<br><br># returned matrix is consistent with the one computed by sciket-learn package<br># TN: c_{0,0}<br># FN: c_{1,0}<br># FP: c_{0,1}<br># TP: c_{1,1}<br>def confusion_matrix(y_true, y_pred):<br>    counter = Counter(y_true &lt;&lt; 1 | y_pred)<br>    matrix = np.zeros((2,2), dtype=np.int32)<br>    for i in range(2):<br>        for j in range(2):<br>            matrix[i, j] = counter[i &lt;&lt; 1 | j]<br>    return matrix<br><br>matrix = confusion_matrix(y_true, y_pred)<br>print(matrix)  <br># [[30 21]<br>#  [27 22]]<br><br>print(f&#39;TP: {matrix[MATRIX_TP_INDEX]}&#39;) #TP: 22<br>print(f&#39;FP: {matrix[MATRIX_FP_INDEX]}&#39;) #FP: 21<br>print(f&#39;TN: {matrix[MATRIX_TN_INDEX]}&#39;) #TN: 30<br>print(f&#39;FN: {matrix[MATRIX_FN_INDEX]}&#39;) #FN: 27<br><br># computed by scikit-learn package for contrast<br>print(metrics.confusion_matrix(y_true, y_pred))  <br># [[30 21]<br>#  [27 22]]</pre><h3>Accuracy</h3><p><strong>Accuracy</strong> represents the number of items predicted correctly divided by total number ofÂ items:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/677/1*2Kp8TPmrdvo3FCdJq-Vrng.png\" /></figure><p>The number of items predicted correctly is the sum of TP + TN and the total number is the sum of TP + TN + FP + FN, Mathmaticly, accuracy defined asÂ follows:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/677/1*sT6uSQVXnf-q4iPpPE2SOg.png\" /></figure><h4><strong>Calculate Accuracy inÂ Python</strong></h4><p>According to the defination, accuracy could be calculated asÂ follows:</p><pre>def accuracy_score(y_true, y_pred):<br>    matrix = confusion_matrix(y_true, y_pred)<br>    tp = matrix[MATRIX_TP_INDEX]<br>    fp = matrix[MATRIX_FP_INDEX]<br>    tn = matrix[MATRIX_TN_INDEX]<br>    fn = matrix[MATRIX_FN_INDEX]<br>    return (tp + tn) / (tp + fp + tn + fn)<br><br>print(accuracy_score(y_true, y_pred))  #0.52<br>print(metrics.accuracy_score(y_true, y_pred))  #0.52</pre><h4><strong>Limitation ofÂ Accuracy</strong></h4><p>The accuracy rate can evluate the total correct rate, but accuracy could be misled in imbalanced dataset. For example, detecting spam in emails. Assume 95% of emails are spam, a model simply predict all of emails are spam, the accuracy of this model is 95%, which make no sense. Accuracy is not valid for imbalanced dataset.</p><h3><strong>Precision andÂ Recall</strong></h3><h4><strong>Precision</strong></h4><p><strong>Precision</strong> (also called positive predictive value) represents the number of items correctly predicted as positive(TP) divided by the total number of items predicted as positive:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/677/1*qSo58VUIMLt3Yh3orIQfFQ.png\" /></figure><p>The total number of items predicted as positive is the sum of true positives(TP) and false positives(FP). Precision mathmaticly definedÂ as:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/677/1*PPclrOn1eF1IcJDzV8dNzA.png\" /></figure><h4><strong>Recall</strong></h4><p><strong>Recall</strong> (also known as sensitivity) represents the number of true positives divided by the total number of items that actually belong to the positiveÂ class.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/677/1*lryGgGmqtlePkIgxSIA3rA.png\" /></figure><p>The total number of items that actually belong to the positive class is the sum of true positives(TP) and false negatives(FN). Recall mathmaticly definedÂ as:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/677/1*nncPuOe2L12HImryaKl-Mw.png\" /></figure><h4>Compute Precision and Recall inÂ Python</h4><pre>def precision_score(y_true, y_pred):<br>    matrix = confusion_matrix(y_true, y_pred)<br>    tp = matrix[MATRIX_TP_INDEX]<br>    fp = matrix[MATRIX_FP_INDEX]<br>    return tp / (tp + fp)<br><br>print(precision_score(y_true, y_pred))  #0.5116279069767442<br>print(metrics.precision_score(y_true, y_pred))  #0.5116279069767442<br><br>def recall_score(y_true, y_pred):<br>    matrix = confusion_matrix(y_true, y_pred)<br>    tp = matrix[MATRIX_TP_INDEX]<br>    fn = matrix[MATRIX_FN_INDEX]<br>    return tp / (tp + fn)<br><br>print(recall_score(y_true, y_pred)) #0.4489795918367347<br>print(metrics.recall_score(y_true, y_pred)) #0.4489795918367347</pre><h4><strong>Precision vs.Â Recall</strong></h4><p>Precision and recall are not particularly useful metrics when used in isolation. It is possible to have perfect recall by retrieving every single item. Likewise, it is possible to have near-perfect precision by selecting only a very small number of extremely likely items. We need to take both precision and recall into account. Ideally, we want to maximize both precision and recallÂ metrics.</p><p>However, there is an inverse relationship between precision and recall, where it is possible to increase one at the cost of reducing the other. How to balance between precision and recall is theÂ dilemma.</p><p>A measure combines precision and recall, symmetrically represents both measures in one metric is F-measure, also calledÂ F-score.</p><h3><strong>F-score/F-measure</strong></h3><p>The F-score combines precision and recall using their harmonic mean, and maximizing the F score implies simultaneously maximizing both precision and recall. There are two different variations of F-score: F1 score and FÎ²Â Score.</p><h4><strong>F1 Score</strong></h4><p>F1 score is the traditional F-measure or balanced F-score. It is the harmonic mean of the precision and recall. F1 score defined asÂ follows:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/677/1*QM3HjjmEmddOqKYYexKsiw.png\" /></figure><p>By replacing the expressions for precision and recall scores in the equation above, the F1 score can also be written asÂ follows:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/677/1*u2SLUm-wsP4UgAV8OerCng.png\" /></figure><p>The highest possible value of an F-score is 1.0, indicating perfect precision and recall, and the lowest possible value is 0, if either precision or recall areÂ zero.</p><p>The more generic F-score applies additional weights Î² is FÎ² score. We will discuss it later. Before that, letâ€™s see how to compute F1 score inÂ Python.</p><h4>Compute F1 Score inÂ Python</h4><pre>def f1_score(y_true, y_pred):<br>    matrix = confusion_matrix(y_true, y_pred)<br>    tp = matrix[MATRIX_TP_INDEX]<br>    fp = matrix[MATRIX_FP_INDEX]<br>    fn = matrix[MATRIX_FN_INDEX]<br>    return 2 * tp / (2 * tp + fp + fn)<br><br>print(f1_score(y_true, y_pred)) #0.4782608695652174<br>print(metrics.f1_score(y_true, y_pred)) #0.47826086956521735</pre><h4><strong>FÎ² Score</strong></h4><p>FÎ² Score is a general F score. It uses a positive real factor Î², where recall is considered</p><p>Î² times as important as precision. FÎ² Score defined asÂ follows:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/677/1*2OsIhnny3N_vCFMiYiayTg.png\" /></figure><p>There are two other commonly used FÎ² measures:</p><ul><li>F2 measureâ€Šâ€”â€Šweights recall higher than precision</li><li>F0.5 measureâ€Šâ€”â€Šputs more emphasis on precision thanÂ recall.</li></ul><p>The FÎ² score is useful when we want to prioritize one measure while preserving results from the otherÂ measure.</p><p>For example, the COVID-19 detection, False Negative results are detrimental (Since a COVID positive patient is diagnosed as COVID negative, leading to the spread of the disease). In this case, the F2 measure is more useful to minimize the False Negatives while also trying to keep the precision score as high as possible. however, for general medical diagnosis, a false positive test can lead to unnecessary treatment and expenses, it is necessary to reduce the False Positives, with a lower Î² value (like an F0.5Â score).</p><h3><strong>Conclusion</strong></h3><p>Accuracy works good for balanced dataset, but is not valid for imbalanced dataset.</p><p>Precision and recall also could be deceived when used in isolation, it is quite tricky to balanceÂ both.</p><p>F1 score offers a more balanced assessment through the harmonic mean of precision and recall. It is a much more comprehensive evaluation metric in comparison with precision andÂ recall.</p><p>Furthermore, FÎ² score, allow controlling the F score metric based on the problem at hand by prioritizing the minimization of either false positive or false negativeÂ losses.</p><h3>Jason ğŸš€</h3><p><em>Thank you for reading until the end. Before youÂ go:</em></p><p>ğŸ‘ Please <strong><em>clap</em></strong> and <strong><em>follow</em></strong>Â me</p><p>ğŸ“¬ <a href=\"https://medium.com/@xuzhusheng/subscribe\">Subscribe</a> to my Medium newsletter for emailÂ updates!</p><p>â˜• or just <a href=\"https://www.buymeacoffee.com/jason.xu\">buy me aÂ coffee</a></p><h3>In Plain EnglishÂ ğŸš€</h3><p><em>Thank you for being a part of the </em><a href=\"https://plainenglish.io\"><strong><em>In Plain English</em></strong></a><em> community! Before youÂ go:</em></p><ul><li>Be sure to <strong>clap</strong> and <strong>follow</strong> the writerÂ ï¸ğŸ‘<strong>ï¸ï¸</strong></li><li>Follow us: <a href=\"https://twitter.com/inPlainEngHQ\"><strong>X</strong></a><strong> | </strong><a href=\"https://www.linkedin.com/company/inplainenglish/\"><strong>LinkedIn</strong></a><strong> | </strong><a href=\"https://www.youtube.com/channel/UCtipWUghju290NWcn8jhyAw\"><strong>YouTube</strong></a><strong> | </strong><a href=\"https://discord.gg/in-plain-english-709094664682340443\"><strong>Discord</strong></a><strong> | </strong><a href=\"https://newsletter.plainenglish.io/\"><strong>Newsletter</strong></a></li><li>Visit our other platforms: <a href=\"https://stackademic.com/\"><strong>Stackademic</strong></a><strong> | </strong><a href=\"https://cofeed.app/\"><strong>CoFeed</strong></a><strong> | </strong><a href=\"https://venturemagazine.net/\"><strong>Venture</strong></a><strong> |Â </strong><a href=\"https://blog.cubed.run\"><strong>Cubed</strong></a></li><li>More content at <a href=\"https://plainenglish.io\"><strong>PlainEnglish.io</strong></a></li></ul><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=614e00f5c15c\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://python.plainenglish.io/precision-recall-and-f-score-614e00f5c15c\">Accuracy, Precision, Recall and F-score in Machine Learning</a> was originally published in <a href=\"https://python.plainenglish.io\">Python in Plain English</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>","enclosures":[],"content_encoded":"<h4>Machine Learning</h4><h4>What is the differnet? Which one should weÂ choose?</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*QTkItc7UFREV0umY\" /><figcaption>Photo by <a href=\"https://unsplash.com/@javaistan?utm_source=medium&amp;utm_medium=referral\">Afif Ramdhasuma</a> onÂ <a href=\"https://unsplash.com?utm_source=medium&amp;utm_medium=referral\">Unsplash</a></figcaption></figure><p>In machine learning, there are various metrics, such as accuracy, precision, recall, and the F1 score for evaluating the performance of a classification model. What is the difference? Which one should weÂ choose?</p><p>In This article, we are going to explore the metrics: accuracy, precision, recall, and F-score. Before we start, we need to comprehend the confusion matrixÂ first.</p><h3>Confusion Matrix</h3><p>A confusion matrix represents the predictive performance of a classification model on a dataset. Here is a confusion matrix structure:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/421/1*eRytmm4XurqgAvZbo01FBg.png\" /></figure><p>For classification tasks, the terms positive and negative refer to the classifierâ€™s prediction, and the terms true and false refer to whether that prediction is correct. The combinations of these terms are the four essential components of a confusion matrix:</p><ul><li><em>True Positives (TP): Number of items correctly predicted as positive.</em></li><li><em>False Positives (FP): Number of items wrongly predicted as positive.</em></li><li><em>True Negatives (TN): Number of items correctly predicted as negative.</em></li><li><em>False Negatives (FN): Number of items wrongly predicted as negative.</em></li></ul><h4><strong>Compute </strong>Confusion Matrix<strong> inÂ Python</strong></h4><p>We could compute confusion matrix in 3Â steps:</p><ol><li>Maps TP, FP, TN, FN to binary 11, 01, 00,Â 10</li><li>marks which quadrant a item belong by bitwise operation y_true &lt; 1 |Â y_pred</li><li>counts marks for eachÂ quadrant</li></ol><p>Here is theÂ scripts:</p><pre>from collections import Counter<br>import sklearn.metrics as metrics<br>import numpy as np<br><br>np.random.seed(202403)<br><br># preparing data<br>y_true, y_pred = np.random.randint(0, 2, size=[2, 100])<br><br><br>MATRIX_TP_INDEX = 1,1<br>MATRIX_FP_INDEX = 0,1<br>MATRIX_TN_INDEX = 0,0<br>MATRIX_FN_INDEX = 1,0<br><br># returned matrix is consistent with the one computed by sciket-learn package<br># TN: c_{0,0}<br># FN: c_{1,0}<br># FP: c_{0,1}<br># TP: c_{1,1}<br>def confusion_matrix(y_true, y_pred):<br>    counter = Counter(y_true &lt;&lt; 1 | y_pred)<br>    matrix = np.zeros((2,2), dtype=np.int32)<br>    for i in range(2):<br>        for j in range(2):<br>            matrix[i, j] = counter[i &lt;&lt; 1 | j]<br>    return matrix<br><br>matrix = confusion_matrix(y_true, y_pred)<br>print(matrix)  <br># [[30 21]<br>#  [27 22]]<br><br>print(f&#39;TP: {matrix[MATRIX_TP_INDEX]}&#39;) #TP: 22<br>print(f&#39;FP: {matrix[MATRIX_FP_INDEX]}&#39;) #FP: 21<br>print(f&#39;TN: {matrix[MATRIX_TN_INDEX]}&#39;) #TN: 30<br>print(f&#39;FN: {matrix[MATRIX_FN_INDEX]}&#39;) #FN: 27<br><br># computed by scikit-learn package for contrast<br>print(metrics.confusion_matrix(y_true, y_pred))  <br># [[30 21]<br>#  [27 22]]</pre><h3>Accuracy</h3><p><strong>Accuracy</strong> represents the number of items predicted correctly divided by total number ofÂ items:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/677/1*2Kp8TPmrdvo3FCdJq-Vrng.png\" /></figure><p>The number of items predicted correctly is the sum of TP + TN and the total number is the sum of TP + TN + FP + FN, Mathmaticly, accuracy defined asÂ follows:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/677/1*sT6uSQVXnf-q4iPpPE2SOg.png\" /></figure><h4><strong>Calculate Accuracy inÂ Python</strong></h4><p>According to the defination, accuracy could be calculated asÂ follows:</p><pre>def accuracy_score(y_true, y_pred):<br>    matrix = confusion_matrix(y_true, y_pred)<br>    tp = matrix[MATRIX_TP_INDEX]<br>    fp = matrix[MATRIX_FP_INDEX]<br>    tn = matrix[MATRIX_TN_INDEX]<br>    fn = matrix[MATRIX_FN_INDEX]<br>    return (tp + tn) / (tp + fp + tn + fn)<br><br>print(accuracy_score(y_true, y_pred))  #0.52<br>print(metrics.accuracy_score(y_true, y_pred))  #0.52</pre><h4><strong>Limitation ofÂ Accuracy</strong></h4><p>The accuracy rate can evluate the total correct rate, but accuracy could be misled in imbalanced dataset. For example, detecting spam in emails. Assume 95% of emails are spam, a model simply predict all of emails are spam, the accuracy of this model is 95%, which make no sense. Accuracy is not valid for imbalanced dataset.</p><h3><strong>Precision andÂ Recall</strong></h3><h4><strong>Precision</strong></h4><p><strong>Precision</strong> (also called positive predictive value) represents the number of items correctly predicted as positive(TP) divided by the total number of items predicted as positive:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/677/1*qSo58VUIMLt3Yh3orIQfFQ.png\" /></figure><p>The total number of items predicted as positive is the sum of true positives(TP) and false positives(FP). Precision mathmaticly definedÂ as:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/677/1*PPclrOn1eF1IcJDzV8dNzA.png\" /></figure><h4><strong>Recall</strong></h4><p><strong>Recall</strong> (also known as sensitivity) represents the number of true positives divided by the total number of items that actually belong to the positiveÂ class.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/677/1*lryGgGmqtlePkIgxSIA3rA.png\" /></figure><p>The total number of items that actually belong to the positive class is the sum of true positives(TP) and false negatives(FN). Recall mathmaticly definedÂ as:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/677/1*nncPuOe2L12HImryaKl-Mw.png\" /></figure><h4>Compute Precision and Recall inÂ Python</h4><pre>def precision_score(y_true, y_pred):<br>    matrix = confusion_matrix(y_true, y_pred)<br>    tp = matrix[MATRIX_TP_INDEX]<br>    fp = matrix[MATRIX_FP_INDEX]<br>    return tp / (tp + fp)<br><br>print(precision_score(y_true, y_pred))  #0.5116279069767442<br>print(metrics.precision_score(y_true, y_pred))  #0.5116279069767442<br><br>def recall_score(y_true, y_pred):<br>    matrix = confusion_matrix(y_true, y_pred)<br>    tp = matrix[MATRIX_TP_INDEX]<br>    fn = matrix[MATRIX_FN_INDEX]<br>    return tp / (tp + fn)<br><br>print(recall_score(y_true, y_pred)) #0.4489795918367347<br>print(metrics.recall_score(y_true, y_pred)) #0.4489795918367347</pre><h4><strong>Precision vs.Â Recall</strong></h4><p>Precision and recall are not particularly useful metrics when used in isolation. It is possible to have perfect recall by retrieving every single item. Likewise, it is possible to have near-perfect precision by selecting only a very small number of extremely likely items. We need to take both precision and recall into account. Ideally, we want to maximize both precision and recallÂ metrics.</p><p>However, there is an inverse relationship between precision and recall, where it is possible to increase one at the cost of reducing the other. How to balance between precision and recall is theÂ dilemma.</p><p>A measure combines precision and recall, symmetrically represents both measures in one metric is F-measure, also calledÂ F-score.</p><h3><strong>F-score/F-measure</strong></h3><p>The F-score combines precision and recall using their harmonic mean, and maximizing the F score implies simultaneously maximizing both precision and recall. There are two different variations of F-score: F1 score and FÎ²Â Score.</p><h4><strong>F1 Score</strong></h4><p>F1 score is the traditional F-measure or balanced F-score. It is the harmonic mean of the precision and recall. F1 score defined asÂ follows:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/677/1*QM3HjjmEmddOqKYYexKsiw.png\" /></figure><p>By replacing the expressions for precision and recall scores in the equation above, the F1 score can also be written asÂ follows:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/677/1*u2SLUm-wsP4UgAV8OerCng.png\" /></figure><p>The highest possible value of an F-score is 1.0, indicating perfect precision and recall, and the lowest possible value is 0, if either precision or recall areÂ zero.</p><p>The more generic F-score applies additional weights Î² is FÎ² score. We will discuss it later. Before that, letâ€™s see how to compute F1 score inÂ Python.</p><h4>Compute F1 Score inÂ Python</h4><pre>def f1_score(y_true, y_pred):<br>    matrix = confusion_matrix(y_true, y_pred)<br>    tp = matrix[MATRIX_TP_INDEX]<br>    fp = matrix[MATRIX_FP_INDEX]<br>    fn = matrix[MATRIX_FN_INDEX]<br>    return 2 * tp / (2 * tp + fp + fn)<br><br>print(f1_score(y_true, y_pred)) #0.4782608695652174<br>print(metrics.f1_score(y_true, y_pred)) #0.47826086956521735</pre><h4><strong>FÎ² Score</strong></h4><p>FÎ² Score is a general F score. It uses a positive real factor Î², where recall is considered</p><p>Î² times as important as precision. FÎ² Score defined asÂ follows:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/677/1*2OsIhnny3N_vCFMiYiayTg.png\" /></figure><p>There are two other commonly used FÎ² measures:</p><ul><li>F2 measureâ€Šâ€”â€Šweights recall higher than precision</li><li>F0.5 measureâ€Šâ€”â€Šputs more emphasis on precision thanÂ recall.</li></ul><p>The FÎ² score is useful when we want to prioritize one measure while preserving results from the otherÂ measure.</p><p>For example, the COVID-19 detection, False Negative results are detrimental (Since a COVID positive patient is diagnosed as COVID negative, leading to the spread of the disease). In this case, the F2 measure is more useful to minimize the False Negatives while also trying to keep the precision score as high as possible. however, for general medical diagnosis, a false positive test can lead to unnecessary treatment and expenses, it is necessary to reduce the False Positives, with a lower Î² value (like an F0.5Â score).</p><h3><strong>Conclusion</strong></h3><p>Accuracy works good for balanced dataset, but is not valid for imbalanced dataset.</p><p>Precision and recall also could be deceived when used in isolation, it is quite tricky to balanceÂ both.</p><p>F1 score offers a more balanced assessment through the harmonic mean of precision and recall. It is a much more comprehensive evaluation metric in comparison with precision andÂ recall.</p><p>Furthermore, FÎ² score, allow controlling the F score metric based on the problem at hand by prioritizing the minimization of either false positive or false negativeÂ losses.</p><h3>Jason ğŸš€</h3><p><em>Thank you for reading until the end. Before youÂ go:</em></p><p>ğŸ‘ Please <strong><em>clap</em></strong> and <strong><em>follow</em></strong>Â me</p><p>ğŸ“¬ <a href=\"https://medium.com/@xuzhusheng/subscribe\">Subscribe</a> to my Medium newsletter for emailÂ updates!</p><p>â˜• or just <a href=\"https://www.buymeacoffee.com/jason.xu\">buy me aÂ coffee</a></p><h3>In Plain EnglishÂ ğŸš€</h3><p><em>Thank you for being a part of the </em><a href=\"https://plainenglish.io\"><strong><em>In Plain English</em></strong></a><em> community! Before youÂ go:</em></p><ul><li>Be sure to <strong>clap</strong> and <strong>follow</strong> the writerÂ ï¸ğŸ‘<strong>ï¸ï¸</strong></li><li>Follow us: <a href=\"https://twitter.com/inPlainEngHQ\"><strong>X</strong></a><strong> | </strong><a href=\"https://www.linkedin.com/company/inplainenglish/\"><strong>LinkedIn</strong></a><strong> | </strong><a href=\"https://www.youtube.com/channel/UCtipWUghju290NWcn8jhyAw\"><strong>YouTube</strong></a><strong> | </strong><a href=\"https://discord.gg/in-plain-english-709094664682340443\"><strong>Discord</strong></a><strong> | </strong><a href=\"https://newsletter.plainenglish.io/\"><strong>Newsletter</strong></a></li><li>Visit our other platforms: <a href=\"https://stackademic.com/\"><strong>Stackademic</strong></a><strong> | </strong><a href=\"https://cofeed.app/\"><strong>CoFeed</strong></a><strong> | </strong><a href=\"https://venturemagazine.net/\"><strong>Venture</strong></a><strong> |Â </strong><a href=\"https://blog.cubed.run\"><strong>Cubed</strong></a></li><li>More content at <a href=\"https://plainenglish.io\"><strong>PlainEnglish.io</strong></a></li></ul><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=614e00f5c15c\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://python.plainenglish.io/precision-recall-and-f-score-614e00f5c15c\">Accuracy, Precision, Recall and F-score in Machine Learning</a> was originally published in <a href=\"https://python.plainenglish.io\">Python in Plain English</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>","media":{}},{"id":"https://medium.com/p/89c14afb2f03","title":"Constructs Bounding Volume Hierarchy(BVH) with Surface Area Heuristic(SAH) in Python","link":"https://python.plainenglish.io/constructs-bounding-volume-hierarchy-bvh-with-surface-area-heuristic-sah-in-python-89c14afb2f03?source=rss-41bd992616fb------2","author":"Jason","published":1710414107000,"created":1710414107000,"category":["python","computer-graphics","3d","numpy","algorithms"],"content":"<h4>algorithm</h4><h4>A step by step guide go build Bounding Volume Hierarchy(BVH) with Surface Area Heuristic(SAH) inÂ Python</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*t76pREm7YKp9PbBg\" /><figcaption>Photo by <a href=\"https://unsplash.com/@dkoi?utm_source=medium&amp;utm_medium=referral\">D koi</a> onÂ <a href=\"https://unsplash.com?utm_source=medium&amp;utm_medium=referral\">Unsplash</a></figcaption></figure><p><strong>Bounding volume hierarchy</strong> (<strong>BVH</strong>) is an advanced data structure widely used in computer graphics, especially in ray tracing algorithms. It is uesed to effectively organize geometric data, such as polygons or triangles that compose a 3D model, such as 3d-tiles. All geometric objects, which form the leaf nodes of the tree, are wrapped in boundingÂ volumes.</p><p>In this article, we are going to explore how to construct bounding volume hierarchy (BVH) with Surface Area Heuristic(SAH).</p><h3><strong>Bounding Volume Hierarchy</strong> Data Structure</h3><p>Bounding volume hierarchy (BVH) is a tree structure on a set of geometric objects.</p><ul><li>All geometric objects, which form the leaf nodes of the tree, are wrapped in boundingÂ volumes.</li><li>These nodes are then grouped as small sets and enclosed within larger bounding volumes. These, in turn, are also grouped and enclosed within other larger bounding volumes in a recursive fashion, forming the hierarchy of theÂ tree.</li><li>A bounding volume can take various forms, such as a sphere, a box (AABBâ€Šâ€”â€ŠAxis Aligned Bounding Box), or an oriented bounding box (OBB), depending on the applicationâ€™s specific requirements.</li></ul><p>Here is a example of a bounding volume hierarchy using rectangles as bounding volumes from <a href=\"https://en.wikipedia.org/\">wikipedia</a>.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/534/1*oFx736LEYo1tuK4gji3fCg.png\" /></figure><h3>Surface Area Heuristic</h3><p>A common method for constructing a high-quality BVH is using the Surface Area Heuristic. The idea of using SAH is based on two main principles:</p><ol><li>Minimize the probability of intersection for BHVÂ nodes</li><li>The probability of intersection of a node is proportional to its surface area, under certain conditions.</li></ol><h4>SAH Formula</h4><p>Here is the SAHÂ formula</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/505/0*9xrJTx8W-9owWJWh\" /></figure><ul><li><em>C(A, B)â€Šâ€”â€Šthe cost for splitting a node into volumes A andÂ B</em></li><li><em>t_traversalâ€Šâ€”â€Šthe time to traverse an interiorÂ node</em></li><li><em>P(A) and P(B)â€Šâ€”â€Šthe probabilities that the ray passes through the volumes A andÂ B</em></li><li><em>N_A and N_Bâ€Šâ€”â€Šare the number of triangles in volumes A andÂ B</em></li><li><em>a_i and b_iâ€Šâ€”â€Šare the ith triangle in volumes A andÂ B</em></li><li><em>t_intersect - is the cost for one ray-triangle intersection.</em></li></ul><p>We can compute P(A) and P(B)Â as:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/174/0*l1SaElXNgQ_y6jw_\" /></figure><ul><li><em>Câ€Šâ€”â€Šthe parent node of A andÂ B</em></li><li><em>S_A, S_B, and S_Câ€Šâ€”â€Šthe surface areas of volumes A, B and C (We can simply compute the surface area of a node by summing all faces of aÂ node)</em></li><li><em>P(A|C) and P(B|C)â€Šâ€”â€Šthe conditional probability that a random ray passing through C will also pass through A or B, given that A or B is a convex volume in another convex volumeÂ C.</em></li></ul><p>Replace P(A) and P(B) at the SAH formula, weÂ get:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/473/0*2I9CU-aGMMgXfAQX\" /></figure><p>Since our goal is find the minimal cost, the actual cost value does not matter. Assume t_traversal as the constant 0, and t_intersect as the constant 1, we get a simplify form of SAHÂ formulaï¼š</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/234/0*7oJo7Vz07tPs3If-\" /></figure><p>Here is the scripts to calculate SAHÂ cost:</p><pre>def sah_cost(surface_area, count):<br>    return surface_area * count</pre><h3>Constructing BVH withÂ SAH</h3><h4>Preparing Data</h4><p>we generates 10 triangles as testing data for construction BVH as followedÂ figure:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/552/1*qfKAzgmjDCCFpS7LvpadHQ.png\" /></figure><p>Here is the generation scripts:</p><pre>import numpy as np<br><br>np.random.seed(202403)<br><br>MIN_ANGLE = np.pi / 6<br>MAX_ANGLE = np.pi / 2<br><br>def make_triangle(max_length, max_translation):<br>    edge_a, edge_b = np.random.uniform(1, max_length, size = 2)<br>    alpha = np.random.uniform(0, np.pi * 2)<br>    beta = alpha + np.random.uniform(MIN_ANGLE, MAX_ANGLE)<br>    point_a = edge_a * np.cos(alpha), edge_a * np.sin(alpha)<br>    point_b = edge_b * np.cos(beta), edge_a * np.sin(beta)<br>    points = np.array([(0, 0), point_a, point_b])<br>    translation = np.random.uniform(max_length, max_translation, size=(1, 2))<br>    return points + translation<br><br>TRINGLES_NUM = 10<br>triangles = [make_triangle(3, 27) for _ in range(TRINGLES_NUM)]</pre><h4>Bounding Volumeâ€Šâ€”â€ŠAABB</h4><p>We use AABB(Axis Aligned Bounding Box) to wrap geometries. An minimal AABB class must have below fields andÂ methods:</p><p><strong>Fields:</strong></p><ul><li><em>centroidâ€Šâ€”â€Šused to sort nodes before spliting nodes to twoÂ groups</em></li><li><em>surface_areaâ€Šâ€”â€Šcalculated surface area, used to calculate SAHÂ cost</em></li></ul><p><strong>Methods:</strong></p><ul><li><em>unionâ€Šâ€”â€Šcalcualte the new bounding volume when mergingÂ boxes</em></li></ul><p>Here is the scripts for boxÂ class:</p><pre>class Box2:<br>    def __init__(self, min=[np.inf] * 2, max = [-np.inf] * 2) -&gt; None:<br>        self.__min = np.array(min)<br>        self.__max = np.array(max)<br>        <br>    @classmethod<br>    def from_geometries(cls, geometries):<br>        return cls(geometries.min(0), geometries.max(0))<br>    <br>    @property<br>    def anchor(self):<br>        return self.__min<br>    <br>    @property<br>    def size(self):<br>        return self.__max - self.__min<br>    <br>    @property<br>    def centroid(self):<br>        return ((self.__max + self.__min) / 2).tolist()<br>    <br>    @property<br>    def min(self):<br>        return self.__min<br><br>    @property<br>    def max(self):<br>        return self.__max<br>    <br>    def union(self, box):<br>        self.__max = np.maximum(self.__max, box.max)<br>        self.__min = np.minimum(self.__min, box.min)<br>        return self<br>    <br>    @property<br>    def surface_area(self):<br>        width, height = self.size<br>        return width * height</pre><h4>BVH Node</h4><p>A BVH node is tree node with geometries data and bounding volume. Here is theÂ scrpts:</p><pre>class Node:<br>    def __init__(self, geometries = None) -&gt; None:<br>        self.geometries = geometries<br>        self.left = None<br>        self.right = None<br>    <br>    def add_children(self, left = None, right = None):<br>        self.left = left<br>        self.right = right<br>        <br>        return self<br>        <br>    @property    <br>    def box(self):<br>        if self.geometries is not None:<br>            return Box2.from_geometries(self.geometries)<br>        <br>        box = Box2()<br>        if self.left:<br>            box.union(self.left.box)<br>            <br>        if self.right:<br>            box.union(self.right.box)<br>            <br>        return box<br>        </pre><h4>Splitting Nodes at Minimal Cost on OneÂ Axis</h4><p>We find the split with minimal cost in 3Â steps:</p><ol><li><em>Sorts nodes by the controid of boundingÂ box</em></li><li><em>Calculates SAH cost for every possibleÂ split</em></li><li><em>Finds the split with minimalÂ cost</em></li></ol><p>Here is theÂ scripts:</p><pre>def calculate_split_costs(nodes):<br>    box = Box2()<br>    costs = []<br>    for i, node in enumerate(nodes, 1):<br>        box = box.union(node.box)<br>        costs.append(sah_cost(box.surface_area, i))<br><br>    return costs[:-1]<br><br>def find_min_cost_split(nodes, axis):    <br>    sorted_nodes = sorted(nodes, key=lambda node: node.box.centroid[axis])<br>    left_costs = calculate_split_costs(sorted_nodes)<br>    <br>    right_costs = reversed(calculate_split_costs(list(reversed(sorted_nodes))))<br>    costs = list(<br>        map(lambda l, r: l + r, left_costs, right_costs))<br>    min_cost = min(costs)<br>    split_index = np.argmin(costs) + 1<br>    return min_cost, split_index</pre><h4>Building BVHÂ Tree</h4><p>The last is actually build the tree. The building can be done inÂ steps:</p><ol><li><em>Return the node if there is only one node left; Return an interior with two nodes as children if there are two nodesÂ left</em></li><li><em>Finds the axis and split index with minimalÂ cost</em></li><li><em>Sorts the nodes by centroid of bounding box on theÂ axis</em></li><li><em>Splits the nodes to twoÂ group</em></li><li><em>Repeats steps 1â€“4 recursively for both splited group until there are less then 3Â nodes</em></li></ol><p>Letâ€™s show an animation of splitting process:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/640/1*B1uyiDUZoF2ubtXdrJuEDg.gif\" /></figure><p>Here is theÂ scripts:</p><pre>DIMENSIONS = 2<br><br>def build_bvh(nodes):<br>    if len(nodes) == 1:<br>        return nodes[0]<br>    <br>    if len(nodes) == 2:<br>        return Node().add_children(*nodes)<br>    <br>    min_costs_splits = [find_min_cost_split(nodes, axis) for axis in range(DIMENSIONS)]<br>    axis, _ = np.argmin(min_splits, 0, keepdims=False)<br>    _ , split_index = min_splits[axis]<br>    sorted_nodes = sorted(nodes, key=lambda node: node.box.centroid[axis])<br>    return Node().add_children(left = build_bvh(sorted_nodes[:split_index]), right = build_bvh(sorted_nodes[split_index:]))<br><br>nodes = list(map(Node, triangles))<br>tree = build_bvh(nodes)</pre><h3>What About 3 Dimensions?</h3><p>Weâ€™ve covered building BVH for 2 dimensions. For 3 dimensions, we need only little changes for calculating the surface area. We create a class Box3 forÂ this.</p><pre>class Box3(Box2):<br>    <br>    @property<br>    def surface_area(self):<br>        a, b, c = self.size<br>        return a * b + b * c + c * a</pre><p>The last thing to do is update the constant DIMENSIONS to 3 and replace Box2 withÂ Box3.</p><h3>Jason ğŸš€</h3><p><em>Thank you for reading until the end. Before youÂ go:</em></p><p>ğŸ‘ Please <strong><em>Clap</em></strong> and <strong><em>follow</em></strong>Â me</p><p>ğŸ“¬ <a href=\"https://medium.com/@xuzhusheng/subscribe\">Subscribe</a> to my Medium newsletter for emailÂ updates!</p><p>â˜• or just <a href=\"https://www.buymeacoffee.com/jason.xu\">buy me aÂ coffee</a></p><h3>In Plain EnglishÂ ğŸš€</h3><p><em>Thank you for being a part of the </em><a href=\"https://plainenglish.io\"><strong><em>In Plain English</em></strong></a><em> community! Before youÂ go:</em></p><ul><li>Be sure to <strong>clap</strong> and <strong>follow</strong> the writerÂ ï¸ğŸ‘<strong>ï¸ï¸</strong></li><li>Follow us: <a href=\"https://twitter.com/inPlainEngHQ\"><strong>X</strong></a><strong> | </strong><a href=\"https://www.linkedin.com/company/inplainenglish/\"><strong>LinkedIn</strong></a><strong> | </strong><a href=\"https://www.youtube.com/channel/UCtipWUghju290NWcn8jhyAw\"><strong>YouTube</strong></a><strong> | </strong><a href=\"https://discord.gg/in-plain-english-709094664682340443\"><strong>Discord</strong></a><strong> | </strong><a href=\"https://newsletter.plainenglish.io/\"><strong>Newsletter</strong></a></li><li>Visit our other platforms: <a href=\"https://stackademic.com/\"><strong>Stackademic</strong></a><strong> | </strong><a href=\"https://cofeed.app/\"><strong>CoFeed</strong></a><strong> | </strong><a href=\"https://venturemagazine.net/\"><strong>Venture</strong></a><strong> |Â </strong><a href=\"https://blog.cubed.run\"><strong>Cubed</strong></a></li><li>More content at <a href=\"https://plainenglish.io\"><strong>PlainEnglish.io</strong></a></li></ul><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=89c14afb2f03\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://python.plainenglish.io/constructs-bounding-volume-hierarchy-bvh-with-surface-area-heuristic-sah-in-python-89c14afb2f03\">Constructs Bounding Volume Hierarchy(BVH) with Surface Area Heuristic(SAH) in Python</a> was originally published in <a href=\"https://python.plainenglish.io\">Python in Plain English</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>","enclosures":[],"content_encoded":"<h4>algorithm</h4><h4>A step by step guide go build Bounding Volume Hierarchy(BVH) with Surface Area Heuristic(SAH) inÂ Python</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*t76pREm7YKp9PbBg\" /><figcaption>Photo by <a href=\"https://unsplash.com/@dkoi?utm_source=medium&amp;utm_medium=referral\">D koi</a> onÂ <a href=\"https://unsplash.com?utm_source=medium&amp;utm_medium=referral\">Unsplash</a></figcaption></figure><p><strong>Bounding volume hierarchy</strong> (<strong>BVH</strong>) is an advanced data structure widely used in computer graphics, especially in ray tracing algorithms. It is uesed to effectively organize geometric data, such as polygons or triangles that compose a 3D model, such as 3d-tiles. All geometric objects, which form the leaf nodes of the tree, are wrapped in boundingÂ volumes.</p><p>In this article, we are going to explore how to construct bounding volume hierarchy (BVH) with Surface Area Heuristic(SAH).</p><h3><strong>Bounding Volume Hierarchy</strong> Data Structure</h3><p>Bounding volume hierarchy (BVH) is a tree structure on a set of geometric objects.</p><ul><li>All geometric objects, which form the leaf nodes of the tree, are wrapped in boundingÂ volumes.</li><li>These nodes are then grouped as small sets and enclosed within larger bounding volumes. These, in turn, are also grouped and enclosed within other larger bounding volumes in a recursive fashion, forming the hierarchy of theÂ tree.</li><li>A bounding volume can take various forms, such as a sphere, a box (AABBâ€Šâ€”â€ŠAxis Aligned Bounding Box), or an oriented bounding box (OBB), depending on the applicationâ€™s specific requirements.</li></ul><p>Here is a example of a bounding volume hierarchy using rectangles as bounding volumes from <a href=\"https://en.wikipedia.org/\">wikipedia</a>.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/534/1*oFx736LEYo1tuK4gji3fCg.png\" /></figure><h3>Surface Area Heuristic</h3><p>A common method for constructing a high-quality BVH is using the Surface Area Heuristic. The idea of using SAH is based on two main principles:</p><ol><li>Minimize the probability of intersection for BHVÂ nodes</li><li>The probability of intersection of a node is proportional to its surface area, under certain conditions.</li></ol><h4>SAH Formula</h4><p>Here is the SAHÂ formula</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/505/0*9xrJTx8W-9owWJWh\" /></figure><ul><li><em>C(A, B)â€Šâ€”â€Šthe cost for splitting a node into volumes A andÂ B</em></li><li><em>t_traversalâ€Šâ€”â€Šthe time to traverse an interiorÂ node</em></li><li><em>P(A) and P(B)â€Šâ€”â€Šthe probabilities that the ray passes through the volumes A andÂ B</em></li><li><em>N_A and N_Bâ€Šâ€”â€Šare the number of triangles in volumes A andÂ B</em></li><li><em>a_i and b_iâ€Šâ€”â€Šare the ith triangle in volumes A andÂ B</em></li><li><em>t_intersect - is the cost for one ray-triangle intersection.</em></li></ul><p>We can compute P(A) and P(B)Â as:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/174/0*l1SaElXNgQ_y6jw_\" /></figure><ul><li><em>Câ€Šâ€”â€Šthe parent node of A andÂ B</em></li><li><em>S_A, S_B, and S_Câ€Šâ€”â€Šthe surface areas of volumes A, B and C (We can simply compute the surface area of a node by summing all faces of aÂ node)</em></li><li><em>P(A|C) and P(B|C)â€Šâ€”â€Šthe conditional probability that a random ray passing through C will also pass through A or B, given that A or B is a convex volume in another convex volumeÂ C.</em></li></ul><p>Replace P(A) and P(B) at the SAH formula, weÂ get:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/473/0*2I9CU-aGMMgXfAQX\" /></figure><p>Since our goal is find the minimal cost, the actual cost value does not matter. Assume t_traversal as the constant 0, and t_intersect as the constant 1, we get a simplify form of SAHÂ formulaï¼š</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/234/0*7oJo7Vz07tPs3If-\" /></figure><p>Here is the scripts to calculate SAHÂ cost:</p><pre>def sah_cost(surface_area, count):<br>    return surface_area * count</pre><h3>Constructing BVH withÂ SAH</h3><h4>Preparing Data</h4><p>we generates 10 triangles as testing data for construction BVH as followedÂ figure:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/552/1*qfKAzgmjDCCFpS7LvpadHQ.png\" /></figure><p>Here is the generation scripts:</p><pre>import numpy as np<br><br>np.random.seed(202403)<br><br>MIN_ANGLE = np.pi / 6<br>MAX_ANGLE = np.pi / 2<br><br>def make_triangle(max_length, max_translation):<br>    edge_a, edge_b = np.random.uniform(1, max_length, size = 2)<br>    alpha = np.random.uniform(0, np.pi * 2)<br>    beta = alpha + np.random.uniform(MIN_ANGLE, MAX_ANGLE)<br>    point_a = edge_a * np.cos(alpha), edge_a * np.sin(alpha)<br>    point_b = edge_b * np.cos(beta), edge_a * np.sin(beta)<br>    points = np.array([(0, 0), point_a, point_b])<br>    translation = np.random.uniform(max_length, max_translation, size=(1, 2))<br>    return points + translation<br><br>TRINGLES_NUM = 10<br>triangles = [make_triangle(3, 27) for _ in range(TRINGLES_NUM)]</pre><h4>Bounding Volumeâ€Šâ€”â€ŠAABB</h4><p>We use AABB(Axis Aligned Bounding Box) to wrap geometries. An minimal AABB class must have below fields andÂ methods:</p><p><strong>Fields:</strong></p><ul><li><em>centroidâ€Šâ€”â€Šused to sort nodes before spliting nodes to twoÂ groups</em></li><li><em>surface_areaâ€Šâ€”â€Šcalculated surface area, used to calculate SAHÂ cost</em></li></ul><p><strong>Methods:</strong></p><ul><li><em>unionâ€Šâ€”â€Šcalcualte the new bounding volume when mergingÂ boxes</em></li></ul><p>Here is the scripts for boxÂ class:</p><pre>class Box2:<br>    def __init__(self, min=[np.inf] * 2, max = [-np.inf] * 2) -&gt; None:<br>        self.__min = np.array(min)<br>        self.__max = np.array(max)<br>        <br>    @classmethod<br>    def from_geometries(cls, geometries):<br>        return cls(geometries.min(0), geometries.max(0))<br>    <br>    @property<br>    def anchor(self):<br>        return self.__min<br>    <br>    @property<br>    def size(self):<br>        return self.__max - self.__min<br>    <br>    @property<br>    def centroid(self):<br>        return ((self.__max + self.__min) / 2).tolist()<br>    <br>    @property<br>    def min(self):<br>        return self.__min<br><br>    @property<br>    def max(self):<br>        return self.__max<br>    <br>    def union(self, box):<br>        self.__max = np.maximum(self.__max, box.max)<br>        self.__min = np.minimum(self.__min, box.min)<br>        return self<br>    <br>    @property<br>    def surface_area(self):<br>        width, height = self.size<br>        return width * height</pre><h4>BVH Node</h4><p>A BVH node is tree node with geometries data and bounding volume. Here is theÂ scrpts:</p><pre>class Node:<br>    def __init__(self, geometries = None) -&gt; None:<br>        self.geometries = geometries<br>        self.left = None<br>        self.right = None<br>    <br>    def add_children(self, left = None, right = None):<br>        self.left = left<br>        self.right = right<br>        <br>        return self<br>        <br>    @property    <br>    def box(self):<br>        if self.geometries is not None:<br>            return Box2.from_geometries(self.geometries)<br>        <br>        box = Box2()<br>        if self.left:<br>            box.union(self.left.box)<br>            <br>        if self.right:<br>            box.union(self.right.box)<br>            <br>        return box<br>        </pre><h4>Splitting Nodes at Minimal Cost on OneÂ Axis</h4><p>We find the split with minimal cost in 3Â steps:</p><ol><li><em>Sorts nodes by the controid of boundingÂ box</em></li><li><em>Calculates SAH cost for every possibleÂ split</em></li><li><em>Finds the split with minimalÂ cost</em></li></ol><p>Here is theÂ scripts:</p><pre>def calculate_split_costs(nodes):<br>    box = Box2()<br>    costs = []<br>    for i, node in enumerate(nodes, 1):<br>        box = box.union(node.box)<br>        costs.append(sah_cost(box.surface_area, i))<br><br>    return costs[:-1]<br><br>def find_min_cost_split(nodes, axis):    <br>    sorted_nodes = sorted(nodes, key=lambda node: node.box.centroid[axis])<br>    left_costs = calculate_split_costs(sorted_nodes)<br>    <br>    right_costs = reversed(calculate_split_costs(list(reversed(sorted_nodes))))<br>    costs = list(<br>        map(lambda l, r: l + r, left_costs, right_costs))<br>    min_cost = min(costs)<br>    split_index = np.argmin(costs) + 1<br>    return min_cost, split_index</pre><h4>Building BVHÂ Tree</h4><p>The last is actually build the tree. The building can be done inÂ steps:</p><ol><li><em>Return the node if there is only one node left; Return an interior with two nodes as children if there are two nodesÂ left</em></li><li><em>Finds the axis and split index with minimalÂ cost</em></li><li><em>Sorts the nodes by centroid of bounding box on theÂ axis</em></li><li><em>Splits the nodes to twoÂ group</em></li><li><em>Repeats steps 1â€“4 recursively for both splited group until there are less then 3Â nodes</em></li></ol><p>Letâ€™s show an animation of splitting process:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/640/1*B1uyiDUZoF2ubtXdrJuEDg.gif\" /></figure><p>Here is theÂ scripts:</p><pre>DIMENSIONS = 2<br><br>def build_bvh(nodes):<br>    if len(nodes) == 1:<br>        return nodes[0]<br>    <br>    if len(nodes) == 2:<br>        return Node().add_children(*nodes)<br>    <br>    min_costs_splits = [find_min_cost_split(nodes, axis) for axis in range(DIMENSIONS)]<br>    axis, _ = np.argmin(min_splits, 0, keepdims=False)<br>    _ , split_index = min_splits[axis]<br>    sorted_nodes = sorted(nodes, key=lambda node: node.box.centroid[axis])<br>    return Node().add_children(left = build_bvh(sorted_nodes[:split_index]), right = build_bvh(sorted_nodes[split_index:]))<br><br>nodes = list(map(Node, triangles))<br>tree = build_bvh(nodes)</pre><h3>What About 3 Dimensions?</h3><p>Weâ€™ve covered building BVH for 2 dimensions. For 3 dimensions, we need only little changes for calculating the surface area. We create a class Box3 forÂ this.</p><pre>class Box3(Box2):<br>    <br>    @property<br>    def surface_area(self):<br>        a, b, c = self.size<br>        return a * b + b * c + c * a</pre><p>The last thing to do is update the constant DIMENSIONS to 3 and replace Box2 withÂ Box3.</p><h3>Jason ğŸš€</h3><p><em>Thank you for reading until the end. Before youÂ go:</em></p><p>ğŸ‘ Please <strong><em>Clap</em></strong> and <strong><em>follow</em></strong>Â me</p><p>ğŸ“¬ <a href=\"https://medium.com/@xuzhusheng/subscribe\">Subscribe</a> to my Medium newsletter for emailÂ updates!</p><p>â˜• or just <a href=\"https://www.buymeacoffee.com/jason.xu\">buy me aÂ coffee</a></p><h3>In Plain EnglishÂ ğŸš€</h3><p><em>Thank you for being a part of the </em><a href=\"https://plainenglish.io\"><strong><em>In Plain English</em></strong></a><em> community! Before youÂ go:</em></p><ul><li>Be sure to <strong>clap</strong> and <strong>follow</strong> the writerÂ ï¸ğŸ‘<strong>ï¸ï¸</strong></li><li>Follow us: <a href=\"https://twitter.com/inPlainEngHQ\"><strong>X</strong></a><strong> | </strong><a href=\"https://www.linkedin.com/company/inplainenglish/\"><strong>LinkedIn</strong></a><strong> | </strong><a href=\"https://www.youtube.com/channel/UCtipWUghju290NWcn8jhyAw\"><strong>YouTube</strong></a><strong> | </strong><a href=\"https://discord.gg/in-plain-english-709094664682340443\"><strong>Discord</strong></a><strong> | </strong><a href=\"https://newsletter.plainenglish.io/\"><strong>Newsletter</strong></a></li><li>Visit our other platforms: <a href=\"https://stackademic.com/\"><strong>Stackademic</strong></a><strong> | </strong><a href=\"https://cofeed.app/\"><strong>CoFeed</strong></a><strong> | </strong><a href=\"https://venturemagazine.net/\"><strong>Venture</strong></a><strong> |Â </strong><a href=\"https://blog.cubed.run\"><strong>Cubed</strong></a></li><li>More content at <a href=\"https://plainenglish.io\"><strong>PlainEnglish.io</strong></a></li></ul><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=89c14afb2f03\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://python.plainenglish.io/constructs-bounding-volume-hierarchy-bvh-with-surface-area-heuristic-sah-in-python-89c14afb2f03\">Constructs Bounding Volume Hierarchy(BVH) with Surface Area Heuristic(SAH) in Python</a> was originally published in <a href=\"https://python.plainenglish.io\">Python in Plain English</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>","media":{}},{"id":"https://medium.com/p/57f92058403c","title":"3D Affine Transformation Matrices Implementation with NumPy","link":"https://python.plainenglish.io/3d-affine-transformation-matrices-implementation-with-numpy-57f92058403c?source=rss-41bd992616fb------2","author":"Jason","published":1709524867000,"created":1709524867000,"category":["computer-graphics","3d","mathematics","numpy","python"],"content":"<h4>3D Affine Transformation</h4><h4>Explores 3D affine transformation matrices and implements it withÂ NumPy</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*YhbgLSfLA9RgoDNE\" /><figcaption>Photo by <a href=\"https://unsplash.com/@mariolagr?utm_source=medium&amp;utm_medium=referral\">MARIOLA GROBELSKA</a> onÂ <a href=\"https://unsplash.com?utm_source=medium&amp;utm_medium=referral\">Unsplash</a></figcaption></figure><p>In computer graphics, afï¬ne transformation is the most general transformations model. Any combination of translation, rotations, scalings/reï¬‚ections and shears can be combined in a single 4 by 4 afï¬ne transformation matrix.</p><p>In this article, we are going to explore common 3d affine transformation matrices and implement it withÂ NumPy.</p><h3><strong>3D Affine Transformation Matrices</strong></h3><p>Here is a afï¬ne transformation matrix that transforms point (or vector) x to point (or vector)Â y.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/217/0*RcVfjT1NLncBvUDl\" /></figure><p>The upper-left 3 Ã— 3 sub-matrix of the matrix represents a rotation transform (include scales and shears). The last column of the matrix represents a translation. When used as a coordinate system, the upper-left 3 x 3 sub-matrix represents an orientation in space while the last column vector represents a position in space. The transformation of point x to point y is obtained by performing the matrix-vector multiplication Mx:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/61/0*BOHJ7Z2VcigfKx9I\" /></figure><p>The transformation matrix uses homogeneous coordinates, which allow to distinguish between points and vectors. Vectors have a direction and magnitude whereas points are positions. Points and vectors are both represented as mathematical column vectors in homogeneous coordinates. The only difference is points have a 1 in the fourth position whereas vectors have a zero at this position, which removes translation operations (4th column) forÂ vectors.</p><p>The transformation of point x to point y using homogeneous matrix is writtenÂ as:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/112/0*5GRNCeZyUUCvgjum\" /></figure><p><strong>Implements matrix withÂ NumPy</strong></p><p>Matrix is easy to be Implemented with NumPy. Letâ€™s see how to construct a matrix withÂ NumPy:</p><pre>import numpy as np<br><br>elements = [<br>    [1,2,3,4],<br>    [4,6,7,8],<br>    [9,10,11,12],<br>    [13,14,15,16]<br>]<br>matrix = np.array(elements)<br>print(matrix)<br># [[ 1  2  3  4]<br>#  [ 4  6  7  8]<br>#  [ 9 10 11 12]<br>#  [13 14 15 16]]</pre><p>Since affine transformation matrix is used to represent objectâ€™s rotaion and translation in 3D models, serialization and deserialization is common scenario. Here is code snippets for constructing matrix from list and converting it to aÂ list:</p><pre>import numpy as np<br><br># constructs from list<br>elements = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]<br>matrix = np.array(elements)<br>matrix = matrix.reshape(4,4)<br>print(matrix)<br># [[ 1  2  3  4]<br>#  [ 5  6  7  8]<br>#  [ 9 10 11 12]<br>#  [13 14 15 16]]<br><br># converts to list<br>print(matrix.reshape(-1).tolist())<br># [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]</pre><h3>Translation</h3><p>A translation operation will translate a point(or an object) from an initial position to a new position based on a linear shift. Here equation of translate a point (x, y, z) to point (x&#39;, y&#39;,Â z&#39;)</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/83/0*v6bX_KcpXD19QEsW\" /></figure><p>And the transformation matrixÂ form:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/297/0*9vAyfWIAClT_y9yn\" /></figure><p><strong>Implements translation matrix withÂ NumPy</strong></p><pre>def translation_matrix(tx, ty, tz):<br>    matrix = [<br>        [1,0,0,tx],<br>        [0,1,0,ty],<br>        [0,0,1,tz],<br>        [0,0,0,1]<br>    ]<br>    return np.array(matrix)<br><br>np.random.seed(202403)<br><br>tx, ty, tz = np.random.randint(10, size=3)<br>print(tx, ty, tz)   #5 5 2<br><br>matrix = translation_matrix(tx, ty, tz)<br>print(matrix)<br># [[1 0 0 5]<br>#  [0 1 0 5]<br>#  [0 0 1 2]<br>#  [0 0 0 1]]<br><br># translates a point x, y, z<br>x, y, z = np.random.randint(10, size = 3)<br>print(x, y, z)  #3 6 8<br>translated_point = matrix @ [x,y,z,1]<br>print(translated_point[:3]) #[ 8 11 10]<br><br>#decompose translation from translation_matrix<br>tx, ty, tz = matrix[:3,3]<br>print(tx, ty, tz)   #5 5 2</pre><h3>Scaling</h3><p>A scale operation will shift a point(or an object) from an initial position to a new position based on a scaling. Here is the equation of scalingÂ point:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/63/0*-fXUxB6sHg76_ye3\" /></figure><p>And the transformation matrixÂ form:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/293/0*LGM6KAFwo6l-9a3Z\" /></figure><p><strong>Implements scaling matrix withÂ NumPy</strong></p><pre>def scaling_matrix(sx, sy, sz):<br>    matrix = [<br>        [sx,0,0,0],<br>        [0,sy,0,0],<br>        [0,0,sz,0],<br>        [0,0,0,1]<br>    ]<br>    <br>    return np.array(matrix)<br><br>np.random.seed(202403)<br><br>sx, sy, sz = np.random.rand(3)<br>print(sx, sy, sz)   #0.5243255319030659 0.4804928539608385 0.07838680854264224<br><br>matrix = scaling_matrix(sx, sy, sz)<br>print(matrix)<br># [[0.52432553 0.         0.         0.        ]<br>#  [0.         0.48049285 0.         0.        ]<br>#  [0.         0.         0.07838681 0.        ]<br>#  [0.         0.         0.         1.        ]]<br><br># scales a point x, y, z<br>x, y, z = np.random.randint(10, size = 3)<br>print(x, y, z)  #6 8 8<br>scaled_point = matrix @ [x,y,z,1]<br>print(scaled_point[:3]) #[3.14595319 3.84394283 0.62709447]</pre><h3>Rotation</h3><p>A rotation operation will shift a point(or an object) from an initial position to a new position based on a rotation about a given axis or any arbitrary vector.</p><p>The rotation matrix is more complex than the scaling and translation matrix since the whole 3x3 upper-left matrix is needed to express complex rotations. It is common to specify arbitrary rotations with a sequence of simpler ones each along one of the three axes. In each case, the rotation is through an angle, about the given axis. Letâ€™s explore rotation matrix around single axis one by one. Notice that the signs of rotation angles are defined using a right-hand rule convention in the following sections.</p><h4><strong>Rotation around theÂ x-axis</strong></h4><p>Here is the matrix for rotating a point through the angle alpha around theÂ x-axis</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/242/0*f7mNutLhtBwhaV-5\" /></figure><p><strong>Implements x-axis rotation matrix withÂ NumPy</strong></p><pre>def rotation_matrix_x(alpha_degree):<br>    alpha_radian = np.deg2rad(alpha_degree)<br>    <br>    rotation_alpha = [<br>        [1, 0, 0, 0],<br>        [0, np.cos(alpha_radian), -np.sin(alpha_radian), 0],<br>        [0, np.sin(alpha_radian), np.cos(alpha_radian), 0],<br>        [0, 0, 0, 1]<br>    ]<br>    <br>    return np.array(rotation_alpha)<br><br>rotated_point = rotation_matrix_x(90) @ [0, 1, 0, 1]<br>print(rotated_point[:3])    #[0.000000e+00 6.123234e-17 1.000000e+00]</pre><h4><strong>Rotation around theÂ y-axis</strong></h4><p>Here is the matrix for rotating a point through the angle beta around theÂ y-axis</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/240/0*S-iwiCWThje9iEH7\" /></figure><p><strong>Implements y-axis rotation matrix withÂ NumPy</strong></p><pre>def rotation_matrix_y(beta_degree):<br>    beta_radian = np.deg2rad(beta_degree)<br><br>    rotation_beta = [<br>        [np.cos(beta_radian), 0, np.sin(beta_radian), 0],<br>        [0, 1, 0, 0],<br>        [-np.sin(beta_radian), 0, np.cos(beta_radian), 0],<br>        [0, 0, 0, 1]<br>    ]<br><br>    return np.array(rotation_beta)<br><br>rotated_point = rotation_matrix_y(90) @ [1, 0, 0, 1]<br>print(rotated_point[:3])    #[ 6.123234e-17  0.000000e+00 -1.000000e+00]</pre><h4><strong>Rotation around theÂ z-axis</strong></h4><p>Here is the matrix for rotating a point through the angle gamma around theÂ z-axis</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/238/0*kYV9Lk6bofzHe5FW\" /></figure><p><strong>Implements z-axis rotation matrix withÂ NumPy</strong></p><pre>def rotation_matrix_z(gamma_degree):<br>    gamma_radian = np.deg2rad(gamma_degree)<br><br>    rotation_gamma = [<br>        [np.cos(gamma_radian), -np.sin(gamma_radian), 0, 0],<br>        [np.sin(gamma_radian), np.cos(gamma_radian), 0, 0],<br>        [0, 0, 1, 0],<br>        [0, 0, 0, 1]<br>    ]<br>    <br>    return np.array(rotation_gamma)<br><br>rotated_point = rotation_matrix_z(90) @ [1, 0, 0, 1]<br>print(rotated_point[:3])    #[6.123234e-17 1.000000e+00 0.000000e+00]</pre><h4>General rotation</h4><p>General rotation matrix around 3 axes can be composed by concatenating matrices around each axis using matrix multiplication. Here is a general rotationÂ matrix:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/690/0*506QFJ0Nj_SowMTp\" /></figure><p><strong>Compose general rotaton matrix withÂ NumPy</strong></p><pre>def rotation_matrix(alpha, beta, gamma):<br>    return rotation_matrix_x(alpha) @ rotation_matrix_y(beta) @ rotation_matrix_z(gamma)<br><br>np.random.seed(202403)<br><br>alpha, beta, gamma = np.random.randint(0, 360, size = 3)<br>print(alpha, beta, gamma)   #165 77 117<br><br>x, y, z = np.random.randint(10, size = 3)<br>print(x, y, z)  #2 3 6<br>rotated_point = rotation_matrix(alpha, beta, gamma) @ [x,y,z,1]<br><br>print(rotated_point[:3]) #[ 5.04067053 -1.65813521 -4.56532892]</pre><h3>Jason ğŸš€</h3><p><em>Thank you for reading until the end. Before youÂ go:</em></p><p>ğŸ‘ Please <strong><em>Clap</em></strong> and <strong><em>follow</em></strong>Â me</p><p>ğŸ“¬ <a href=\"https://medium.com/@xuzhusheng/subscribe\">Subscribe</a> to my Medium newsletter for emailÂ updates!</p><p>â˜• or just <a href=\"https://www.buymeacoffee.com/jason.xu\">buy me aÂ coffee</a></p><h3>In Plain EnglishÂ ğŸš€</h3><p><em>Thank you for being a part of the </em><a href=\"https://plainenglish.io\"><strong><em>In Plain English</em></strong></a><em> community! Before youÂ go:</em></p><ul><li>Be sure to <strong>clap</strong> and <strong>follow</strong> the writerÂ ï¸ğŸ‘<strong>ï¸ï¸</strong></li><li>Follow us: <a href=\"https://twitter.com/inPlainEngHQ\"><strong>X</strong></a><strong> | </strong><a href=\"https://www.linkedin.com/company/inplainenglish/\"><strong>LinkedIn</strong></a><strong> | </strong><a href=\"https://www.youtube.com/channel/UCtipWUghju290NWcn8jhyAw\"><strong>YouTube</strong></a><strong> | </strong><a href=\"https://discord.gg/in-plain-english-709094664682340443\"><strong>Discord</strong></a><strong> | </strong><a href=\"https://newsletter.plainenglish.io/\"><strong>Newsletter</strong></a></li><li>Visit our other platforms: <a href=\"https://stackademic.com/\"><strong>Stackademic</strong></a><strong> | </strong><a href=\"https://cofeed.app/\"><strong>CoFeed</strong></a><strong> | </strong><a href=\"https://venturemagazine.net/\"><strong>Venture</strong></a><strong> |Â </strong><a href=\"https://blog.cubed.run\"><strong>Cubed</strong></a></li><li>More content at <a href=\"https://plainenglish.io\"><strong>PlainEnglish.io</strong></a></li></ul><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=57f92058403c\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://python.plainenglish.io/3d-affine-transformation-matrices-implementation-with-numpy-57f92058403c\">3D Affine Transformation Matrices Implementation with NumPy</a> was originally published in <a href=\"https://python.plainenglish.io\">Python in Plain English</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>","enclosures":[],"content_encoded":"<h4>3D Affine Transformation</h4><h4>Explores 3D affine transformation matrices and implements it withÂ NumPy</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*YhbgLSfLA9RgoDNE\" /><figcaption>Photo by <a href=\"https://unsplash.com/@mariolagr?utm_source=medium&amp;utm_medium=referral\">MARIOLA GROBELSKA</a> onÂ <a href=\"https://unsplash.com?utm_source=medium&amp;utm_medium=referral\">Unsplash</a></figcaption></figure><p>In computer graphics, afï¬ne transformation is the most general transformations model. Any combination of translation, rotations, scalings/reï¬‚ections and shears can be combined in a single 4 by 4 afï¬ne transformation matrix.</p><p>In this article, we are going to explore common 3d affine transformation matrices and implement it withÂ NumPy.</p><h3><strong>3D Affine Transformation Matrices</strong></h3><p>Here is a afï¬ne transformation matrix that transforms point (or vector) x to point (or vector)Â y.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/217/0*RcVfjT1NLncBvUDl\" /></figure><p>The upper-left 3 Ã— 3 sub-matrix of the matrix represents a rotation transform (include scales and shears). The last column of the matrix represents a translation. When used as a coordinate system, the upper-left 3 x 3 sub-matrix represents an orientation in space while the last column vector represents a position in space. The transformation of point x to point y is obtained by performing the matrix-vector multiplication Mx:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/61/0*BOHJ7Z2VcigfKx9I\" /></figure><p>The transformation matrix uses homogeneous coordinates, which allow to distinguish between points and vectors. Vectors have a direction and magnitude whereas points are positions. Points and vectors are both represented as mathematical column vectors in homogeneous coordinates. The only difference is points have a 1 in the fourth position whereas vectors have a zero at this position, which removes translation operations (4th column) forÂ vectors.</p><p>The transformation of point x to point y using homogeneous matrix is writtenÂ as:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/112/0*5GRNCeZyUUCvgjum\" /></figure><p><strong>Implements matrix withÂ NumPy</strong></p><p>Matrix is easy to be Implemented with NumPy. Letâ€™s see how to construct a matrix withÂ NumPy:</p><pre>import numpy as np<br><br>elements = [<br>    [1,2,3,4],<br>    [4,6,7,8],<br>    [9,10,11,12],<br>    [13,14,15,16]<br>]<br>matrix = np.array(elements)<br>print(matrix)<br># [[ 1  2  3  4]<br>#  [ 4  6  7  8]<br>#  [ 9 10 11 12]<br>#  [13 14 15 16]]</pre><p>Since affine transformation matrix is used to represent objectâ€™s rotaion and translation in 3D models, serialization and deserialization is common scenario. Here is code snippets for constructing matrix from list and converting it to aÂ list:</p><pre>import numpy as np<br><br># constructs from list<br>elements = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]<br>matrix = np.array(elements)<br>matrix = matrix.reshape(4,4)<br>print(matrix)<br># [[ 1  2  3  4]<br>#  [ 5  6  7  8]<br>#  [ 9 10 11 12]<br>#  [13 14 15 16]]<br><br># converts to list<br>print(matrix.reshape(-1).tolist())<br># [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]</pre><h3>Translation</h3><p>A translation operation will translate a point(or an object) from an initial position to a new position based on a linear shift. Here equation of translate a point (x, y, z) to point (x&#39;, y&#39;,Â z&#39;)</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/83/0*v6bX_KcpXD19QEsW\" /></figure><p>And the transformation matrixÂ form:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/297/0*9vAyfWIAClT_y9yn\" /></figure><p><strong>Implements translation matrix withÂ NumPy</strong></p><pre>def translation_matrix(tx, ty, tz):<br>    matrix = [<br>        [1,0,0,tx],<br>        [0,1,0,ty],<br>        [0,0,1,tz],<br>        [0,0,0,1]<br>    ]<br>    return np.array(matrix)<br><br>np.random.seed(202403)<br><br>tx, ty, tz = np.random.randint(10, size=3)<br>print(tx, ty, tz)   #5 5 2<br><br>matrix = translation_matrix(tx, ty, tz)<br>print(matrix)<br># [[1 0 0 5]<br>#  [0 1 0 5]<br>#  [0 0 1 2]<br>#  [0 0 0 1]]<br><br># translates a point x, y, z<br>x, y, z = np.random.randint(10, size = 3)<br>print(x, y, z)  #3 6 8<br>translated_point = matrix @ [x,y,z,1]<br>print(translated_point[:3]) #[ 8 11 10]<br><br>#decompose translation from translation_matrix<br>tx, ty, tz = matrix[:3,3]<br>print(tx, ty, tz)   #5 5 2</pre><h3>Scaling</h3><p>A scale operation will shift a point(or an object) from an initial position to a new position based on a scaling. Here is the equation of scalingÂ point:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/63/0*-fXUxB6sHg76_ye3\" /></figure><p>And the transformation matrixÂ form:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/293/0*LGM6KAFwo6l-9a3Z\" /></figure><p><strong>Implements scaling matrix withÂ NumPy</strong></p><pre>def scaling_matrix(sx, sy, sz):<br>    matrix = [<br>        [sx,0,0,0],<br>        [0,sy,0,0],<br>        [0,0,sz,0],<br>        [0,0,0,1]<br>    ]<br>    <br>    return np.array(matrix)<br><br>np.random.seed(202403)<br><br>sx, sy, sz = np.random.rand(3)<br>print(sx, sy, sz)   #0.5243255319030659 0.4804928539608385 0.07838680854264224<br><br>matrix = scaling_matrix(sx, sy, sz)<br>print(matrix)<br># [[0.52432553 0.         0.         0.        ]<br>#  [0.         0.48049285 0.         0.        ]<br>#  [0.         0.         0.07838681 0.        ]<br>#  [0.         0.         0.         1.        ]]<br><br># scales a point x, y, z<br>x, y, z = np.random.randint(10, size = 3)<br>print(x, y, z)  #6 8 8<br>scaled_point = matrix @ [x,y,z,1]<br>print(scaled_point[:3]) #[3.14595319 3.84394283 0.62709447]</pre><h3>Rotation</h3><p>A rotation operation will shift a point(or an object) from an initial position to a new position based on a rotation about a given axis or any arbitrary vector.</p><p>The rotation matrix is more complex than the scaling and translation matrix since the whole 3x3 upper-left matrix is needed to express complex rotations. It is common to specify arbitrary rotations with a sequence of simpler ones each along one of the three axes. In each case, the rotation is through an angle, about the given axis. Letâ€™s explore rotation matrix around single axis one by one. Notice that the signs of rotation angles are defined using a right-hand rule convention in the following sections.</p><h4><strong>Rotation around theÂ x-axis</strong></h4><p>Here is the matrix for rotating a point through the angle alpha around theÂ x-axis</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/242/0*f7mNutLhtBwhaV-5\" /></figure><p><strong>Implements x-axis rotation matrix withÂ NumPy</strong></p><pre>def rotation_matrix_x(alpha_degree):<br>    alpha_radian = np.deg2rad(alpha_degree)<br>    <br>    rotation_alpha = [<br>        [1, 0, 0, 0],<br>        [0, np.cos(alpha_radian), -np.sin(alpha_radian), 0],<br>        [0, np.sin(alpha_radian), np.cos(alpha_radian), 0],<br>        [0, 0, 0, 1]<br>    ]<br>    <br>    return np.array(rotation_alpha)<br><br>rotated_point = rotation_matrix_x(90) @ [0, 1, 0, 1]<br>print(rotated_point[:3])    #[0.000000e+00 6.123234e-17 1.000000e+00]</pre><h4><strong>Rotation around theÂ y-axis</strong></h4><p>Here is the matrix for rotating a point through the angle beta around theÂ y-axis</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/240/0*S-iwiCWThje9iEH7\" /></figure><p><strong>Implements y-axis rotation matrix withÂ NumPy</strong></p><pre>def rotation_matrix_y(beta_degree):<br>    beta_radian = np.deg2rad(beta_degree)<br><br>    rotation_beta = [<br>        [np.cos(beta_radian), 0, np.sin(beta_radian), 0],<br>        [0, 1, 0, 0],<br>        [-np.sin(beta_radian), 0, np.cos(beta_radian), 0],<br>        [0, 0, 0, 1]<br>    ]<br><br>    return np.array(rotation_beta)<br><br>rotated_point = rotation_matrix_y(90) @ [1, 0, 0, 1]<br>print(rotated_point[:3])    #[ 6.123234e-17  0.000000e+00 -1.000000e+00]</pre><h4><strong>Rotation around theÂ z-axis</strong></h4><p>Here is the matrix for rotating a point through the angle gamma around theÂ z-axis</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/238/0*kYV9Lk6bofzHe5FW\" /></figure><p><strong>Implements z-axis rotation matrix withÂ NumPy</strong></p><pre>def rotation_matrix_z(gamma_degree):<br>    gamma_radian = np.deg2rad(gamma_degree)<br><br>    rotation_gamma = [<br>        [np.cos(gamma_radian), -np.sin(gamma_radian), 0, 0],<br>        [np.sin(gamma_radian), np.cos(gamma_radian), 0, 0],<br>        [0, 0, 1, 0],<br>        [0, 0, 0, 1]<br>    ]<br>    <br>    return np.array(rotation_gamma)<br><br>rotated_point = rotation_matrix_z(90) @ [1, 0, 0, 1]<br>print(rotated_point[:3])    #[6.123234e-17 1.000000e+00 0.000000e+00]</pre><h4>General rotation</h4><p>General rotation matrix around 3 axes can be composed by concatenating matrices around each axis using matrix multiplication. Here is a general rotationÂ matrix:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/690/0*506QFJ0Nj_SowMTp\" /></figure><p><strong>Compose general rotaton matrix withÂ NumPy</strong></p><pre>def rotation_matrix(alpha, beta, gamma):<br>    return rotation_matrix_x(alpha) @ rotation_matrix_y(beta) @ rotation_matrix_z(gamma)<br><br>np.random.seed(202403)<br><br>alpha, beta, gamma = np.random.randint(0, 360, size = 3)<br>print(alpha, beta, gamma)   #165 77 117<br><br>x, y, z = np.random.randint(10, size = 3)<br>print(x, y, z)  #2 3 6<br>rotated_point = rotation_matrix(alpha, beta, gamma) @ [x,y,z,1]<br><br>print(rotated_point[:3]) #[ 5.04067053 -1.65813521 -4.56532892]</pre><h3>Jason ğŸš€</h3><p><em>Thank you for reading until the end. Before youÂ go:</em></p><p>ğŸ‘ Please <strong><em>Clap</em></strong> and <strong><em>follow</em></strong>Â me</p><p>ğŸ“¬ <a href=\"https://medium.com/@xuzhusheng/subscribe\">Subscribe</a> to my Medium newsletter for emailÂ updates!</p><p>â˜• or just <a href=\"https://www.buymeacoffee.com/jason.xu\">buy me aÂ coffee</a></p><h3>In Plain EnglishÂ ğŸš€</h3><p><em>Thank you for being a part of the </em><a href=\"https://plainenglish.io\"><strong><em>In Plain English</em></strong></a><em> community! Before youÂ go:</em></p><ul><li>Be sure to <strong>clap</strong> and <strong>follow</strong> the writerÂ ï¸ğŸ‘<strong>ï¸ï¸</strong></li><li>Follow us: <a href=\"https://twitter.com/inPlainEngHQ\"><strong>X</strong></a><strong> | </strong><a href=\"https://www.linkedin.com/company/inplainenglish/\"><strong>LinkedIn</strong></a><strong> | </strong><a href=\"https://www.youtube.com/channel/UCtipWUghju290NWcn8jhyAw\"><strong>YouTube</strong></a><strong> | </strong><a href=\"https://discord.gg/in-plain-english-709094664682340443\"><strong>Discord</strong></a><strong> | </strong><a href=\"https://newsletter.plainenglish.io/\"><strong>Newsletter</strong></a></li><li>Visit our other platforms: <a href=\"https://stackademic.com/\"><strong>Stackademic</strong></a><strong> | </strong><a href=\"https://cofeed.app/\"><strong>CoFeed</strong></a><strong> | </strong><a href=\"https://venturemagazine.net/\"><strong>Venture</strong></a><strong> |Â </strong><a href=\"https://blog.cubed.run\"><strong>Cubed</strong></a></li><li>More content at <a href=\"https://plainenglish.io\"><strong>PlainEnglish.io</strong></a></li></ul><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=57f92058403c\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://python.plainenglish.io/3d-affine-transformation-matrices-implementation-with-numpy-57f92058403c\">3D Affine Transformation Matrices Implementation with NumPy</a> was originally published in <a href=\"https://python.plainenglish.io\">Python in Plain English</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>","media":{}},{"id":"https://medium.com/p/fe885394d17f","title":"Manipulate JSON with Python Dynamic Object","link":"https://python.plainenglish.io/manipulate-json-with-python-dynamic-object-fe885394d17f?source=rss-41bd992616fb------2","author":"Jason","published":1707876757000,"created":1707876757000,"category":["json","programming","code","python","coding"],"content":"<h4>Code Snippets</h4><h4>Avoid code duplication with python dynamicÂ object</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*tmSiQ9rxkxOG1cJX\" /><figcaption>Photo by <a href=\"https://unsplash.com/@hiteshchoudhary?utm_source=medium&amp;utm_medium=referral\">Hitesh Choudhary</a> onÂ <a href=\"https://unsplash.com?utm_source=medium&amp;utm_medium=referral\">Unsplash</a></figcaption></figure><p>JSON (JavaScript Object Notation) is a lightweight, text-based data format used for storing and exchanging data. Itâ€™s a simple and flexible way of representing data that can be easily understood and parsed by both humans and machines. JSON has become one of the most popular in standard.</p><p>Python provides variou tools for parsing and manipulating JSON data. JSON string can be parsed into corresponding dictionary or custom python object. It is a commom pratice parse JSON string to custom object. However, we have to define corresponding class in advance. It can be a bunch of codes, especially for complexÂ class.</p><p>In this article, I am going to share my code snippets for mapping JSON to python object without predefined attribtute at myÂ project:</p><p><a href=\"https://github.com/xuzhusheng/gltf-to-3d-tiles\">GitHub - xuzhusheng/gltf-to-3d-tiles: glTF to 3d Tiles Converter. Convert glTF model to Glb, b3dm or 3d tiles format.</a></p><p>Letâ€™s get start we a briefing about JSON data structure we are going to deal with - glTFÂ file.</p><h3>Briefing about The JSON Data Structure</h3><p>The JSON data we are going to manipulate is <strong>glTF</strong> (Graphics Library Transmission Format), a <a href=\"https://en.wikipedia.org/wiki/List_of_file_formats#3D_graphics\">standard file format</a> for <a href=\"https://en.wikipedia.org/wiki/3D_modeling\">three-dimensional scenes and models</a>. Here is a minimal glTFÂ file:</p><pre>{<br>  &quot;scene&quot;: 0,<br>  &quot;scenes&quot; : [<br>    {<br>      &quot;nodes&quot; : [ 0 ]<br>    }<br>  ],<br>  <br>  &quot;nodes&quot; : [<br>    {<br>      &quot;mesh&quot; : 0<br>    }<br>  ],<br>  <br>  &quot;meshes&quot; : [<br>    {<br>      &quot;primitives&quot; : [ {<br>        &quot;attributes&quot; : {<br>          &quot;POSITION&quot; : 1<br>        },<br>        &quot;indices&quot; : 0<br>      } ]<br>    }<br>  ],<br><br>  &quot;buffers&quot; : [<br>    {<br>      &quot;uri&quot; : &quot;data:application/octet-stream;base64,AAABAAIAAAAAAAAAAAAAAAAAAAAAAIA/AAAAAAAAAAAAAAAAAACAPwAAAAA=&quot;,<br>      &quot;byteLength&quot; : 44<br>    }<br>  ],<br>  &quot;bufferViews&quot; : [<br>    {<br>      &quot;buffer&quot; : 0,<br>      &quot;byteOffset&quot; : 0,<br>      &quot;byteLength&quot; : 6,<br>      &quot;target&quot; : 34963<br>    },<br>    {<br>      &quot;buffer&quot; : 0,<br>      &quot;byteOffset&quot; : 8,<br>      &quot;byteLength&quot; : 36,<br>      &quot;target&quot; : 34962<br>    }<br>  ],<br>  &quot;accessors&quot; : [<br>    {<br>      &quot;bufferView&quot; : 0,<br>      &quot;byteOffset&quot; : 0,<br>      &quot;componentType&quot; : 5123,<br>      &quot;count&quot; : 3,<br>      &quot;type&quot; : &quot;SCALAR&quot;,<br>      &quot;max&quot; : [ 2 ],<br>      &quot;min&quot; : [ 0 ]<br>    },<br>    {<br>      &quot;bufferView&quot; : 1,<br>      &quot;byteOffset&quot; : 0,<br>      &quot;componentType&quot; : 5126,<br>      &quot;count&quot; : 3,<br>      &quot;type&quot; : &quot;VEC3&quot;,<br>      &quot;max&quot; : [ 1.0, 1.0, 0.0 ],<br>      &quot;min&quot; : [ 0.0, 0.0, 0.0 ]<br>    }<br>  ],<br>  <br>  &quot;asset&quot; : {<br>    &quot;version&quot; : &quot;2.0&quot;<br>  }<br>}</pre><p>Letâ€™s save this file as minimal.gltf. We are going to load and convert this file to a dynamic object in nextÂ section.</p><h3>Converting JSON to Python DynamicÂ Object</h3><p>JSON could converted to python object in twoÂ steps:</p><ol><li>converts JSON data to a dictionary object by json.load()</li><li>converts dictionary object to dynamicÂ object.</li></ol><p>The second step could be done with the function setattr(). Letâ€™s get into theÂ codes.</p><pre>class GltfModel:<br>    <br>    def __init__(self) -&gt; None:<br>        ...<br><br>    @classmethod<br>    def from_kwargs(cls, **kwargs):<br>        <br>        obj = cls()<br>        <br>        for key, value in kwargs.items():<br>            if type(value) == dict:<br>                setattr(obj, key, cls.from_kwargs(**value))<br>            elif type(value) == list:<br>                setattr(obj, key, [cls.from_kwargs(**item) if type(item) == dict else item for item in value])<br>            elif value is not None:<br>                setattr(obj, key, value)<br>                <br>        return obj</pre><p><strong>Codes walkÂ throuth:</strong></p><ol><li>Defines a class funcion from_kwargs() accepts keyword arguments to create and initialize dynamic object - @classmethod def from_kwargs(cls, **kwargs)</li><li>Creates object from class cls - obj =Â cls()</li><li>Parses keyword arguments in a loop - for key, value in kwargs.items()</li><li>Creates a nested object attribute by calling cls.from_kwargs() recursively for dict value - if type(value) == dict: setattr(obj, key, cls.from_kwargs(**value))</li><li>Creates an array attribute with primary data type value or nested object for list value - elif type(value) == list: setattr(obj, key, [cls.from_kwargs(**item) if type(item) == dict else item for item inÂ value])</li><li>Creates an attribute with primary data type for other not none value - elif value is not None: setattr(obj, key,Â value)</li></ol><h3>Access and Manipulate Attributes</h3><p>Afte converted the minial.gltf to a dynamic object, we can access and manipulate attributes with dot notation like model.scene. It is much nicer and cleaner than model[&quot;scene&quot;] or model.get(&quot;scene&quot;). However, there are some optional node in gltf data structure. Correspondingly, there are some optional attributes. If we access any optioanl attribute that does not exist with dot notation model.not_exist_attribute, we will get a AttributeError. To avoid this, we need to override the __getattr__() magic function of class GltfModel:</p><pre>def __getattr__(self, name):<br>        return None</pre><p>Than, if we access any none exist attribute with mode.not_exist_attribute, it returnÂ None</p><h3>Naming convention</h3><p>The JSON in minimal.gltf using camal case naming convention violates python PEP 8 standard. I using the code snippets to convert camel case to snakeÂ case:</p><pre>import re<br><br>CAMEL_PATTERN = r&#39;(?&lt;!^)(?=[A-Z])&#39;<br>camel_to_snake = lambda name : re.sub(CAMEL_PATTERN, &#39;_&#39;, name).lower()</pre><p>For converting between snake case and camel case, please read myÂ article:</p><p><a href=\"https://xuzhusheng.medium.com/converting-between-naming-convention-with-python-2d91032bd0dc\">Converting between Snake Case and Camel Case</a></p><h3>Conclusion</h3><p>The completed code snippets asÂ below:</p><pre>import re<br><br>CAMEL_PATTERN = r&#39;(?&lt;!^)(?=[A-Z])&#39;<br>camel_to_snake = lambda name : re.sub(CAMEL_PATTERN, &#39;_&#39;, name).lower()<br><br>class GltfModel:<br>    <br>    def __init__(self) -&gt; None:<br>        ...<br><br>    @classmethod<br>    def from_kwargs(cls, **kwargs):<br>        <br>        obj = cls()<br>        <br>        for key, value in kwargs.items():<br>            key = camel_to_snake(key)<br>            if type(value) == dict:<br>                setattr(obj, key, cls.from_kwargs(**value))<br>            elif type(value) == list:<br>                setattr(obj, key, [cls.from_kwargs(**item) if type(item) == dict else item for item in value])<br>            elif value is not None:<br>                setattr(obj, key, value)<br>                <br>        return obj<br><br>    def __getattr__(self, name):<br>        return None<br><br>with open(&quot;minimal.gltf&quot;, encoding=&#39;utf-8&#39;) as f:<br>    data = json.load(f)<br>    <br>gltf = GltfModel.from_kwargs(**data)<br><br>print(gltf.scene) # 0<br>print(gltf.not_exist_attribute) # None</pre><h3>Jason ğŸš€</h3><p><em>Thank you for reading until the end. Before youÂ go:</em></p><p>ğŸ‘ Please <strong><em>Clap</em></strong> and <strong><em>follow</em></strong>Â me</p><p>ğŸ“¬ <a href=\"https://medium.com/@xuzhusheng/subscribe\">Subscribe</a> to my Medium newsletter for emailÂ updates!</p><p>â˜• or just <a href=\"https://www.buymeacoffee.com/jason.xu\">buy me aÂ coffee</a></p><h3>In Plain EnglishÂ ğŸš€</h3><p><em>Thank you for being a part of the </em><a href=\"https://plainenglish.io\"><strong><em>In Plain English</em></strong></a><em> community! Before youÂ go:</em></p><ul><li>Be sure to <strong>clap</strong> and <strong>follow</strong> the writerÂ ï¸ğŸ‘<strong>ï¸ï¸</strong></li><li>Follow us: <a href=\"https://twitter.com/inPlainEngHQ\"><strong>X</strong></a><strong> | </strong><a href=\"https://www.linkedin.com/company/inplainenglish/\"><strong>LinkedIn</strong></a><strong> | </strong><a href=\"https://www.youtube.com/channel/UCtipWUghju290NWcn8jhyAw\"><strong>YouTube</strong></a><strong> | </strong><a href=\"https://discord.gg/in-plain-english-709094664682340443\"><strong>Discord</strong></a><strong> | </strong><a href=\"https://newsletter.plainenglish.io/\"><strong>Newsletter</strong></a></li><li>Visit our other platforms: <a href=\"https://stackademic.com/\"><strong>Stackademic</strong></a><strong> | </strong><a href=\"https://cofeed.app/\"><strong>CoFeed</strong></a><strong> | </strong><a href=\"https://venturemagazine.net/\"><strong>Venture</strong></a><strong> |Â </strong><a href=\"https://blog.cubed.run\"><strong>Cubed</strong></a></li><li>More content at <a href=\"https://plainenglish.io\"><strong>PlainEnglish.io</strong></a></li></ul><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=fe885394d17f\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://python.plainenglish.io/manipulate-json-with-python-dynamic-object-fe885394d17f\">Manipulate JSON with Python Dynamic Object</a> was originally published in <a href=\"https://python.plainenglish.io\">Python in Plain English</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>","enclosures":[],"content_encoded":"<h4>Code Snippets</h4><h4>Avoid code duplication with python dynamicÂ object</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*tmSiQ9rxkxOG1cJX\" /><figcaption>Photo by <a href=\"https://unsplash.com/@hiteshchoudhary?utm_source=medium&amp;utm_medium=referral\">Hitesh Choudhary</a> onÂ <a href=\"https://unsplash.com?utm_source=medium&amp;utm_medium=referral\">Unsplash</a></figcaption></figure><p>JSON (JavaScript Object Notation) is a lightweight, text-based data format used for storing and exchanging data. Itâ€™s a simple and flexible way of representing data that can be easily understood and parsed by both humans and machines. JSON has become one of the most popular in standard.</p><p>Python provides variou tools for parsing and manipulating JSON data. JSON string can be parsed into corresponding dictionary or custom python object. It is a commom pratice parse JSON string to custom object. However, we have to define corresponding class in advance. It can be a bunch of codes, especially for complexÂ class.</p><p>In this article, I am going to share my code snippets for mapping JSON to python object without predefined attribtute at myÂ project:</p><p><a href=\"https://github.com/xuzhusheng/gltf-to-3d-tiles\">GitHub - xuzhusheng/gltf-to-3d-tiles: glTF to 3d Tiles Converter. Convert glTF model to Glb, b3dm or 3d tiles format.</a></p><p>Letâ€™s get start we a briefing about JSON data structure we are going to deal with - glTFÂ file.</p><h3>Briefing about The JSON Data Structure</h3><p>The JSON data we are going to manipulate is <strong>glTF</strong> (Graphics Library Transmission Format), a <a href=\"https://en.wikipedia.org/wiki/List_of_file_formats#3D_graphics\">standard file format</a> for <a href=\"https://en.wikipedia.org/wiki/3D_modeling\">three-dimensional scenes and models</a>. Here is a minimal glTFÂ file:</p><pre>{<br>  &quot;scene&quot;: 0,<br>  &quot;scenes&quot; : [<br>    {<br>      &quot;nodes&quot; : [ 0 ]<br>    }<br>  ],<br>  <br>  &quot;nodes&quot; : [<br>    {<br>      &quot;mesh&quot; : 0<br>    }<br>  ],<br>  <br>  &quot;meshes&quot; : [<br>    {<br>      &quot;primitives&quot; : [ {<br>        &quot;attributes&quot; : {<br>          &quot;POSITION&quot; : 1<br>        },<br>        &quot;indices&quot; : 0<br>      } ]<br>    }<br>  ],<br><br>  &quot;buffers&quot; : [<br>    {<br>      &quot;uri&quot; : &quot;data:application/octet-stream;base64,AAABAAIAAAAAAAAAAAAAAAAAAAAAAIA/AAAAAAAAAAAAAAAAAACAPwAAAAA=&quot;,<br>      &quot;byteLength&quot; : 44<br>    }<br>  ],<br>  &quot;bufferViews&quot; : [<br>    {<br>      &quot;buffer&quot; : 0,<br>      &quot;byteOffset&quot; : 0,<br>      &quot;byteLength&quot; : 6,<br>      &quot;target&quot; : 34963<br>    },<br>    {<br>      &quot;buffer&quot; : 0,<br>      &quot;byteOffset&quot; : 8,<br>      &quot;byteLength&quot; : 36,<br>      &quot;target&quot; : 34962<br>    }<br>  ],<br>  &quot;accessors&quot; : [<br>    {<br>      &quot;bufferView&quot; : 0,<br>      &quot;byteOffset&quot; : 0,<br>      &quot;componentType&quot; : 5123,<br>      &quot;count&quot; : 3,<br>      &quot;type&quot; : &quot;SCALAR&quot;,<br>      &quot;max&quot; : [ 2 ],<br>      &quot;min&quot; : [ 0 ]<br>    },<br>    {<br>      &quot;bufferView&quot; : 1,<br>      &quot;byteOffset&quot; : 0,<br>      &quot;componentType&quot; : 5126,<br>      &quot;count&quot; : 3,<br>      &quot;type&quot; : &quot;VEC3&quot;,<br>      &quot;max&quot; : [ 1.0, 1.0, 0.0 ],<br>      &quot;min&quot; : [ 0.0, 0.0, 0.0 ]<br>    }<br>  ],<br>  <br>  &quot;asset&quot; : {<br>    &quot;version&quot; : &quot;2.0&quot;<br>  }<br>}</pre><p>Letâ€™s save this file as minimal.gltf. We are going to load and convert this file to a dynamic object in nextÂ section.</p><h3>Converting JSON to Python DynamicÂ Object</h3><p>JSON could converted to python object in twoÂ steps:</p><ol><li>converts JSON data to a dictionary object by json.load()</li><li>converts dictionary object to dynamicÂ object.</li></ol><p>The second step could be done with the function setattr(). Letâ€™s get into theÂ codes.</p><pre>class GltfModel:<br>    <br>    def __init__(self) -&gt; None:<br>        ...<br><br>    @classmethod<br>    def from_kwargs(cls, **kwargs):<br>        <br>        obj = cls()<br>        <br>        for key, value in kwargs.items():<br>            if type(value) == dict:<br>                setattr(obj, key, cls.from_kwargs(**value))<br>            elif type(value) == list:<br>                setattr(obj, key, [cls.from_kwargs(**item) if type(item) == dict else item for item in value])<br>            elif value is not None:<br>                setattr(obj, key, value)<br>                <br>        return obj</pre><p><strong>Codes walkÂ throuth:</strong></p><ol><li>Defines a class funcion from_kwargs() accepts keyword arguments to create and initialize dynamic object - @classmethod def from_kwargs(cls, **kwargs)</li><li>Creates object from class cls - obj =Â cls()</li><li>Parses keyword arguments in a loop - for key, value in kwargs.items()</li><li>Creates a nested object attribute by calling cls.from_kwargs() recursively for dict value - if type(value) == dict: setattr(obj, key, cls.from_kwargs(**value))</li><li>Creates an array attribute with primary data type value or nested object for list value - elif type(value) == list: setattr(obj, key, [cls.from_kwargs(**item) if type(item) == dict else item for item inÂ value])</li><li>Creates an attribute with primary data type for other not none value - elif value is not None: setattr(obj, key,Â value)</li></ol><h3>Access and Manipulate Attributes</h3><p>Afte converted the minial.gltf to a dynamic object, we can access and manipulate attributes with dot notation like model.scene. It is much nicer and cleaner than model[&quot;scene&quot;] or model.get(&quot;scene&quot;). However, there are some optional node in gltf data structure. Correspondingly, there are some optional attributes. If we access any optioanl attribute that does not exist with dot notation model.not_exist_attribute, we will get a AttributeError. To avoid this, we need to override the __getattr__() magic function of class GltfModel:</p><pre>def __getattr__(self, name):<br>        return None</pre><p>Than, if we access any none exist attribute with mode.not_exist_attribute, it returnÂ None</p><h3>Naming convention</h3><p>The JSON in minimal.gltf using camal case naming convention violates python PEP 8 standard. I using the code snippets to convert camel case to snakeÂ case:</p><pre>import re<br><br>CAMEL_PATTERN = r&#39;(?&lt;!^)(?=[A-Z])&#39;<br>camel_to_snake = lambda name : re.sub(CAMEL_PATTERN, &#39;_&#39;, name).lower()</pre><p>For converting between snake case and camel case, please read myÂ article:</p><p><a href=\"https://xuzhusheng.medium.com/converting-between-naming-convention-with-python-2d91032bd0dc\">Converting between Snake Case and Camel Case</a></p><h3>Conclusion</h3><p>The completed code snippets asÂ below:</p><pre>import re<br><br>CAMEL_PATTERN = r&#39;(?&lt;!^)(?=[A-Z])&#39;<br>camel_to_snake = lambda name : re.sub(CAMEL_PATTERN, &#39;_&#39;, name).lower()<br><br>class GltfModel:<br>    <br>    def __init__(self) -&gt; None:<br>        ...<br><br>    @classmethod<br>    def from_kwargs(cls, **kwargs):<br>        <br>        obj = cls()<br>        <br>        for key, value in kwargs.items():<br>            key = camel_to_snake(key)<br>            if type(value) == dict:<br>                setattr(obj, key, cls.from_kwargs(**value))<br>            elif type(value) == list:<br>                setattr(obj, key, [cls.from_kwargs(**item) if type(item) == dict else item for item in value])<br>            elif value is not None:<br>                setattr(obj, key, value)<br>                <br>        return obj<br><br>    def __getattr__(self, name):<br>        return None<br><br>with open(&quot;minimal.gltf&quot;, encoding=&#39;utf-8&#39;) as f:<br>    data = json.load(f)<br>    <br>gltf = GltfModel.from_kwargs(**data)<br><br>print(gltf.scene) # 0<br>print(gltf.not_exist_attribute) # None</pre><h3>Jason ğŸš€</h3><p><em>Thank you for reading until the end. Before youÂ go:</em></p><p>ğŸ‘ Please <strong><em>Clap</em></strong> and <strong><em>follow</em></strong>Â me</p><p>ğŸ“¬ <a href=\"https://medium.com/@xuzhusheng/subscribe\">Subscribe</a> to my Medium newsletter for emailÂ updates!</p><p>â˜• or just <a href=\"https://www.buymeacoffee.com/jason.xu\">buy me aÂ coffee</a></p><h3>In Plain EnglishÂ ğŸš€</h3><p><em>Thank you for being a part of the </em><a href=\"https://plainenglish.io\"><strong><em>In Plain English</em></strong></a><em> community! Before youÂ go:</em></p><ul><li>Be sure to <strong>clap</strong> and <strong>follow</strong> the writerÂ ï¸ğŸ‘<strong>ï¸ï¸</strong></li><li>Follow us: <a href=\"https://twitter.com/inPlainEngHQ\"><strong>X</strong></a><strong> | </strong><a href=\"https://www.linkedin.com/company/inplainenglish/\"><strong>LinkedIn</strong></a><strong> | </strong><a href=\"https://www.youtube.com/channel/UCtipWUghju290NWcn8jhyAw\"><strong>YouTube</strong></a><strong> | </strong><a href=\"https://discord.gg/in-plain-english-709094664682340443\"><strong>Discord</strong></a><strong> | </strong><a href=\"https://newsletter.plainenglish.io/\"><strong>Newsletter</strong></a></li><li>Visit our other platforms: <a href=\"https://stackademic.com/\"><strong>Stackademic</strong></a><strong> | </strong><a href=\"https://cofeed.app/\"><strong>CoFeed</strong></a><strong> | </strong><a href=\"https://venturemagazine.net/\"><strong>Venture</strong></a><strong> |Â </strong><a href=\"https://blog.cubed.run\"><strong>Cubed</strong></a></li><li>More content at <a href=\"https://plainenglish.io\"><strong>PlainEnglish.io</strong></a></li></ul><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=fe885394d17f\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://python.plainenglish.io/manipulate-json-with-python-dynamic-object-fe885394d17f\">Manipulate JSON with Python Dynamic Object</a> was originally published in <a href=\"https://python.plainenglish.io\">Python in Plain English</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>","media":{}},{"id":"https://medium.com/p/2d91032bd0dc","title":"Converting between Snake Case and Camel Case","link":"https://python.plainenglish.io/converting-between-naming-convention-with-python-2d91032bd0dc?source=rss-41bd992616fb------2","author":"Jason","published":1706884190000,"created":1706884190000,"category":["code","python","programming","coding","python-programming"],"content":"<h4>code snippets</h4><h4>Elegant Python code snippets for converting between snake case and camelÂ case</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*Rz_NQ08qJUTzulHH\" /><figcaption>Photo by <a href=\"https://unsplash.com/@cdr6934?utm_source=medium&amp;utm_medium=referral\">Chris Ried</a> onÂ <a href=\"https://unsplash.com?utm_source=medium&amp;utm_medium=referral\">Unsplash</a></figcaption></figure><p>I shared my code snippets about manipulate JSON with python dynamic object in myÂ article:</p><p><a href=\"https://xuzhusheng.medium.com/manipulate-json-with-python-dynamic-object-fe885394d17f\">Manipulate JSON with Python Dynamic Object</a></p><p>But the JSON data using camel case, itâ€™s naming convention violates python PEP 8 standard. we need to convert the camel case to snakeÂ case.</p><p>In this articl, we are intruduces some elegant code snippets to converting between and camel case. Before we start, letâ€™s review the relative name conventions first.</p><h3>Naming Conventions</h3><p>Here listed the snake case, camel case and pascal case naming conventions:</p><ul><li>Snake Case - Separates the words with underscore, e.g. snake_case</li><li>Camel Case - All words start with a capital letter except the first one, e.g. camelCase</li><li>Pascal Case - All words start with a capital letter, e.g. PascalCase</li></ul><p>Pascal Case is also mentioned above, because pascal case acted as a median naing convention between snake case and camel case. We are converts snake case to pascal case, and then converts pascal case to camel case in coming sesction.</p><p>The only different between camel case and the pascal case is whether the first letter is capital. Letâ€™s warm up with the easiest one, converting between pascal case and camelÂ case.</p><h3>Converting between Pascal Case and CamelÂ Case</h3><p>The only thing we need to do is convert the first letters to upper case or otherwise. The scripts asÂ below:</p><pre>def pascal_to_camel(name):<br>    return name[0].lower() + name[1:]<br><br>print(pascal_to_camel(&quot;CamelCase&quot;)) #camelCase<br><br>def camel_to_pascal(name):<br>    return name[0].upper() + name[1:]<br><br>print(camel_to_pascal(&quot;PascalCase&quot;)) #PascalCase</pre><h3>Snake Case to PascalÂ Case</h3><p>Converts from snake case to pascal case, we need to convert the first letter of each word to upper case and remove the underscore seperator. Here is theÂ script:</p><pre>def snake_to_pascal(name):<br>    return &#39;&#39;.join(name.title().split(&#39;_&#39;))<br><br>print(snake_to_pascal(&quot;pascal_case&quot;)) # PascalCase</pre><h3>Snake Case to CamelÂ Case</h3><p>Combines snake_to_pascal and pascal_to_camel, we could converts the snake case to camelÂ case:</p><pre>def snake_to_camel(name):<br>    return pascal_to_camel(camel_to_pascal(name))<br><br>print(snake_to_camel(&quot;camel_case&quot;)) # camelCase</pre><h3>Converting to SnakeÂ Case</h3><p>Converting camel case or pascal case to snake case is the same. It could be done by 2Â steps:</p><ol><li>Inserts a underscore seperator before each upper caseÂ letter.</li><li>converts string to lowerÂ case.</li></ol><p>It can be done by re.sub() function:</p><pre>import re<br><br>CAMEL_PATTERN = r&#39;(?&lt;!^)(?=[A-Z])&#39;<br><br>def camel_to_snake(name):<br>    return re.sub(CAMEL_PATTERN, &#39;_&#39;, name).lower()<br><br>print(camel_to_snake(&quot;cnakeCase&quot;)) # snake_case</pre><p>Since compile the regex can take times, we could do it beforehand to improve performance:</p><pre>import re<br>CAMEL_PATTERN = re.compile(r&#39;(?&lt;!^)(?=[A-Z])&#39;)<br>def camel_to_snake(name):<br>    return CAMEL_PATTERN.sub(&#39;_&#39;, name).lower()<br><br>print(camel_to_snake(&quot;SnakeCase&quot;)) # snake_case<br>print(camel_to_snake(&quot;HTTPStatus&quot;)) # h_t_t_p_status</pre><p>It was suppose to convert HTTPStatus to http_status. To handle this case, we need a different approach.</p><h4>Advanced Cases (Not Reversible)</h4><p>These cases is <strong>not reversible</strong>, once we convert HTTPStatus to http_status, There is no way we can convert back to HTTPStatus. Also two steps to get itÂ done:</p><ol><li>Looks for every upper case letter that following lower case letter ( letter C in snakeCase ) or followed by lower case letter (letter S in HTTPStatus ), then insert a underscore seperator beforeÂ each.</li><li>Converts string to lowerÂ case.</li></ol><p>Here is theÂ script:</p><pre>ADVANCED_CAMEL_PATTERN = re.compile(r&#39;(?&lt;=[a-z])[A-Z]|(?&lt;!^)[A-Z](?=[a-z])&#39;)<br>def advanced_camel_to_snake(name):<br>    return re.sub(ADVANCED_CAMEL_PATTERN, r&quot;_\\g&lt;0&gt;&quot;, name).lower()<br><br>print(advanced_camel_to_snake(&quot;snakeCase&quot;)) # snake_case<br>print(advanced_camel_to_snake(&quot;SnakeCase&quot;))  # snake_case<br>print(advanced_camel_to_snake(&quot;HTTPStatus&quot;)) # http_status<br>print(advanced_camel_to_snake(&quot;HTTPStatusXYZ&quot;)) # http_status_xyz<br>print(advanced_camel_to_snake(&quot;getHTTPStatus&quot;)) # get_http_status<br>print(advanced_camel_to_snake(&quot;GetHTTPStatus&quot;)) # get_http_status</pre><h3>Conclusion</h3><p>Weâ€™ve covered code snippets for converting between snake case, camel case and pascal case. I put all of the converting functions together asÂ below:</p><iframe src=\"\" width=\"0\" height=\"0\" frameborder=\"0\" scrolling=\"no\"><a href=\"https://medium.com/media/c0ae932bbd2bffeb19a2c7a0a42b07d1/href\">https://medium.com/media/c0ae932bbd2bffeb19a2c7a0a42b07d1/href</a></iframe><h3>Jason ğŸš€</h3><p><em>Thank you for reading until the end. Before youÂ go:</em></p><p>ğŸ‘ Please <strong><em>Clap</em></strong> and <strong><em>follow</em></strong>Â me</p><p>ğŸ“¬ <a href=\"https://medium.com/@xuzhusheng/subscribe\">Subscribe</a> to my Medium newsletter for emailÂ updates!</p><p>â˜• or just <a href=\"https://www.buymeacoffee.com/jason.xu\">buy me aÂ coffee</a></p><h3>In Plain EnglishÂ ğŸš€</h3><p><em>Thank you for being a part of the </em><a href=\"https://plainenglish.io\"><strong><em>In Plain English</em></strong></a><em> community! Before youÂ go:</em></p><ul><li>Be sure to <strong>clap</strong> and <strong>follow</strong> the writerÂ ï¸ğŸ‘<strong>ï¸ï¸</strong></li><li>Follow us: <a href=\"https://twitter.com/inPlainEngHQ\"><strong>X</strong></a><strong> | </strong><a href=\"https://www.linkedin.com/company/inplainenglish/\"><strong>LinkedIn</strong></a><strong> | </strong><a href=\"https://www.youtube.com/channel/UCtipWUghju290NWcn8jhyAw\"><strong>YouTube</strong></a><strong> | </strong><a href=\"https://discord.gg/in-plain-english-709094664682340443\"><strong>Discord</strong></a><strong> | </strong><a href=\"https://newsletter.plainenglish.io/\"><strong>Newsletter</strong></a></li><li>Visit our other platforms: <a href=\"https://stackademic.com/\"><strong>Stackademic</strong></a><strong> | </strong><a href=\"https://cofeed.app/\"><strong>CoFeed</strong></a><strong> | </strong><a href=\"https://venturemagazine.net/\"><strong>Venture</strong></a><strong> |Â </strong><a href=\"https://blog.cubed.run\"><strong>Cubed</strong></a></li><li>More content at <a href=\"https://plainenglish.io\"><strong>PlainEnglish.io</strong></a></li></ul><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=2d91032bd0dc\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://python.plainenglish.io/converting-between-naming-convention-with-python-2d91032bd0dc\">Converting between Snake Case and Camel Case</a> was originally published in <a href=\"https://python.plainenglish.io\">Python in Plain English</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>","enclosures":[],"content_encoded":"<h4>code snippets</h4><h4>Elegant Python code snippets for converting between snake case and camelÂ case</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*Rz_NQ08qJUTzulHH\" /><figcaption>Photo by <a href=\"https://unsplash.com/@cdr6934?utm_source=medium&amp;utm_medium=referral\">Chris Ried</a> onÂ <a href=\"https://unsplash.com?utm_source=medium&amp;utm_medium=referral\">Unsplash</a></figcaption></figure><p>I shared my code snippets about manipulate JSON with python dynamic object in myÂ article:</p><p><a href=\"https://xuzhusheng.medium.com/manipulate-json-with-python-dynamic-object-fe885394d17f\">Manipulate JSON with Python Dynamic Object</a></p><p>But the JSON data using camel case, itâ€™s naming convention violates python PEP 8 standard. we need to convert the camel case to snakeÂ case.</p><p>In this articl, we are intruduces some elegant code snippets to converting between and camel case. Before we start, letâ€™s review the relative name conventions first.</p><h3>Naming Conventions</h3><p>Here listed the snake case, camel case and pascal case naming conventions:</p><ul><li>Snake Case - Separates the words with underscore, e.g. snake_case</li><li>Camel Case - All words start with a capital letter except the first one, e.g. camelCase</li><li>Pascal Case - All words start with a capital letter, e.g. PascalCase</li></ul><p>Pascal Case is also mentioned above, because pascal case acted as a median naing convention between snake case and camel case. We are converts snake case to pascal case, and then converts pascal case to camel case in coming sesction.</p><p>The only different between camel case and the pascal case is whether the first letter is capital. Letâ€™s warm up with the easiest one, converting between pascal case and camelÂ case.</p><h3>Converting between Pascal Case and CamelÂ Case</h3><p>The only thing we need to do is convert the first letters to upper case or otherwise. The scripts asÂ below:</p><pre>def pascal_to_camel(name):<br>    return name[0].lower() + name[1:]<br><br>print(pascal_to_camel(&quot;CamelCase&quot;)) #camelCase<br><br>def camel_to_pascal(name):<br>    return name[0].upper() + name[1:]<br><br>print(camel_to_pascal(&quot;PascalCase&quot;)) #PascalCase</pre><h3>Snake Case to PascalÂ Case</h3><p>Converts from snake case to pascal case, we need to convert the first letter of each word to upper case and remove the underscore seperator. Here is theÂ script:</p><pre>def snake_to_pascal(name):<br>    return &#39;&#39;.join(name.title().split(&#39;_&#39;))<br><br>print(snake_to_pascal(&quot;pascal_case&quot;)) # PascalCase</pre><h3>Snake Case to CamelÂ Case</h3><p>Combines snake_to_pascal and pascal_to_camel, we could converts the snake case to camelÂ case:</p><pre>def snake_to_camel(name):<br>    return pascal_to_camel(camel_to_pascal(name))<br><br>print(snake_to_camel(&quot;camel_case&quot;)) # camelCase</pre><h3>Converting to SnakeÂ Case</h3><p>Converting camel case or pascal case to snake case is the same. It could be done by 2Â steps:</p><ol><li>Inserts a underscore seperator before each upper caseÂ letter.</li><li>converts string to lowerÂ case.</li></ol><p>It can be done by re.sub() function:</p><pre>import re<br><br>CAMEL_PATTERN = r&#39;(?&lt;!^)(?=[A-Z])&#39;<br><br>def camel_to_snake(name):<br>    return re.sub(CAMEL_PATTERN, &#39;_&#39;, name).lower()<br><br>print(camel_to_snake(&quot;cnakeCase&quot;)) # snake_case</pre><p>Since compile the regex can take times, we could do it beforehand to improve performance:</p><pre>import re<br>CAMEL_PATTERN = re.compile(r&#39;(?&lt;!^)(?=[A-Z])&#39;)<br>def camel_to_snake(name):<br>    return CAMEL_PATTERN.sub(&#39;_&#39;, name).lower()<br><br>print(camel_to_snake(&quot;SnakeCase&quot;)) # snake_case<br>print(camel_to_snake(&quot;HTTPStatus&quot;)) # h_t_t_p_status</pre><p>It was suppose to convert HTTPStatus to http_status. To handle this case, we need a different approach.</p><h4>Advanced Cases (Not Reversible)</h4><p>These cases is <strong>not reversible</strong>, once we convert HTTPStatus to http_status, There is no way we can convert back to HTTPStatus. Also two steps to get itÂ done:</p><ol><li>Looks for every upper case letter that following lower case letter ( letter C in snakeCase ) or followed by lower case letter (letter S in HTTPStatus ), then insert a underscore seperator beforeÂ each.</li><li>Converts string to lowerÂ case.</li></ol><p>Here is theÂ script:</p><pre>ADVANCED_CAMEL_PATTERN = re.compile(r&#39;(?&lt;=[a-z])[A-Z]|(?&lt;!^)[A-Z](?=[a-z])&#39;)<br>def advanced_camel_to_snake(name):<br>    return re.sub(ADVANCED_CAMEL_PATTERN, r&quot;_\\g&lt;0&gt;&quot;, name).lower()<br><br>print(advanced_camel_to_snake(&quot;snakeCase&quot;)) # snake_case<br>print(advanced_camel_to_snake(&quot;SnakeCase&quot;))  # snake_case<br>print(advanced_camel_to_snake(&quot;HTTPStatus&quot;)) # http_status<br>print(advanced_camel_to_snake(&quot;HTTPStatusXYZ&quot;)) # http_status_xyz<br>print(advanced_camel_to_snake(&quot;getHTTPStatus&quot;)) # get_http_status<br>print(advanced_camel_to_snake(&quot;GetHTTPStatus&quot;)) # get_http_status</pre><h3>Conclusion</h3><p>Weâ€™ve covered code snippets for converting between snake case, camel case and pascal case. I put all of the converting functions together asÂ below:</p><iframe src=\"\" width=\"0\" height=\"0\" frameborder=\"0\" scrolling=\"no\"><a href=\"https://medium.com/media/c0ae932bbd2bffeb19a2c7a0a42b07d1/href\">https://medium.com/media/c0ae932bbd2bffeb19a2c7a0a42b07d1/href</a></iframe><h3>Jason ğŸš€</h3><p><em>Thank you for reading until the end. Before youÂ go:</em></p><p>ğŸ‘ Please <strong><em>Clap</em></strong> and <strong><em>follow</em></strong>Â me</p><p>ğŸ“¬ <a href=\"https://medium.com/@xuzhusheng/subscribe\">Subscribe</a> to my Medium newsletter for emailÂ updates!</p><p>â˜• or just <a href=\"https://www.buymeacoffee.com/jason.xu\">buy me aÂ coffee</a></p><h3>In Plain EnglishÂ ğŸš€</h3><p><em>Thank you for being a part of the </em><a href=\"https://plainenglish.io\"><strong><em>In Plain English</em></strong></a><em> community! Before youÂ go:</em></p><ul><li>Be sure to <strong>clap</strong> and <strong>follow</strong> the writerÂ ï¸ğŸ‘<strong>ï¸ï¸</strong></li><li>Follow us: <a href=\"https://twitter.com/inPlainEngHQ\"><strong>X</strong></a><strong> | </strong><a href=\"https://www.linkedin.com/company/inplainenglish/\"><strong>LinkedIn</strong></a><strong> | </strong><a href=\"https://www.youtube.com/channel/UCtipWUghju290NWcn8jhyAw\"><strong>YouTube</strong></a><strong> | </strong><a href=\"https://discord.gg/in-plain-english-709094664682340443\"><strong>Discord</strong></a><strong> | </strong><a href=\"https://newsletter.plainenglish.io/\"><strong>Newsletter</strong></a></li><li>Visit our other platforms: <a href=\"https://stackademic.com/\"><strong>Stackademic</strong></a><strong> | </strong><a href=\"https://cofeed.app/\"><strong>CoFeed</strong></a><strong> | </strong><a href=\"https://venturemagazine.net/\"><strong>Venture</strong></a><strong> |Â </strong><a href=\"https://blog.cubed.run\"><strong>Cubed</strong></a></li><li>More content at <a href=\"https://plainenglish.io\"><strong>PlainEnglish.io</strong></a></li></ul><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=2d91032bd0dc\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://python.plainenglish.io/converting-between-naming-convention-with-python-2d91032bd0dc\">Converting between Snake Case and Camel Case</a> was originally published in <a href=\"https://python.plainenglish.io\">Python in Plain English</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>","media":{}},{"id":"https://medium.com/p/05805e5c1e39","title":"Loads millions of Rows into MySQL in Seconds","link":"https://python.plainenglish.io/how-to-load-millions-of-rows-csv-data-into-mysql-in-seconds-05805e5c1e39?source=rss-41bd992616fb------2","author":"Jason","published":1706441559000,"created":1706441559000,"category":["pandas","mysql","python","data-science","sql"],"content":"<h4>Data Manipulation</h4><h4>Two efficient methods to load millions of rows CSV data into MySQL in severalÂ seconds</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*8OY5u8tQOpR10Jep\" /><figcaption>Photo by <a href=\"https://unsplash.com/@sortino?utm_source=medium&amp;utm_medium=referral\">Joshua Sortino</a> onÂ <a href=\"https://unsplash.com?utm_source=medium&amp;utm_medium=referral\">Unsplash</a></figcaption></figure><p>When we are doing data migrations or data cleaning, we might need to load millions of rows CSV data in to database. MySQL is one of the most popular database management system in theÂ world.</p><p>In this article, we will cover two efficient methods to load CSV data toÂ MySQL.</p><h3>Requirement</h3><h4>Preparing Data</h4><p>Suppose we need to load a person.csv file with millions of rows records to MySQL database table. Here is a sampleÂ file:</p><iframe src=\"\" width=\"0\" height=\"0\" frameborder=\"0\" scrolling=\"no\"><a href=\"https://medium.com/media/d36a65ec9a2e13c8c8db5cce4457ebb9/href\">https://medium.com/media/d36a65ec9a2e13c8c8db5cce4457ebb9/href</a></iframe><p>In real practic, our data might exported from another database system or scraped from web. For scraping data from web pages, pleaseÂ read:</p><p><a href=\"https://xuzhusheng.medium.com/playwright-web-scrapping-in-python-2024-def04f46a129\">Scrapes Interactive Pages with Playwright in Python</a></p><p>In this article, we generages csv file with Faker. The generation scripts asÂ below:</p><pre>from aiofile import async_open<br>from faker import Faker<br><br>Faker.seed(2024)    <br>faker = Faker()<br>async with async_open(&quot;person.csv&quot;, &quot;w&quot;, encoding=&quot;UTF-8&quot;) as af:<br>    await af.write(&quot;name, age, birthday, phone_number, email\\n&quot;)<br>    for _ in range(1000000):<br>        name = faker.name()<br>        age = faker.pyint(1, 115)<br>        birthday = faker.date_of_birth(minimum_age=1, maximum_age=115)<br>        phone_number = faker.phone_number()<br>        email = faker.ascii_free_email()<br>        line = f&#39;{name}, {age}, {birthday}, {phone_number}, {email}\\n&#39;<br>        await af.write(line)</pre><h4>Creating Table</h4><p>We need a table with corresponding columns and a id as primary key asÂ below:</p><iframe src=\"\" width=\"0\" height=\"0\" frameborder=\"0\" scrolling=\"no\"><a href=\"https://medium.com/media/050a105f26c1afa71a3f11fcbadd20a3/href\">https://medium.com/media/050a105f26c1afa71a3f11fcbadd20a3/href</a></iframe><p>Here is the SQLÂ scripts:</p><pre>CREATE TABLE person (<br>    `id` INT auto_increment primary key,<br>    `name` VARCHAR(255) NOT NULL,<br>    `age` TINYINT,<br>    `birthday` DATE NOT NULL,<br>    `phone_number` VARCHAR(30),<br>    `email` VARCHAR(255)<br>);</pre><h3>Loading Data intoÂ MySQL</h3><p>Using the LOAD DATA statement is one of the most efficient methods to load data into MySQL. Letâ€™s cover this methodÂ first.</p><h4>Using LOAD DATA statement</h4><p>Here is the LOAD DATAÂ scripts:</p><pre>LOAD DATA LOCAL<br>    INFILE &#39;person.csv&#39;<br>    INTO TABLE `person`<br>    FIELDS TERMINATED by &#39;,&#39;<br>    LINES TERMINATED by &#39;\\n&#39;<br>    IGNORE 1 LINES<br>    (name, age, birthday, phone_number, email);</pre><p><strong>Codes walkÂ through:</strong></p><ul><li>LOCAL specifies load data from client machine - LOAD DATAÂ LOCAL</li><li>CSV file path - INFILE &#39;person.csv&#39;</li><li>Destination table - INTO TABLEÂ person</li><li>CSV Delimiter - FIELDS TERMINATED byÂ &#39;,&#39;</li><li>Line breaker - LINES TERMINATED byÂ &#39;\\n&#39;</li><li>Ignore header - IGNORE 1Â LINES</li><li>Column mapping - (name, age, birthday, phone_number, email)</li></ul><p>The local data loading is disabled by default. We can enable it by set the global variable local_infile =Â &#39;ON&#39;</p><pre>set global local_infile = &#39;ON&#39;</pre><p>Run the script, all of the data in csv file will be loaded into mysql table. The loading take<strong> 6 - 7 seconds</strong> on my computer.</p><p>Using LOAD DATA statement is alway my first option to load huge data into mysql. But what if we are not allowed to enable the local data loading setting? Is there otherÂ options?</p><h4>Using pandas</h4><p>pandas is a fast and easy to use open source data analysis and manipulation python library. With pandas, it need just serval line of codes to get our taskÂ done.</p><p>Before getting start, we need to install libraries: spandas, sqlalchemy and mysqlclient. Pandas need sqlalchemy and mysqlclient to connect to MySQL database. The installation command asÂ below.</p><pre>pip install pandas<br>pip install sqlalchemy<br>pip install mysqlclient</pre><p>The load data scripts with pandas is very simple. Letâ€™s get intoÂ it.</p><pre>import pandas as pd<br>from sqlalchemy import create_engine<br><br>df = pd.read_csv(&quot;person.csv&quot;, skipinitialspace=True)<br>engine = create_engine(&#39;mysql://root@127.0.0.1/db&#39;)<br>df.to_sql(name=&#39;person&#39;, con=engine, if_exists=&#39;append&#39;, index=False)</pre><p><strong>Codes walkÂ through:</strong></p><ul><li>Import the necessary libraries - the first twoÂ lines</li><li>Read csv file by pd.read_csv(file) - df = pd.read_csv(â€œperson.csvâ€, skipinitialspace=True)</li><li>Create engine for database connection by create_engine(url) - engine = create_engine(â€˜mysql://root@127.0.0.1/dbâ€™)</li><li>Load data into MySQL database - df.to_sql(name=â€™personâ€™, con=engine, if_exists=â€™appendâ€™, index=False)</li></ul><p>This loading take <strong>22â€“24 seconds</strong> on my computer. It is slower, but it is simple and generic, easy to adapt to other source file format or database.</p><p>We covered two methods for loading data with one million rows. What if there are much more data, hundres of millions rowsÂ data?</p><h3>Loading Hundreds of Millions Rows CSVÂ data</h3><p>It is not feasible to load a file with hundres of millions row. In this case, we can split it into many files with one million rows, then load file with above methods. This can be done by the splitÂ command.</p><pre> split -d -l 1000000 person.csv person_ --additional-suffix .csv</pre><h3>Conclusion</h3><p>Weâ€™ve covered two efficient methods to load huge csv data into mysql database.</p><p>Using LOAD DATA statement is much more faster, but need permission to configurate database server, so that we can enable local data load. When we permission and the loading time is really crucial, using LOAD DATA statement is ourÂ choice.</p><p>When we are dealing with varied source file format or varied database, using pandas is more simple and adaptable.</p><h3>Jason ğŸš€</h3><p><em>Thank you for reading until the end. Before youÂ go:</em></p><p>ğŸ‘ Please <strong><em>Clap</em></strong> and <strong><em>follow</em></strong>Â me</p><p>ğŸ“¬ <a href=\"https://medium.com/@xuzhusheng/subscribe\">Subscribe</a> to my Medium newsletter for emailÂ updates!</p><p>â˜• or just <a href=\"https://www.buymeacoffee.com/jason.xu\">buy me aÂ coffee</a></p><h3>In Plain EnglishÂ ğŸš€</h3><p><em>Thank you for being a part of the </em><a href=\"https://plainenglish.io\"><strong><em>In Plain English</em></strong></a><em> community! Before youÂ go:</em></p><ul><li>Be sure to <strong>clap</strong> and <strong>follow</strong> the writerÂ ï¸ğŸ‘<strong>ï¸ï¸</strong></li><li>Follow us: <a href=\"https://twitter.com/inPlainEngHQ\"><strong>X</strong></a><strong> | </strong><a href=\"https://www.linkedin.com/company/inplainenglish/\"><strong>LinkedIn</strong></a><strong> | </strong><a href=\"https://www.youtube.com/channel/UCtipWUghju290NWcn8jhyAw\"><strong>YouTube</strong></a><strong> | </strong><a href=\"https://discord.gg/in-plain-english-709094664682340443\"><strong>Discord</strong></a><strong> | </strong><a href=\"https://newsletter.plainenglish.io/\"><strong>Newsletter</strong></a></li><li>Visit our other platforms: <a href=\"https://stackademic.com/\"><strong>Stackademic</strong></a><strong> | </strong><a href=\"https://cofeed.app/\"><strong>CoFeed</strong></a><strong> | </strong><a href=\"https://venturemagazine.net/\"><strong>Venture</strong></a><strong> |Â </strong><a href=\"https://blog.cubed.run\"><strong>Cubed</strong></a></li><li>More content at <a href=\"https://plainenglish.io\"><strong>PlainEnglish.io</strong></a></li></ul><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=05805e5c1e39\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://python.plainenglish.io/how-to-load-millions-of-rows-csv-data-into-mysql-in-seconds-05805e5c1e39\">Loads millions of Rows into MySQL in Seconds</a> was originally published in <a href=\"https://python.plainenglish.io\">Python in Plain English</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>","enclosures":[],"content_encoded":"<h4>Data Manipulation</h4><h4>Two efficient methods to load millions of rows CSV data into MySQL in severalÂ seconds</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*8OY5u8tQOpR10Jep\" /><figcaption>Photo by <a href=\"https://unsplash.com/@sortino?utm_source=medium&amp;utm_medium=referral\">Joshua Sortino</a> onÂ <a href=\"https://unsplash.com?utm_source=medium&amp;utm_medium=referral\">Unsplash</a></figcaption></figure><p>When we are doing data migrations or data cleaning, we might need to load millions of rows CSV data in to database. MySQL is one of the most popular database management system in theÂ world.</p><p>In this article, we will cover two efficient methods to load CSV data toÂ MySQL.</p><h3>Requirement</h3><h4>Preparing Data</h4><p>Suppose we need to load a person.csv file with millions of rows records to MySQL database table. Here is a sampleÂ file:</p><iframe src=\"\" width=\"0\" height=\"0\" frameborder=\"0\" scrolling=\"no\"><a href=\"https://medium.com/media/d36a65ec9a2e13c8c8db5cce4457ebb9/href\">https://medium.com/media/d36a65ec9a2e13c8c8db5cce4457ebb9/href</a></iframe><p>In real practic, our data might exported from another database system or scraped from web. For scraping data from web pages, pleaseÂ read:</p><p><a href=\"https://xuzhusheng.medium.com/playwright-web-scrapping-in-python-2024-def04f46a129\">Scrapes Interactive Pages with Playwright in Python</a></p><p>In this article, we generages csv file with Faker. The generation scripts asÂ below:</p><pre>from aiofile import async_open<br>from faker import Faker<br><br>Faker.seed(2024)    <br>faker = Faker()<br>async with async_open(&quot;person.csv&quot;, &quot;w&quot;, encoding=&quot;UTF-8&quot;) as af:<br>    await af.write(&quot;name, age, birthday, phone_number, email\\n&quot;)<br>    for _ in range(1000000):<br>        name = faker.name()<br>        age = faker.pyint(1, 115)<br>        birthday = faker.date_of_birth(minimum_age=1, maximum_age=115)<br>        phone_number = faker.phone_number()<br>        email = faker.ascii_free_email()<br>        line = f&#39;{name}, {age}, {birthday}, {phone_number}, {email}\\n&#39;<br>        await af.write(line)</pre><h4>Creating Table</h4><p>We need a table with corresponding columns and a id as primary key asÂ below:</p><iframe src=\"\" width=\"0\" height=\"0\" frameborder=\"0\" scrolling=\"no\"><a href=\"https://medium.com/media/050a105f26c1afa71a3f11fcbadd20a3/href\">https://medium.com/media/050a105f26c1afa71a3f11fcbadd20a3/href</a></iframe><p>Here is the SQLÂ scripts:</p><pre>CREATE TABLE person (<br>    `id` INT auto_increment primary key,<br>    `name` VARCHAR(255) NOT NULL,<br>    `age` TINYINT,<br>    `birthday` DATE NOT NULL,<br>    `phone_number` VARCHAR(30),<br>    `email` VARCHAR(255)<br>);</pre><h3>Loading Data intoÂ MySQL</h3><p>Using the LOAD DATA statement is one of the most efficient methods to load data into MySQL. Letâ€™s cover this methodÂ first.</p><h4>Using LOAD DATA statement</h4><p>Here is the LOAD DATAÂ scripts:</p><pre>LOAD DATA LOCAL<br>    INFILE &#39;person.csv&#39;<br>    INTO TABLE `person`<br>    FIELDS TERMINATED by &#39;,&#39;<br>    LINES TERMINATED by &#39;\\n&#39;<br>    IGNORE 1 LINES<br>    (name, age, birthday, phone_number, email);</pre><p><strong>Codes walkÂ through:</strong></p><ul><li>LOCAL specifies load data from client machine - LOAD DATAÂ LOCAL</li><li>CSV file path - INFILE &#39;person.csv&#39;</li><li>Destination table - INTO TABLEÂ person</li><li>CSV Delimiter - FIELDS TERMINATED byÂ &#39;,&#39;</li><li>Line breaker - LINES TERMINATED byÂ &#39;\\n&#39;</li><li>Ignore header - IGNORE 1Â LINES</li><li>Column mapping - (name, age, birthday, phone_number, email)</li></ul><p>The local data loading is disabled by default. We can enable it by set the global variable local_infile =Â &#39;ON&#39;</p><pre>set global local_infile = &#39;ON&#39;</pre><p>Run the script, all of the data in csv file will be loaded into mysql table. The loading take<strong> 6 - 7 seconds</strong> on my computer.</p><p>Using LOAD DATA statement is alway my first option to load huge data into mysql. But what if we are not allowed to enable the local data loading setting? Is there otherÂ options?</p><h4>Using pandas</h4><p>pandas is a fast and easy to use open source data analysis and manipulation python library. With pandas, it need just serval line of codes to get our taskÂ done.</p><p>Before getting start, we need to install libraries: spandas, sqlalchemy and mysqlclient. Pandas need sqlalchemy and mysqlclient to connect to MySQL database. The installation command asÂ below.</p><pre>pip install pandas<br>pip install sqlalchemy<br>pip install mysqlclient</pre><p>The load data scripts with pandas is very simple. Letâ€™s get intoÂ it.</p><pre>import pandas as pd<br>from sqlalchemy import create_engine<br><br>df = pd.read_csv(&quot;person.csv&quot;, skipinitialspace=True)<br>engine = create_engine(&#39;mysql://root@127.0.0.1/db&#39;)<br>df.to_sql(name=&#39;person&#39;, con=engine, if_exists=&#39;append&#39;, index=False)</pre><p><strong>Codes walkÂ through:</strong></p><ul><li>Import the necessary libraries - the first twoÂ lines</li><li>Read csv file by pd.read_csv(file) - df = pd.read_csv(â€œperson.csvâ€, skipinitialspace=True)</li><li>Create engine for database connection by create_engine(url) - engine = create_engine(â€˜mysql://root@127.0.0.1/dbâ€™)</li><li>Load data into MySQL database - df.to_sql(name=â€™personâ€™, con=engine, if_exists=â€™appendâ€™, index=False)</li></ul><p>This loading take <strong>22â€“24 seconds</strong> on my computer. It is slower, but it is simple and generic, easy to adapt to other source file format or database.</p><p>We covered two methods for loading data with one million rows. What if there are much more data, hundres of millions rowsÂ data?</p><h3>Loading Hundreds of Millions Rows CSVÂ data</h3><p>It is not feasible to load a file with hundres of millions row. In this case, we can split it into many files with one million rows, then load file with above methods. This can be done by the splitÂ command.</p><pre> split -d -l 1000000 person.csv person_ --additional-suffix .csv</pre><h3>Conclusion</h3><p>Weâ€™ve covered two efficient methods to load huge csv data into mysql database.</p><p>Using LOAD DATA statement is much more faster, but need permission to configurate database server, so that we can enable local data load. When we permission and the loading time is really crucial, using LOAD DATA statement is ourÂ choice.</p><p>When we are dealing with varied source file format or varied database, using pandas is more simple and adaptable.</p><h3>Jason ğŸš€</h3><p><em>Thank you for reading until the end. Before youÂ go:</em></p><p>ğŸ‘ Please <strong><em>Clap</em></strong> and <strong><em>follow</em></strong>Â me</p><p>ğŸ“¬ <a href=\"https://medium.com/@xuzhusheng/subscribe\">Subscribe</a> to my Medium newsletter for emailÂ updates!</p><p>â˜• or just <a href=\"https://www.buymeacoffee.com/jason.xu\">buy me aÂ coffee</a></p><h3>In Plain EnglishÂ ğŸš€</h3><p><em>Thank you for being a part of the </em><a href=\"https://plainenglish.io\"><strong><em>In Plain English</em></strong></a><em> community! Before youÂ go:</em></p><ul><li>Be sure to <strong>clap</strong> and <strong>follow</strong> the writerÂ ï¸ğŸ‘<strong>ï¸ï¸</strong></li><li>Follow us: <a href=\"https://twitter.com/inPlainEngHQ\"><strong>X</strong></a><strong> | </strong><a href=\"https://www.linkedin.com/company/inplainenglish/\"><strong>LinkedIn</strong></a><strong> | </strong><a href=\"https://www.youtube.com/channel/UCtipWUghju290NWcn8jhyAw\"><strong>YouTube</strong></a><strong> | </strong><a href=\"https://discord.gg/in-plain-english-709094664682340443\"><strong>Discord</strong></a><strong> | </strong><a href=\"https://newsletter.plainenglish.io/\"><strong>Newsletter</strong></a></li><li>Visit our other platforms: <a href=\"https://stackademic.com/\"><strong>Stackademic</strong></a><strong> | </strong><a href=\"https://cofeed.app/\"><strong>CoFeed</strong></a><strong> | </strong><a href=\"https://venturemagazine.net/\"><strong>Venture</strong></a><strong> |Â </strong><a href=\"https://blog.cubed.run\"><strong>Cubed</strong></a></li><li>More content at <a href=\"https://plainenglish.io\"><strong>PlainEnglish.io</strong></a></li></ul><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=05805e5c1e39\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://python.plainenglish.io/how-to-load-millions-of-rows-csv-data-into-mysql-in-seconds-05805e5c1e39\">Loads millions of Rows into MySQL in Seconds</a> was originally published in <a href=\"https://python.plainenglish.io\">Python in Plain English</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>","media":{}},{"id":"https://medium.com/p/def04f46a129","title":"Scraping Interactive Pages with Playwright in Python","link":"https://python.plainenglish.io/playwright-web-scrapping-in-python-2024-def04f46a129?source=rss-41bd992616fb------2","author":"Jason","published":1705919391000,"created":1705919391000,"category":["web-scraping","python","playwrights","programming","web-automation"],"content":"<h4>Web Scraping</h4><h4>Explore how to scrape dynamic interactive pages with scrolling and infinite pagination with a practical example.</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*KI3ciuhZYqQ-NwU7\" /><figcaption>Photo by <a href=\"https://unsplash.com/@lucabravo?utm_source=medium&amp;utm_medium=referral\">Luca Bravo</a> onÂ <a href=\"https://unsplash.com?utm_source=medium&amp;utm_medium=referral\">Unsplash</a></figcaption></figure><p>In this article, we are going to explore how to scrape dynamic page with scrolling and infinite pagination. We scrape pages with Playwright inÂ Python.</p><p>We are going to build a scraper to scrape the historical Snapshot of 21 January 2024 from <a href=\"https://coinmarketcap.com/historical/20240121/\">CoinMarketCap</a>. At the end of this article, we will get a CSV file asÂ below.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Smq1wbAWf4QJu-yGHoq7Pg.png\" /><figcaption>CSV FileÂ Snapshot</figcaption></figure><h3>What is Playwright</h3><p>Playwright is an open-source cross-platform library built on Node.js. But it is compatible with most popular programming languages, such as Node.js, Python, Java, andÂ .NET. You can use playwright with any of these languages youÂ like.</p><p>Playwright was created for end-to-end testing, it is perfectly capable of browser automation and web scraping. Playwright web scraping has become one of the most popular searched topics recently.</p><h3><strong>Installing Playwright</strong></h3><p>Install playwright is very simple. All we need is install the playwright library by pipcommand and the install the necessary browsers byplaywright install command:Â pip</p><pre>pip install playwright<br>playwright install</pre><h3>First Playwright script.</h3><p>Playwright supports both synchronous api and asynchronous api. Letâ€™s using asynchronous api to create a basic script to open a dynamic page asÂ follows.</p><iframe src=\"\" width=\"0\" height=\"0\" frameborder=\"0\" scrolling=\"no\"><a href=\"https://medium.com/media/504f6982c229c3f3a8471f4585e388d3/href\">https://medium.com/media/504f6982c229c3f3a8471f4585e388d3/href</a></iframe><p><strong>Codes walkÂ through:</strong></p><ol><li>Imports playwright asynchronous API. (lineÂ 1)</li><li>Launches a chromium browser and open a new page. (line 5â€Šâ€”â€ŠlineÂ 7).</li><li>Navigates to the target page by page.goto() function. (lineÂ 8)</li><li>Captures the screenshot and saves into â€œscreenshot.pngâ€. (lineÂ 9)</li><li>Close the browser at the end. ï¼ˆlineÂ 10ï¼‰</li></ol><p>Run the script, we will get a screenshot asÂ below:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*rtU6gpe0zu8AgcNC_htPqg.png\" /><figcaption>Screenshot</figcaption></figure><p>Data in the table is what we are going to scrap in nextÂ section.</p><h3><strong>Locating elements and Extracting data</strong></h3><p>The first step to extract data from any element is locate the element. Playwright use locators to locate elements on theÂ page.</p><p>Locators are the central piece of Playwrightâ€™s ability to locate elements and perform actions automated. Some built in locators of playwright sumarized below.</p><p><strong>Built in locators of playwright summary</strong></p><ul><li>page.get_by_role() to locate by explicit and implicit accessibility attributes.</li><li>page.get_by_text() to locate by textÂ content.</li><li>page.get_by_label() to locate a form control by associated labelâ€™sÂ text.</li><li>page.get_by_placeholder() to locate an input by placeholder.</li><li>page.get_by_alt_text()to locate an element, usually image, by its text alternative.</li><li>page.get_by_title() to locate an element by its title attribute.</li><li>page.get_by_test_id() to locate an element based on its data-testid attribute (other attributes can be configured).</li></ul><p>We are going to locate table header element by page.locator() and retireve the header text by locator.inner_text():</p><pre>header = await page.locator(&quot;thead tr&quot;).inner_text()<br>print(header)</pre><p>If we run the script to check result, we will get anÂ error:</p><pre>Error: strict mode violation: locator(â€œthead trâ€) resolved to 3 elements</pre><p>There are three table header elements in the page, we need only the visible one. We filter the rest by locator.locator(&quot;visible=true). The completed codes asÂ below:</p><pre>header = await page.locator(&quot;thead tr&quot;).locator(&quot;visible=true&quot;).inner_text()<br>print(header)</pre><p>Rerun the script, we could see the header text printed asÂ below:</p><pre>Rank Name Symbol Market Cap Price Circulating Supply volume (24h) % 1h % 24h % 7d</pre><p>Letâ€™s get into the whole scripts than locates table elements and retrieves corresponding text.</p><iframe src=\"\" width=\"0\" height=\"0\" frameborder=\"0\" scrolling=\"no\"><a href=\"https://medium.com/media/eb42a068b6ca298a3292822233b745ff/href\">https://medium.com/media/eb42a068b6ca298a3292822233b745ff/href</a></iframe><p><strong>Codes walkÂ through:</strong></p><ol><li>Navigates to the target page. This is the same as first script above. (line 1 - line 10Â )</li><li>Locates the table header and extracts the header text by locator.inner_text() function. (lineÂ 11)</li><li>Locates all rows of the table body. (lineÂ 13)</li><li>Extracts row text and reformat it to print on the screen in a loop. (lineÂ 14â€“18)</li></ol><p>It seems quite simple. Letâ€™s run this example and check theÂ result.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*AvYaK4Ie3ep-IcUJvN2mTQ.png\" /></figure><p>We got only 20 rows. The rest data is missing. The page load rows visible on screen only. We need to scroll down, so that it could load the restÂ data.</p><h3><strong>Scrolling and Infinite Pagination</strong></h3><p>Scrolling could be done easy by add row.scroll_into_view_if_needed() before inner_text = await row.inner_text().</p><p>The trick part is pagination. At the bottom of the page, there is a â€œLoad Moreâ€Â button.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Wx1OrTPpP2ywHJESunmLGg.png\" /></figure><p>What we need to do is keep clicking the â€œLoad Moreâ€ button while is clickable. The â€œLoad Moreâ€ scripts asÂ below:</p><pre>async def has_next_page():<br>    try:<br>        await page.get_by_role(&quot;button&quot;, name=&quot;Load More&quot;).click(trial = True)<br>        return True<br>    except:<br>        return False<br>                        <br>async def load_next_page():<br>    current_page = 1<br>    while await has_next_page():<br>        try:<br>            yield current_page<br>            await page.get_by_role(&quot;button&quot;, name=&quot;Load More&quot;).click(force=True)<br>            current_page += 1<br>        except:<br>            ...<br>    yield current_page</pre><p><strong>Codes walkÂ through</strong></p><ol><li>Function has_next_page() waits for the â€œLoad Moreâ€ button to be clickable then return Ture. Or return False if any exception. By setting (trial = True), the click() fucntion perform only actionable checks and skips the clickÂ action.</li><li>While the â€œLoad Moreâ€ button is clickable, each time function load_next_page() is called, it clicks the â€œLoad Moreâ€ button to load next pageÂ data.</li></ol><p>Letâ€™s do some refactoring, extracts locates elements and extracts data codes to a data() function. And put the pagnitions codes together.</p><pre>async def data():  <br>    <br>    yield await page.locator(&quot;thead tr&quot;).locator(&quot;visible=true&quot;).inner_text()<br>    <br>    current_row = 0<br>    async for _ in load_next_page():<br>        rows = await page.locator(&quot;tbody tr&quot;).all()<br>        rows = rows[current_row:]<br>        <br>        for row in rows:<br>            await row.wait_for(timeout=0)<br>            await row.scroll_into_view_if_needed(timeout=0)<br>            yield await row.inner_text()<br>            current_row += 1 </pre><p>The current_row index indicates the next row to be parsed. After the â€œLoad Moreâ€ button is clicked, it parses rows start from current_row to theÂ end.</p><p>The final thing, we save the extracted data in a csv file instead of print it on screen and add a progress bar by tqdm. The completed codes asÂ below:</p><iframe src=\"\" width=\"0\" height=\"0\" frameborder=\"0\" scrolling=\"no\"><a href=\"https://medium.com/media/c86b8cf1e7087305f5408b6b320c61a7/href\">https://medium.com/media/c86b8cf1e7087305f5408b6b320c61a7/href</a></iframe><h3>Whatâ€™s Next</h3><p>In this article, we store scraped data into a CSV file. But in real scraping practic, we deal with thounds of millions of pages, instead of storing data in CSV files, we usually store data into database. One of the most popular database management system MySQL. For loading CSV data into MySQL efficiently, read myÂ article:</p><p><a href=\"https://xuzhusheng.medium.com/how-to-load-millions-of-rows-csv-data-into-mysql-in-seconds-05805e5c1e39\">Loads millions of Records into MySQL in Seconds</a></p><h3>Jason ğŸš€</h3><p><em>Thank you for reading until the end. Before youÂ go:</em></p><p>ğŸ‘ Please <strong><em>Clap</em></strong> and <strong><em>follow</em></strong>Â me</p><p>ğŸ“¬ <a href=\"https://medium.com/@xuzhusheng/subscribe\">Subscribe</a> to my Medium newsletter for emailÂ updates!</p><p>â˜• or just <a href=\"https://www.buymeacoffee.com/jason.xu\">buy me aÂ coffee</a></p><h3>In Plain EnglishÂ ğŸš€</h3><p><em>Thank you for being a part of the </em><a href=\"https://plainenglish.io\"><strong><em>In Plain English</em></strong></a><em> community! Before youÂ go:</em></p><ul><li>Be sure to <strong>clap</strong> and <strong>follow</strong> the writerÂ ï¸ğŸ‘<strong>ï¸ï¸</strong></li><li>Follow us: <a href=\"https://twitter.com/inPlainEngHQ\"><strong>X</strong></a><strong> | </strong><a href=\"https://www.linkedin.com/company/inplainenglish/\"><strong>LinkedIn</strong></a><strong> | </strong><a href=\"https://www.youtube.com/channel/UCtipWUghju290NWcn8jhyAw\"><strong>YouTube</strong></a><strong> | </strong><a href=\"https://discord.gg/in-plain-english-709094664682340443\"><strong>Discord</strong></a><strong> | </strong><a href=\"https://newsletter.plainenglish.io/\"><strong>Newsletter</strong></a></li><li>Visit our other platforms: <a href=\"https://stackademic.com/\"><strong>Stackademic</strong></a><strong> | </strong><a href=\"https://cofeed.app/\"><strong>CoFeed</strong></a><strong> | </strong><a href=\"https://venturemagazine.net/\"><strong>Venture</strong></a><strong> |Â </strong><a href=\"https://blog.cubed.run\"><strong>Cubed</strong></a></li><li>More content at <a href=\"https://plainenglish.io\"><strong>PlainEnglish.io</strong></a></li></ul><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=def04f46a129\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://python.plainenglish.io/playwright-web-scrapping-in-python-2024-def04f46a129\">Scraping Interactive Pages with Playwright in Python</a> was originally published in <a href=\"https://python.plainenglish.io\">Python in Plain English</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>","enclosures":[],"content_encoded":"<h4>Web Scraping</h4><h4>Explore how to scrape dynamic interactive pages with scrolling and infinite pagination with a practical example.</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*KI3ciuhZYqQ-NwU7\" /><figcaption>Photo by <a href=\"https://unsplash.com/@lucabravo?utm_source=medium&amp;utm_medium=referral\">Luca Bravo</a> onÂ <a href=\"https://unsplash.com?utm_source=medium&amp;utm_medium=referral\">Unsplash</a></figcaption></figure><p>In this article, we are going to explore how to scrape dynamic page with scrolling and infinite pagination. We scrape pages with Playwright inÂ Python.</p><p>We are going to build a scraper to scrape the historical Snapshot of 21 January 2024 from <a href=\"https://coinmarketcap.com/historical/20240121/\">CoinMarketCap</a>. At the end of this article, we will get a CSV file asÂ below.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Smq1wbAWf4QJu-yGHoq7Pg.png\" /><figcaption>CSV FileÂ Snapshot</figcaption></figure><h3>What is Playwright</h3><p>Playwright is an open-source cross-platform library built on Node.js. But it is compatible with most popular programming languages, such as Node.js, Python, Java, andÂ .NET. You can use playwright with any of these languages youÂ like.</p><p>Playwright was created for end-to-end testing, it is perfectly capable of browser automation and web scraping. Playwright web scraping has become one of the most popular searched topics recently.</p><h3><strong>Installing Playwright</strong></h3><p>Install playwright is very simple. All we need is install the playwright library by pipcommand and the install the necessary browsers byplaywright install command:Â pip</p><pre>pip install playwright<br>playwright install</pre><h3>First Playwright script.</h3><p>Playwright supports both synchronous api and asynchronous api. Letâ€™s using asynchronous api to create a basic script to open a dynamic page asÂ follows.</p><iframe src=\"\" width=\"0\" height=\"0\" frameborder=\"0\" scrolling=\"no\"><a href=\"https://medium.com/media/504f6982c229c3f3a8471f4585e388d3/href\">https://medium.com/media/504f6982c229c3f3a8471f4585e388d3/href</a></iframe><p><strong>Codes walkÂ through:</strong></p><ol><li>Imports playwright asynchronous API. (lineÂ 1)</li><li>Launches a chromium browser and open a new page. (line 5â€Šâ€”â€ŠlineÂ 7).</li><li>Navigates to the target page by page.goto() function. (lineÂ 8)</li><li>Captures the screenshot and saves into â€œscreenshot.pngâ€. (lineÂ 9)</li><li>Close the browser at the end. ï¼ˆlineÂ 10ï¼‰</li></ol><p>Run the script, we will get a screenshot asÂ below:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*rtU6gpe0zu8AgcNC_htPqg.png\" /><figcaption>Screenshot</figcaption></figure><p>Data in the table is what we are going to scrap in nextÂ section.</p><h3><strong>Locating elements and Extracting data</strong></h3><p>The first step to extract data from any element is locate the element. Playwright use locators to locate elements on theÂ page.</p><p>Locators are the central piece of Playwrightâ€™s ability to locate elements and perform actions automated. Some built in locators of playwright sumarized below.</p><p><strong>Built in locators of playwright summary</strong></p><ul><li>page.get_by_role() to locate by explicit and implicit accessibility attributes.</li><li>page.get_by_text() to locate by textÂ content.</li><li>page.get_by_label() to locate a form control by associated labelâ€™sÂ text.</li><li>page.get_by_placeholder() to locate an input by placeholder.</li><li>page.get_by_alt_text()to locate an element, usually image, by its text alternative.</li><li>page.get_by_title() to locate an element by its title attribute.</li><li>page.get_by_test_id() to locate an element based on its data-testid attribute (other attributes can be configured).</li></ul><p>We are going to locate table header element by page.locator() and retireve the header text by locator.inner_text():</p><pre>header = await page.locator(&quot;thead tr&quot;).inner_text()<br>print(header)</pre><p>If we run the script to check result, we will get anÂ error:</p><pre>Error: strict mode violation: locator(â€œthead trâ€) resolved to 3 elements</pre><p>There are three table header elements in the page, we need only the visible one. We filter the rest by locator.locator(&quot;visible=true). The completed codes asÂ below:</p><pre>header = await page.locator(&quot;thead tr&quot;).locator(&quot;visible=true&quot;).inner_text()<br>print(header)</pre><p>Rerun the script, we could see the header text printed asÂ below:</p><pre>Rank Name Symbol Market Cap Price Circulating Supply volume (24h) % 1h % 24h % 7d</pre><p>Letâ€™s get into the whole scripts than locates table elements and retrieves corresponding text.</p><iframe src=\"\" width=\"0\" height=\"0\" frameborder=\"0\" scrolling=\"no\"><a href=\"https://medium.com/media/eb42a068b6ca298a3292822233b745ff/href\">https://medium.com/media/eb42a068b6ca298a3292822233b745ff/href</a></iframe><p><strong>Codes walkÂ through:</strong></p><ol><li>Navigates to the target page. This is the same as first script above. (line 1 - line 10Â )</li><li>Locates the table header and extracts the header text by locator.inner_text() function. (lineÂ 11)</li><li>Locates all rows of the table body. (lineÂ 13)</li><li>Extracts row text and reformat it to print on the screen in a loop. (lineÂ 14â€“18)</li></ol><p>It seems quite simple. Letâ€™s run this example and check theÂ result.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*AvYaK4Ie3ep-IcUJvN2mTQ.png\" /></figure><p>We got only 20 rows. The rest data is missing. The page load rows visible on screen only. We need to scroll down, so that it could load the restÂ data.</p><h3><strong>Scrolling and Infinite Pagination</strong></h3><p>Scrolling could be done easy by add row.scroll_into_view_if_needed() before inner_text = await row.inner_text().</p><p>The trick part is pagination. At the bottom of the page, there is a â€œLoad Moreâ€Â button.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Wx1OrTPpP2ywHJESunmLGg.png\" /></figure><p>What we need to do is keep clicking the â€œLoad Moreâ€ button while is clickable. The â€œLoad Moreâ€ scripts asÂ below:</p><pre>async def has_next_page():<br>    try:<br>        await page.get_by_role(&quot;button&quot;, name=&quot;Load More&quot;).click(trial = True)<br>        return True<br>    except:<br>        return False<br>                        <br>async def load_next_page():<br>    current_page = 1<br>    while await has_next_page():<br>        try:<br>            yield current_page<br>            await page.get_by_role(&quot;button&quot;, name=&quot;Load More&quot;).click(force=True)<br>            current_page += 1<br>        except:<br>            ...<br>    yield current_page</pre><p><strong>Codes walkÂ through</strong></p><ol><li>Function has_next_page() waits for the â€œLoad Moreâ€ button to be clickable then return Ture. Or return False if any exception. By setting (trial = True), the click() fucntion perform only actionable checks and skips the clickÂ action.</li><li>While the â€œLoad Moreâ€ button is clickable, each time function load_next_page() is called, it clicks the â€œLoad Moreâ€ button to load next pageÂ data.</li></ol><p>Letâ€™s do some refactoring, extracts locates elements and extracts data codes to a data() function. And put the pagnitions codes together.</p><pre>async def data():  <br>    <br>    yield await page.locator(&quot;thead tr&quot;).locator(&quot;visible=true&quot;).inner_text()<br>    <br>    current_row = 0<br>    async for _ in load_next_page():<br>        rows = await page.locator(&quot;tbody tr&quot;).all()<br>        rows = rows[current_row:]<br>        <br>        for row in rows:<br>            await row.wait_for(timeout=0)<br>            await row.scroll_into_view_if_needed(timeout=0)<br>            yield await row.inner_text()<br>            current_row += 1 </pre><p>The current_row index indicates the next row to be parsed. After the â€œLoad Moreâ€ button is clicked, it parses rows start from current_row to theÂ end.</p><p>The final thing, we save the extracted data in a csv file instead of print it on screen and add a progress bar by tqdm. The completed codes asÂ below:</p><iframe src=\"\" width=\"0\" height=\"0\" frameborder=\"0\" scrolling=\"no\"><a href=\"https://medium.com/media/c86b8cf1e7087305f5408b6b320c61a7/href\">https://medium.com/media/c86b8cf1e7087305f5408b6b320c61a7/href</a></iframe><h3>Whatâ€™s Next</h3><p>In this article, we store scraped data into a CSV file. But in real scraping practic, we deal with thounds of millions of pages, instead of storing data in CSV files, we usually store data into database. One of the most popular database management system MySQL. For loading CSV data into MySQL efficiently, read myÂ article:</p><p><a href=\"https://xuzhusheng.medium.com/how-to-load-millions-of-rows-csv-data-into-mysql-in-seconds-05805e5c1e39\">Loads millions of Records into MySQL in Seconds</a></p><h3>Jason ğŸš€</h3><p><em>Thank you for reading until the end. Before youÂ go:</em></p><p>ğŸ‘ Please <strong><em>Clap</em></strong> and <strong><em>follow</em></strong>Â me</p><p>ğŸ“¬ <a href=\"https://medium.com/@xuzhusheng/subscribe\">Subscribe</a> to my Medium newsletter for emailÂ updates!</p><p>â˜• or just <a href=\"https://www.buymeacoffee.com/jason.xu\">buy me aÂ coffee</a></p><h3>In Plain EnglishÂ ğŸš€</h3><p><em>Thank you for being a part of the </em><a href=\"https://plainenglish.io\"><strong><em>In Plain English</em></strong></a><em> community! Before youÂ go:</em></p><ul><li>Be sure to <strong>clap</strong> and <strong>follow</strong> the writerÂ ï¸ğŸ‘<strong>ï¸ï¸</strong></li><li>Follow us: <a href=\"https://twitter.com/inPlainEngHQ\"><strong>X</strong></a><strong> | </strong><a href=\"https://www.linkedin.com/company/inplainenglish/\"><strong>LinkedIn</strong></a><strong> | </strong><a href=\"https://www.youtube.com/channel/UCtipWUghju290NWcn8jhyAw\"><strong>YouTube</strong></a><strong> | </strong><a href=\"https://discord.gg/in-plain-english-709094664682340443\"><strong>Discord</strong></a><strong> | </strong><a href=\"https://newsletter.plainenglish.io/\"><strong>Newsletter</strong></a></li><li>Visit our other platforms: <a href=\"https://stackademic.com/\"><strong>Stackademic</strong></a><strong> | </strong><a href=\"https://cofeed.app/\"><strong>CoFeed</strong></a><strong> | </strong><a href=\"https://venturemagazine.net/\"><strong>Venture</strong></a><strong> |Â </strong><a href=\"https://blog.cubed.run\"><strong>Cubed</strong></a></li><li>More content at <a href=\"https://plainenglish.io\"><strong>PlainEnglish.io</strong></a></li></ul><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=def04f46a129\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://python.plainenglish.io/playwright-web-scrapping-in-python-2024-def04f46a129\">Scraping Interactive Pages with Playwright in Python</a> was originally published in <a href=\"https://python.plainenglish.io\">Python in Plain English</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>","media":{}}]}