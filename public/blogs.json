{
    "status": "ok",
    "feed": {
        "url": "https://medium.com/feed/@xuzhusheng",
        "title": "Stories by Jason on Medium",
        "link": "https://medium.com/@xuzhusheng?source=rss-41bd992616fb------2",
        "author": "",
        "description": "Stories by Jason on Medium",
        "image": "https://cdn-images-1.medium.com/fit/c/150/150/1*WvSeAJwGVusKLkQSyDG6qw.jpeg"
    },
    "items": [
        {
            "title": "Covariance and Correlation",
            "pubDate": "2024-05-02 10:01:28",
            "link": "https://python.plainenglish.io/covariance-and-correlation-20d849be6d5d?source=rss-41bd992616fb------2",
            "guid": "https://medium.com/p/20d849be6d5d",
            "author": "Jason",
            "thumbnail": "",
            "description": "\n<h4>Machine Learning</h4>\n<h4>Revealing Hidden Connections between Variables in Your\u00a0Dataset</h4>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*DxKN3PxZNPfOQCN_\"><figcaption>Photo by <a href=\"https://unsplash.com/@kommumikation?utm_source=medium&amp;utm_medium=referral\">Mika Baumeister</a> on\u00a0<a href=\"https://unsplash.com/?utm_source=medium&amp;utm_medium=referral\">Unsplash</a></figcaption></figure><p>Covariance and correlation are two of the most fundamental statistics and probability theory concepts. Both covariance and correlation have high utility in machine learning and data analysis.</p>\n<p>In this article, we are going to discover the concepts of covariance and correlation. We will cover this topic with below sections:</p>\n<ul>\n<li><em>Covariance<br>- What is covariance<br>- Calculating covariance with\u00a0NumPy</em></li>\n<li><em>Correlation<br>- Pearson Correlation Coefficient<br>- Calculating Pearson correlation coefficient with\u00a0NumPy</em></li>\n<li><em>Covariance VS. Correlation</em></li>\n</ul>\n<p>Let\u2019s start.</p>\n<h3><strong>Covariance</strong></h3>\n<p>Covariance is a measure of the joint variability of two random variables. It describes how the two variables change together. The sign of the covariance shows the tendency in the linear relationship between the variables.</p>\n<ul>\n<li><em>Positive covariance: Both variables tend to move in the same direction.</em></li>\n<li><em>Negative covariance: Two variables tend to move in inverse directions.</em></li>\n<li><em>Zero covariance\uff1aTwo variables are completely independent.</em></li>\n</ul>\n<h4><strong>Corvarance Formula</strong></h4>\n<p>Covariance is calculated as expected value or average of the product of the differences of each random variable from their expected values. Given by two random variables X and Y, the covariance is denoted by cov(X,Y). The formula is given\u00a0below:</p>\n<p><strong>Population covariance</strong></p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/642/1*Iaq8ggKmBs3QElbVGTH10Q.png\"></figure><p>where:</p>\n<ul>\n<li><em>cov is the covariance</em></li>\n<li><em>x_i and y_i is the ith value of X or\u00a0Y</em></li>\n<li><em>x-bar and y-bar is the mean of X or\u00a0Y</em></li>\n<li><em>N is the number of x and y in the population</em></li>\n</ul>\n<p><strong>Sample covariance</strong></p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/642/1*kXERbK1EGsKKYKby8nuiRg.png\"></figure><p>where:</p>\n<ul><li><em>n is sample size. n\u200a\u2014\u200a1 is degrees of freedom and the use of the term n \u2212 1 is called Bessel\u2019s correction</em></li></ul>\n<h4><strong>Calculating Covariance with\u00a0NumPy</strong></h4>\n<p>According to the formula, covariance can be calculated as\u00a0below:</p>\n<pre>import numpy as np<br><br>np.random.seed(0)<br><br>x, y = np.random.randint(10, size = (2,7))<br>print(x) # [5 0 3 3 7 9 3]<br>print(y) # [5 2 4 7 6 8 8]<br><br>def covariance(x, y, *, bias = False):<br>    num = len(x) if bias else len(x) - 1<br>    return ((x - x.mean()) * (y - y.mean())).sum() / num<br><br># Unbiased sample covariance<br>print(covariance(x, y)) # 4.095238095238096<br><br># Population covariance or biased sample covariance<br>print(covariance(x, y, bias=True)) # 3.510204081632654</pre>\n<h3><strong>Correlation</strong></h3>\n<p>A correlation reflects the strength and/or direction of the relationship between two (or more) variables. It usually refers to the degree to which a pair of variables are linearly related. The direction of a correlation can be positive, negative or\u00a0zero:</p>\n<ul>\n<li><em>Positive correlation: Both variables change in the same direction (i.e., one variable increases as the other increases. Or, one decreases as the other decreases).</em></li>\n<li><em>Negative correlation: The variables change in opposite directions (i.e., one variable increases as the other decreases, and vice\u00a0versa)</em></li>\n<li><em>Zero correlation: There is no relationship between the variables.</em></li>\n</ul>\n<p>There are several correlation coefficients measuring the degree of correlation. The most common one is the Pearson correlation coefficient.</p>\n<h4><strong>Pearson Correlation Coefficient (PCC)</strong></h4>\n<p>Pearson correlation coefficient is a correlation coefficient that measures linear correlation between two sets of data. It is the ratio between the covariance of two variables and the product of their standard deviations. Thus, it is essentially a normalized measurement of the covariance, the result always has a value between \u22121 and\u00a01.</p>\n<p>Pearson correlation coefficient is commonly represented by the r. The formula\u00a0is:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/642/1*E9OEPW9JtqphvQ6UAw71UQ.png\"></figure><p>where</p>\n<ul>\n<li><em>cov is the covariance</em></li>\n<li><em>S_x and S_y is the standard deviation</em></li>\n</ul>\n<p>The value of r ranges between -1 and 1. We Interpret r as\u00a0below:</p>\n<a href=\"https://medium.com/media/e3ccf1ac78aec83aecebf2968a8b0604/href\">https://medium.com/media/e3ccf1ac78aec83aecebf2968a8b0604/href</a><h4><strong>Calculating pearson correlation coefficient with\u00a0NumPy</strong></h4>\n<p>According to the formula, pearson correlation coefficient can be calculated as\u00a0below:</p>\n<pre>def correlation_coefficient(x, y):<br>    return covariance(x, y) / (np.std(x, ddof=1) * np.std(y, ddof=1))<br><br>print(correlation_coefficient(x, y))    # 0.6196679516337091</pre>\n<h3><strong>Corvarance VS. Correlation</strong></h3>\n<p>Covariance reveals how two variables change together while correlation determines how closely two variables are related to each\u00a0other.</p>\n<ul>\n<li><em>Both covariance and correlation measure the relationship and the dependency between two variables.</em></li>\n<li><em>Covariance indicates the direction of the linear relationship between variables.</em></li>\n<li><em>Correlation measures both the strength and direction of the linear relationship between two variables.</em></li>\n<li><em>Correlation values are standardized.</em></li>\n<li><em>Covariance values are not standardized.</em></li>\n</ul>\n<h3>Jason \ud83d\ude80</h3>\n<p><em>Thank you for reading until the end. Before you\u00a0go:</em></p>\n<p><em>\ud83d\udc4f Please </em><strong><em>clap</em></strong><em> and </em><strong><em>follow</em></strong><em>\u00a0me.</em></p>\n<p><em>\ud83d\udcec </em><a href=\"https://medium.com/@xuzhusheng/subscribe\"><em>Subscribe</em></a><em> to my Medium newsletter for email\u00a0updates!</em></p>\n<p><em>\u2615 or just </em><a href=\"https://www.buymeacoffee.com/jason.xu\"><em>buy me a\u00a0coffee</em></a><em>.</em></p>\n<h3>In Plain English\u00a0\ud83d\ude80</h3>\n<p><em>Thank you for being a part of the </em><a href=\"https://plainenglish.io/\"><strong><em>In Plain English</em></strong></a><em> community! Before you\u00a0go:</em></p>\n<ul>\n<li>Be sure to <strong>clap</strong> and <strong>follow</strong> the writer\u00a0\ufe0f\ud83d\udc4f<strong>\ufe0f\ufe0f</strong>\n</li>\n<li>Follow us: <a href=\"https://twitter.com/inPlainEngHQ\"><strong>X</strong></a><strong> | </strong><a href=\"https://www.linkedin.com/company/inplainenglish/\"><strong>LinkedIn</strong></a><strong> | </strong><a href=\"https://www.youtube.com/channel/UCtipWUghju290NWcn8jhyAw\"><strong>YouTube</strong></a><strong> | </strong><a href=\"https://discord.gg/in-plain-english-709094664682340443\"><strong>Discord</strong></a><strong> | </strong><a href=\"https://newsletter.plainenglish.io/\"><strong>Newsletter</strong></a>\n</li>\n<li>Visit our other platforms: <a href=\"https://stackademic.com/\"><strong>Stackademic</strong></a><strong> | </strong><a href=\"https://cofeed.app/\"><strong>CoFeed</strong></a><strong> | </strong><a href=\"https://venturemagazine.net/\"><strong>Venture</strong></a><strong> |\u00a0</strong><a href=\"https://blog.cubed.run/\"><strong>Cubed</strong></a>\n</li>\n<li>More content at <a href=\"https://plainenglish.io/\"><strong>PlainEnglish.io</strong></a>\n</li>\n</ul>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=20d849be6d5d\" width=\"1\" height=\"1\" alt=\"\"><hr>\n<p><a href=\"https://python.plainenglish.io/covariance-and-correlation-20d849be6d5d\">Covariance and Correlation</a> was originally published in <a href=\"https://python.plainenglish.io/\">Python in Plain English</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n",
            "content": "\n<h4>Machine Learning</h4>\n<h4>Revealing Hidden Connections between Variables in Your\u00a0Dataset</h4>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*DxKN3PxZNPfOQCN_\"><figcaption>Photo by <a href=\"https://unsplash.com/@kommumikation?utm_source=medium&amp;utm_medium=referral\">Mika Baumeister</a> on\u00a0<a href=\"https://unsplash.com/?utm_source=medium&amp;utm_medium=referral\">Unsplash</a></figcaption></figure><p>Covariance and correlation are two of the most fundamental statistics and probability theory concepts. Both covariance and correlation have high utility in machine learning and data analysis.</p>\n<p>In this article, we are going to discover the concepts of covariance and correlation. We will cover this topic with below sections:</p>\n<ul>\n<li><em>Covariance<br>- What is covariance<br>- Calculating covariance with\u00a0NumPy</em></li>\n<li><em>Correlation<br>- Pearson Correlation Coefficient<br>- Calculating Pearson correlation coefficient with\u00a0NumPy</em></li>\n<li><em>Covariance VS. Correlation</em></li>\n</ul>\n<p>Let\u2019s start.</p>\n<h3><strong>Covariance</strong></h3>\n<p>Covariance is a measure of the joint variability of two random variables. It describes how the two variables change together. The sign of the covariance shows the tendency in the linear relationship between the variables.</p>\n<ul>\n<li><em>Positive covariance: Both variables tend to move in the same direction.</em></li>\n<li><em>Negative covariance: Two variables tend to move in inverse directions.</em></li>\n<li><em>Zero covariance\uff1aTwo variables are completely independent.</em></li>\n</ul>\n<h4><strong>Corvarance Formula</strong></h4>\n<p>Covariance is calculated as expected value or average of the product of the differences of each random variable from their expected values. Given by two random variables X and Y, the covariance is denoted by cov(X,Y). The formula is given\u00a0below:</p>\n<p><strong>Population covariance</strong></p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/642/1*Iaq8ggKmBs3QElbVGTH10Q.png\"></figure><p>where:</p>\n<ul>\n<li><em>cov is the covariance</em></li>\n<li><em>x_i and y_i is the ith value of X or\u00a0Y</em></li>\n<li><em>x-bar and y-bar is the mean of X or\u00a0Y</em></li>\n<li><em>N is the number of x and y in the population</em></li>\n</ul>\n<p><strong>Sample covariance</strong></p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/642/1*kXERbK1EGsKKYKby8nuiRg.png\"></figure><p>where:</p>\n<ul><li><em>n is sample size. n\u200a\u2014\u200a1 is degrees of freedom and the use of the term n \u2212 1 is called Bessel\u2019s correction</em></li></ul>\n<h4><strong>Calculating Covariance with\u00a0NumPy</strong></h4>\n<p>According to the formula, covariance can be calculated as\u00a0below:</p>\n<pre>import numpy as np<br><br>np.random.seed(0)<br><br>x, y = np.random.randint(10, size = (2,7))<br>print(x) # [5 0 3 3 7 9 3]<br>print(y) # [5 2 4 7 6 8 8]<br><br>def covariance(x, y, *, bias = False):<br>    num = len(x) if bias else len(x) - 1<br>    return ((x - x.mean()) * (y - y.mean())).sum() / num<br><br># Unbiased sample covariance<br>print(covariance(x, y)) # 4.095238095238096<br><br># Population covariance or biased sample covariance<br>print(covariance(x, y, bias=True)) # 3.510204081632654</pre>\n<h3><strong>Correlation</strong></h3>\n<p>A correlation reflects the strength and/or direction of the relationship between two (or more) variables. It usually refers to the degree to which a pair of variables are linearly related. The direction of a correlation can be positive, negative or\u00a0zero:</p>\n<ul>\n<li><em>Positive correlation: Both variables change in the same direction (i.e., one variable increases as the other increases. Or, one decreases as the other decreases).</em></li>\n<li><em>Negative correlation: The variables change in opposite directions (i.e., one variable increases as the other decreases, and vice\u00a0versa)</em></li>\n<li><em>Zero correlation: There is no relationship between the variables.</em></li>\n</ul>\n<p>There are several correlation coefficients measuring the degree of correlation. The most common one is the Pearson correlation coefficient.</p>\n<h4><strong>Pearson Correlation Coefficient (PCC)</strong></h4>\n<p>Pearson correlation coefficient is a correlation coefficient that measures linear correlation between two sets of data. It is the ratio between the covariance of two variables and the product of their standard deviations. Thus, it is essentially a normalized measurement of the covariance, the result always has a value between \u22121 and\u00a01.</p>\n<p>Pearson correlation coefficient is commonly represented by the r. The formula\u00a0is:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/642/1*E9OEPW9JtqphvQ6UAw71UQ.png\"></figure><p>where</p>\n<ul>\n<li><em>cov is the covariance</em></li>\n<li><em>S_x and S_y is the standard deviation</em></li>\n</ul>\n<p>The value of r ranges between -1 and 1. We Interpret r as\u00a0below:</p>\n<a href=\"https://medium.com/media/e3ccf1ac78aec83aecebf2968a8b0604/href\">https://medium.com/media/e3ccf1ac78aec83aecebf2968a8b0604/href</a><h4><strong>Calculating pearson correlation coefficient with\u00a0NumPy</strong></h4>\n<p>According to the formula, pearson correlation coefficient can be calculated as\u00a0below:</p>\n<pre>def correlation_coefficient(x, y):<br>    return covariance(x, y) / (np.std(x, ddof=1) * np.std(y, ddof=1))<br><br>print(correlation_coefficient(x, y))    # 0.6196679516337091</pre>\n<h3><strong>Corvarance VS. Correlation</strong></h3>\n<p>Covariance reveals how two variables change together while correlation determines how closely two variables are related to each\u00a0other.</p>\n<ul>\n<li><em>Both covariance and correlation measure the relationship and the dependency between two variables.</em></li>\n<li><em>Covariance indicates the direction of the linear relationship between variables.</em></li>\n<li><em>Correlation measures both the strength and direction of the linear relationship between two variables.</em></li>\n<li><em>Correlation values are standardized.</em></li>\n<li><em>Covariance values are not standardized.</em></li>\n</ul>\n<h3>Jason \ud83d\ude80</h3>\n<p><em>Thank you for reading until the end. Before you\u00a0go:</em></p>\n<p><em>\ud83d\udc4f Please </em><strong><em>clap</em></strong><em> and </em><strong><em>follow</em></strong><em>\u00a0me.</em></p>\n<p><em>\ud83d\udcec </em><a href=\"https://medium.com/@xuzhusheng/subscribe\"><em>Subscribe</em></a><em> to my Medium newsletter for email\u00a0updates!</em></p>\n<p><em>\u2615 or just </em><a href=\"https://www.buymeacoffee.com/jason.xu\"><em>buy me a\u00a0coffee</em></a><em>.</em></p>\n<h3>In Plain English\u00a0\ud83d\ude80</h3>\n<p><em>Thank you for being a part of the </em><a href=\"https://plainenglish.io/\"><strong><em>In Plain English</em></strong></a><em> community! Before you\u00a0go:</em></p>\n<ul>\n<li>Be sure to <strong>clap</strong> and <strong>follow</strong> the writer\u00a0\ufe0f\ud83d\udc4f<strong>\ufe0f\ufe0f</strong>\n</li>\n<li>Follow us: <a href=\"https://twitter.com/inPlainEngHQ\"><strong>X</strong></a><strong> | </strong><a href=\"https://www.linkedin.com/company/inplainenglish/\"><strong>LinkedIn</strong></a><strong> | </strong><a href=\"https://www.youtube.com/channel/UCtipWUghju290NWcn8jhyAw\"><strong>YouTube</strong></a><strong> | </strong><a href=\"https://discord.gg/in-plain-english-709094664682340443\"><strong>Discord</strong></a><strong> | </strong><a href=\"https://newsletter.plainenglish.io/\"><strong>Newsletter</strong></a>\n</li>\n<li>Visit our other platforms: <a href=\"https://stackademic.com/\"><strong>Stackademic</strong></a><strong> | </strong><a href=\"https://cofeed.app/\"><strong>CoFeed</strong></a><strong> | </strong><a href=\"https://venturemagazine.net/\"><strong>Venture</strong></a><strong> |\u00a0</strong><a href=\"https://blog.cubed.run/\"><strong>Cubed</strong></a>\n</li>\n<li>More content at <a href=\"https://plainenglish.io/\"><strong>PlainEnglish.io</strong></a>\n</li>\n</ul>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=20d849be6d5d\" width=\"1\" height=\"1\" alt=\"\"><hr>\n<p><a href=\"https://python.plainenglish.io/covariance-and-correlation-20d849be6d5d\">Covariance and Correlation</a> was originally published in <a href=\"https://python.plainenglish.io/\">Python in Plain English</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n",
            "enclosure": {},
            "categories": [
                "statistics",
                "data-analysis",
                "data-science",
                "machine-learning",
                "python"
            ]
        },
        {
            "title": "Variance and Standard Deviation",
            "pubDate": "2024-04-15 00:02:10",
            "link": "https://python.plainenglish.io/calculates-variance-and-standard-deviation-with-python-e8cd434645bf?source=rss-41bd992616fb------2",
            "guid": "https://medium.com/p/e8cd434645bf",
            "author": "Jason",
            "thumbnail": "",
            "description": "\n<h4>Machine Learning</h4>\n<h4>What variance and standard deviation are and how to calculate them.</h4>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*vSWCAp4xDrKWelgx\"><figcaption>Photo by <a href=\"https://unsplash.com/@bash__profile?utm_source=medium&amp;utm_medium=referral\">Nicholas Cappello</a> on\u00a0<a href=\"https://unsplash.com/?utm_source=medium&amp;utm_medium=referral\">Unsplash</a></figcaption></figure><p><strong>Variance</strong> and <strong>standard deviation</strong> and are two basic mathematical concepts. Both measure the variability of figures within a data set using the mean of a certain group of numbers. They are important to help determine volatility and the distribution of\u00a0returns.</p>\n<p>In this article, we are going to explore variance and standard deviation and how to calculate with\u00a0NumPy.</p>\n<p>At the end of this article, we will comprehend:</p>\n<ul>\n<li><em>What the expected value or arthmetic mean is and how to calculate it</em></li>\n<li><em>What the variance is and how to calculate it</em></li>\n<li><em>What the standard diviation is and how to calcualte it</em></li>\n</ul>\n<p>Let\u2019s start with the most basic mean and expected\u00a0value.</p>\n<h3><strong>Arithmetic Mean and Expected\u00a0Value</strong></h3>\n<h4><strong>Arithmetic Mean (Sample\u00a0Mean)</strong></h4>\n<p>In mathematics and statistics, the arithmetic mean of a set of observed data is equal to the sum of the numerical values of each observation, divided by the total number of observations. The arithmetic mean calculated from observed sample is symbolized as x-bar. It is defined by the\u00a0formula:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/682/1*meyblNvsdxElBI90rBxs4w.png\"></figure><h4><strong>Expected Value (Population Mean)</strong></h4>\n<p>The expected value of a discrete random variable X, symbolized as E(X), is often referred to as the long-term mean, population mean, symbolized as \u03bc to differentiate the sample mean. The Expected Value difined by the\u00a0formula:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/682/1*SOWeJ7TWG3XTW8eIG2m8Mw.png\"></figure><h4><strong>Calculating mean with\u00a0NumPy</strong></h4>\n<p>We can use the `mean()` function in NumPy to calculate mean for vector and matrix. Let\u2019s see how to do\u00a0it:</p>\n<pre>import numpy as np<br><br>np.random.seed(202404)<br><br><br>vector = np.random.randint(10, size = 7)<br>print(vector) # [2 1 1 6 5 5 0]<br><br># mean for vector<br>vector.mean()<br><br><br>matrix = np.random.randint(10, size=(3,5))<br>print(matrix)<br># [[0 6 9 8 9]<br>#  [1 2 0 8 1]<br>#  [5 1 5 8 7]]<br><br># column mean<br>print(matrix.mean(axis=0))  # [2.         3.         4.66666667 8.         5.66666667]<br><br># row mean<br>print(matrix.mean(axis=1))  # [6.4 2.4 5.2]<br><br># mean for all element<br>print(matrix.mean())    # 4.666666666666667</pre>\n<h3><strong>Variance</strong></h3>\n<p>In probability theory and statistics, variance is the expected value of the squared deviation from the mean of a random variable. Variance is a measure of dispersion, meaning it is a measure of how far a set of numbers is spread out from their average\u00a0value.</p>\n<h4><strong>Population Variance</strong></h4>\n<p>The population variance of a finite population given\u00a0by:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/682/1*Ant7t14LDv3mIPAtskzXGg.png\"></figure><ul>\n<li><em>\u03c3\u00b2 is population variance</em></li>\n<li><em>x_i is observed value from the population</em></li>\n<li><em>\u03bc is the mean of all\u00a0x</em></li>\n<li><em>N is the number of x in the population</em></li>\n</ul>\n<h4><strong>Sample Variance</strong></h4>\n<p>In many practical situations, the true variance of a population is not known a priori and must be computed somehow. Variance is usually estimated from a sample drawn from a population. The unbiased estimate of population variance calculated from a sample\u00a0is:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/682/1*KPwFtcmP3cwn0IYHVmJbxg.png\"></figure><h4><strong>Calculating Variance with\u00a0NumPy</strong></h4>\n<p>According to the formulas, we could calculate the variance as\u00a0below:</p>\n<pre>import numpy as np<br><br>np.random.seed(202404)<br><br>data = np.random.randint(10, size = 7)<br>print(data) # [2 1 1 6 5 5 0]<br><br>def variance(data, *, bias = False):<br>    num = len(data) if bias else len(data) - 1<br>    return ((data - data.mean()) ** 2).sum() / num<br><br># unbiased sample variance<br>print(variance(data))   # 5.809523809523809<br><br># population variance or biased sample variance<br>print(variance(data, bias=True))    # 4.979591836734693</pre>\n<p>In real pratice, We use the `var()` function in NumPy to calculate variance as\u00a0below:</p>\n<pre>import numpy as np<br><br>np.random.seed(202404)<br><br>vector = np.random.randint(10, size = 7)<br>print(vector) # [2 1 1 6 5 5 0]<br><br># unbiased sample variance<br>print(vector.var(ddof=1)) # 5.809523809523809<br><br># population variance or biased sample variance<br>print(vector.var(ddof=0)) # 4.979591836734693<br><br>matrix = np.random.randint(10, size=(3, 5))<br>print(matrix)<br># [[0 6 9 8 9]<br>#  [1 2 0 8 1]<br>#  [5 1 5 8 7]]<br><br># unbiased sample variance<br># column variance<br>print(matrix.var(axis=0, ddof=1))   # [ 7.          7.         20.33333333  0.         17.33333333]<br># row variance<br>print(matrix.var(axis=1, ddof=1))   # [14.3 10.3  7.2]<br># variance for all elements<br>print(matrix.var( ddof=1))  # 12.095238095238098<br><br># population variance or biased sample variance<br># column variance<br>print(matrix.var(axis=0))   # [ 4.66666667  4.66666667 13.55555556  0.         11.55555556]<br># row variance<br>print(matrix.var(axis=1))   # [11.44  8.24  5.76]<br># variance for all elements<br>print(matrix.var()) # 11.288888888888891</pre>\n<h3><strong>Standard Deviation</strong></h3>\n<p>The standard deviation (SD) is a statistic that measures the dispersion of a dataset relative to its mean and is calculated as the square root of the variance. If the data points are further from the mean, there is a higher deviation within the data set. The more spread out the data, the higher the standard deviation. Like the variance, there are population standard deviation and sample standard deviation.</p>\n<h4><strong>Population standard deviation</strong></h4>\n<p>The formula of population standard deviation is:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/682/1*GXlVE8QqZBA4Af2f150ihg.png\"></figure><h4><strong>Sample standard deviation</strong></h4>\n<p>The sample of population standard deviation is:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/682/1*GXlVE8QqZBA4Af2f150ihg.png\"></figure><h4><strong>Calculating Standard Deviation with\u00a0NumPy</strong></h4>\n<p>We use the `std()` function in NumPy to calculate standard deviation like we calculate variance above. Let\u2019s see how to do it with examples:</p>\n<pre>import numpy as np<br><br>np.random.seed(202404)<br><br>vector = np.random.randint(10, size = 7)<br>print(vector) # [2 1 1 6 5 5 0]<br><br># unbiased sample variance<br>print(vector.std(ddof=1)) # 2.410295378065479<br><br># population standard deviation or biased sample standard deviation<br>print(vector.std(ddof=0)) # 2.231499907401901<br><br>matrix = np.random.randint(10, size=(3, 5))<br>print(matrix)<br># [[0 6 9 8 9]<br>#  [1 2 0 8 1]<br>#  [5 1 5 8 7]]<br><br># unbiased sample standard deviation<br># column standard deviation<br>print(matrix.std(axis=0, ddof=1))   # [2.64575131 2.64575131 4.50924975 0.         4.163332  ]<br># row standard deviation<br>print(matrix.std(axis=1, ddof=1))   # [3.78153408 3.20936131 2.68328157]<br># standard deviation for all elements<br>print(matrix.std( ddof=1))  # 3.477820883144803<br><br># population standard deviation or biased sample standard deviation<br># column standard deviation<br>print(matrix.std(axis=0))   # [2.1602469  2.1602469  3.68178701 0.         3.39934634]<br># row standard deviation<br>print(matrix.std(axis=1))   # [3.38230691 2.87054002 2.4       ]<br># standard deviation for all elements<br>print(matrix.std()) # 3.3598941782277745</pre>\n<h3><strong>Conclusion</strong></h3>\n<p>The variance measures the average degree to which each point differs from the mean. While standard deviation is the square root of the variance. They are both important to help determine volatility and the distribution of\u00a0returns.</p>\n<p>In many practical situations, we usually estimate variance and standard deviation from a sample drawn from a population. When estimate variance and standard deviation from a sample, we use Bessel\u2019s correction to adjust the divisor to n (sample size) -\u00a01.</p>\n<p>We can use the var() and std() functions to calculate variance and standard deviation with\u00a0NumPy</p>\n<h3>Jason \ud83d\ude80</h3>\n<p><em>Thank you for reading until the end. Before you\u00a0go:</em></p>\n<p>\ud83d\udc4f Please <strong><em>clap</em></strong> and <strong><em>follow</em></strong>\u00a0me</p>\n<p>\ud83d\udcec <a href=\"https://medium.com/@xuzhusheng/subscribe\">Subscribe</a> to my Medium newsletter for email\u00a0updates!</p>\n<p>\u2615 or just <a href=\"https://www.buymeacoffee.com/jason.xu\">buy me a\u00a0coffee</a></p>\n<h3>In Plain English\u00a0\ud83d\ude80</h3>\n<p><em>Thank you for being a part of the </em><a href=\"https://plainenglish.io/\"><strong><em>In Plain English</em></strong></a><em> community! Before you\u00a0go:</em></p>\n<ul>\n<li>Be sure to <strong>clap</strong> and <strong>follow</strong> the writer\u00a0\ufe0f\ud83d\udc4f<strong>\ufe0f\ufe0f</strong>\n</li>\n<li>Follow us: <a href=\"https://twitter.com/inPlainEngHQ\"><strong>X</strong></a><strong> | </strong><a href=\"https://www.linkedin.com/company/inplainenglish/\"><strong>LinkedIn</strong></a><strong> | </strong><a href=\"https://www.youtube.com/channel/UCtipWUghju290NWcn8jhyAw\"><strong>YouTube</strong></a><strong> | </strong><a href=\"https://discord.gg/in-plain-english-709094664682340443\"><strong>Discord</strong></a><strong> | </strong><a href=\"https://newsletter.plainenglish.io/\"><strong>Newsletter</strong></a>\n</li>\n<li>Visit our other platforms: <a href=\"https://stackademic.com/\"><strong>Stackademic</strong></a><strong> | </strong><a href=\"https://cofeed.app/\"><strong>CoFeed</strong></a><strong> | </strong><a href=\"https://venturemagazine.net/\"><strong>Venture</strong></a><strong> |\u00a0</strong><a href=\"https://blog.cubed.run/\"><strong>Cubed</strong></a>\n</li>\n<li>More content at <a href=\"https://plainenglish.io/\"><strong>PlainEnglish.io</strong></a>\n</li>\n</ul>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=e8cd434645bf\" width=\"1\" height=\"1\" alt=\"\"><hr>\n<p><a href=\"https://python.plainenglish.io/calculates-variance-and-standard-deviation-with-python-e8cd434645bf\">Variance and Standard Deviation</a> was originally published in <a href=\"https://python.plainenglish.io/\">Python in Plain English</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n",
            "content": "\n<h4>Machine Learning</h4>\n<h4>What variance and standard deviation are and how to calculate them.</h4>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*vSWCAp4xDrKWelgx\"><figcaption>Photo by <a href=\"https://unsplash.com/@bash__profile?utm_source=medium&amp;utm_medium=referral\">Nicholas Cappello</a> on\u00a0<a href=\"https://unsplash.com/?utm_source=medium&amp;utm_medium=referral\">Unsplash</a></figcaption></figure><p><strong>Variance</strong> and <strong>standard deviation</strong> and are two basic mathematical concepts. Both measure the variability of figures within a data set using the mean of a certain group of numbers. They are important to help determine volatility and the distribution of\u00a0returns.</p>\n<p>In this article, we are going to explore variance and standard deviation and how to calculate with\u00a0NumPy.</p>\n<p>At the end of this article, we will comprehend:</p>\n<ul>\n<li><em>What the expected value or arthmetic mean is and how to calculate it</em></li>\n<li><em>What the variance is and how to calculate it</em></li>\n<li><em>What the standard diviation is and how to calcualte it</em></li>\n</ul>\n<p>Let\u2019s start with the most basic mean and expected\u00a0value.</p>\n<h3><strong>Arithmetic Mean and Expected\u00a0Value</strong></h3>\n<h4><strong>Arithmetic Mean (Sample\u00a0Mean)</strong></h4>\n<p>In mathematics and statistics, the arithmetic mean of a set of observed data is equal to the sum of the numerical values of each observation, divided by the total number of observations. The arithmetic mean calculated from observed sample is symbolized as x-bar. It is defined by the\u00a0formula:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/682/1*meyblNvsdxElBI90rBxs4w.png\"></figure><h4><strong>Expected Value (Population Mean)</strong></h4>\n<p>The expected value of a discrete random variable X, symbolized as E(X), is often referred to as the long-term mean, population mean, symbolized as \u03bc to differentiate the sample mean. The Expected Value difined by the\u00a0formula:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/682/1*SOWeJ7TWG3XTW8eIG2m8Mw.png\"></figure><h4><strong>Calculating mean with\u00a0NumPy</strong></h4>\n<p>We can use the `mean()` function in NumPy to calculate mean for vector and matrix. Let\u2019s see how to do\u00a0it:</p>\n<pre>import numpy as np<br><br>np.random.seed(202404)<br><br><br>vector = np.random.randint(10, size = 7)<br>print(vector) # [2 1 1 6 5 5 0]<br><br># mean for vector<br>vector.mean()<br><br><br>matrix = np.random.randint(10, size=(3,5))<br>print(matrix)<br># [[0 6 9 8 9]<br>#  [1 2 0 8 1]<br>#  [5 1 5 8 7]]<br><br># column mean<br>print(matrix.mean(axis=0))  # [2.         3.         4.66666667 8.         5.66666667]<br><br># row mean<br>print(matrix.mean(axis=1))  # [6.4 2.4 5.2]<br><br># mean for all element<br>print(matrix.mean())    # 4.666666666666667</pre>\n<h3><strong>Variance</strong></h3>\n<p>In probability theory and statistics, variance is the expected value of the squared deviation from the mean of a random variable. Variance is a measure of dispersion, meaning it is a measure of how far a set of numbers is spread out from their average\u00a0value.</p>\n<h4><strong>Population Variance</strong></h4>\n<p>The population variance of a finite population given\u00a0by:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/682/1*Ant7t14LDv3mIPAtskzXGg.png\"></figure><ul>\n<li><em>\u03c3\u00b2 is population variance</em></li>\n<li><em>x_i is observed value from the population</em></li>\n<li><em>\u03bc is the mean of all\u00a0x</em></li>\n<li><em>N is the number of x in the population</em></li>\n</ul>\n<h4><strong>Sample Variance</strong></h4>\n<p>In many practical situations, the true variance of a population is not known a priori and must be computed somehow. Variance is usually estimated from a sample drawn from a population. The unbiased estimate of population variance calculated from a sample\u00a0is:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/682/1*KPwFtcmP3cwn0IYHVmJbxg.png\"></figure><h4><strong>Calculating Variance with\u00a0NumPy</strong></h4>\n<p>According to the formulas, we could calculate the variance as\u00a0below:</p>\n<pre>import numpy as np<br><br>np.random.seed(202404)<br><br>data = np.random.randint(10, size = 7)<br>print(data) # [2 1 1 6 5 5 0]<br><br>def variance(data, *, bias = False):<br>    num = len(data) if bias else len(data) - 1<br>    return ((data - data.mean()) ** 2).sum() / num<br><br># unbiased sample variance<br>print(variance(data))   # 5.809523809523809<br><br># population variance or biased sample variance<br>print(variance(data, bias=True))    # 4.979591836734693</pre>\n<p>In real pratice, We use the `var()` function in NumPy to calculate variance as\u00a0below:</p>\n<pre>import numpy as np<br><br>np.random.seed(202404)<br><br>vector = np.random.randint(10, size = 7)<br>print(vector) # [2 1 1 6 5 5 0]<br><br># unbiased sample variance<br>print(vector.var(ddof=1)) # 5.809523809523809<br><br># population variance or biased sample variance<br>print(vector.var(ddof=0)) # 4.979591836734693<br><br>matrix = np.random.randint(10, size=(3, 5))<br>print(matrix)<br># [[0 6 9 8 9]<br>#  [1 2 0 8 1]<br>#  [5 1 5 8 7]]<br><br># unbiased sample variance<br># column variance<br>print(matrix.var(axis=0, ddof=1))   # [ 7.          7.         20.33333333  0.         17.33333333]<br># row variance<br>print(matrix.var(axis=1, ddof=1))   # [14.3 10.3  7.2]<br># variance for all elements<br>print(matrix.var( ddof=1))  # 12.095238095238098<br><br># population variance or biased sample variance<br># column variance<br>print(matrix.var(axis=0))   # [ 4.66666667  4.66666667 13.55555556  0.         11.55555556]<br># row variance<br>print(matrix.var(axis=1))   # [11.44  8.24  5.76]<br># variance for all elements<br>print(matrix.var()) # 11.288888888888891</pre>\n<h3><strong>Standard Deviation</strong></h3>\n<p>The standard deviation (SD) is a statistic that measures the dispersion of a dataset relative to its mean and is calculated as the square root of the variance. If the data points are further from the mean, there is a higher deviation within the data set. The more spread out the data, the higher the standard deviation. Like the variance, there are population standard deviation and sample standard deviation.</p>\n<h4><strong>Population standard deviation</strong></h4>\n<p>The formula of population standard deviation is:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/682/1*GXlVE8QqZBA4Af2f150ihg.png\"></figure><h4><strong>Sample standard deviation</strong></h4>\n<p>The sample of population standard deviation is:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/682/1*GXlVE8QqZBA4Af2f150ihg.png\"></figure><h4><strong>Calculating Standard Deviation with\u00a0NumPy</strong></h4>\n<p>We use the `std()` function in NumPy to calculate standard deviation like we calculate variance above. Let\u2019s see how to do it with examples:</p>\n<pre>import numpy as np<br><br>np.random.seed(202404)<br><br>vector = np.random.randint(10, size = 7)<br>print(vector) # [2 1 1 6 5 5 0]<br><br># unbiased sample variance<br>print(vector.std(ddof=1)) # 2.410295378065479<br><br># population standard deviation or biased sample standard deviation<br>print(vector.std(ddof=0)) # 2.231499907401901<br><br>matrix = np.random.randint(10, size=(3, 5))<br>print(matrix)<br># [[0 6 9 8 9]<br>#  [1 2 0 8 1]<br>#  [5 1 5 8 7]]<br><br># unbiased sample standard deviation<br># column standard deviation<br>print(matrix.std(axis=0, ddof=1))   # [2.64575131 2.64575131 4.50924975 0.         4.163332  ]<br># row standard deviation<br>print(matrix.std(axis=1, ddof=1))   # [3.78153408 3.20936131 2.68328157]<br># standard deviation for all elements<br>print(matrix.std( ddof=1))  # 3.477820883144803<br><br># population standard deviation or biased sample standard deviation<br># column standard deviation<br>print(matrix.std(axis=0))   # [2.1602469  2.1602469  3.68178701 0.         3.39934634]<br># row standard deviation<br>print(matrix.std(axis=1))   # [3.38230691 2.87054002 2.4       ]<br># standard deviation for all elements<br>print(matrix.std()) # 3.3598941782277745</pre>\n<h3><strong>Conclusion</strong></h3>\n<p>The variance measures the average degree to which each point differs from the mean. While standard deviation is the square root of the variance. They are both important to help determine volatility and the distribution of\u00a0returns.</p>\n<p>In many practical situations, we usually estimate variance and standard deviation from a sample drawn from a population. When estimate variance and standard deviation from a sample, we use Bessel\u2019s correction to adjust the divisor to n (sample size) -\u00a01.</p>\n<p>We can use the var() and std() functions to calculate variance and standard deviation with\u00a0NumPy</p>\n<h3>Jason \ud83d\ude80</h3>\n<p><em>Thank you for reading until the end. Before you\u00a0go:</em></p>\n<p>\ud83d\udc4f Please <strong><em>clap</em></strong> and <strong><em>follow</em></strong>\u00a0me</p>\n<p>\ud83d\udcec <a href=\"https://medium.com/@xuzhusheng/subscribe\">Subscribe</a> to my Medium newsletter for email\u00a0updates!</p>\n<p>\u2615 or just <a href=\"https://www.buymeacoffee.com/jason.xu\">buy me a\u00a0coffee</a></p>\n<h3>In Plain English\u00a0\ud83d\ude80</h3>\n<p><em>Thank you for being a part of the </em><a href=\"https://plainenglish.io/\"><strong><em>In Plain English</em></strong></a><em> community! Before you\u00a0go:</em></p>\n<ul>\n<li>Be sure to <strong>clap</strong> and <strong>follow</strong> the writer\u00a0\ufe0f\ud83d\udc4f<strong>\ufe0f\ufe0f</strong>\n</li>\n<li>Follow us: <a href=\"https://twitter.com/inPlainEngHQ\"><strong>X</strong></a><strong> | </strong><a href=\"https://www.linkedin.com/company/inplainenglish/\"><strong>LinkedIn</strong></a><strong> | </strong><a href=\"https://www.youtube.com/channel/UCtipWUghju290NWcn8jhyAw\"><strong>YouTube</strong></a><strong> | </strong><a href=\"https://discord.gg/in-plain-english-709094664682340443\"><strong>Discord</strong></a><strong> | </strong><a href=\"https://newsletter.plainenglish.io/\"><strong>Newsletter</strong></a>\n</li>\n<li>Visit our other platforms: <a href=\"https://stackademic.com/\"><strong>Stackademic</strong></a><strong> | </strong><a href=\"https://cofeed.app/\"><strong>CoFeed</strong></a><strong> | </strong><a href=\"https://venturemagazine.net/\"><strong>Venture</strong></a><strong> |\u00a0</strong><a href=\"https://blog.cubed.run/\"><strong>Cubed</strong></a>\n</li>\n<li>More content at <a href=\"https://plainenglish.io/\"><strong>PlainEnglish.io</strong></a>\n</li>\n</ul>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=e8cd434645bf\" width=\"1\" height=\"1\" alt=\"\"><hr>\n<p><a href=\"https://python.plainenglish.io/calculates-variance-and-standard-deviation-with-python-e8cd434645bf\">Variance and Standard Deviation</a> was originally published in <a href=\"https://python.plainenglish.io/\">Python in Plain English</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n",
            "enclosure": {},
            "categories": [
                "data-analysis",
                "data-science",
                "machine-learning",
                "statistics",
                "python"
            ]
        },
        {
            "title": "Testing for Stationarity in Time Series Data",
            "pubDate": "2024-04-02 02:23:32",
            "link": "https://python.plainenglish.io/testing-for-stationarity-in-time-series-data-044401094749?source=rss-41bd992616fb------2",
            "guid": "https://medium.com/p/044401094749",
            "author": "Jason",
            "thumbnail": "",
            "description": "\n<h4>Machine Learning</h4>\n<h4>Explore stationarity and the most common ways to test stationarity in\u00a0python.</h4>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*eqs_lEJTW9WI1Ulo\"><figcaption>Photo by <a href=\"https://unsplash.com/@lukechesser?utm_source=medium&amp;utm_medium=referral\">Luke Chesser</a> on\u00a0<a href=\"https://unsplash.com/?utm_source=medium&amp;utm_medium=referral\">Unsplash</a></figcaption></figure><p>Stationarity is a crucial concept in time series analysis. It influencing how data is perceived and predicted. Stationarity is a fundamental assumption for many time series analysis techniques. Non-stationary data are often transformed to become stationary.</p>\n<p>In this article, we are going to explore what is stationarity, how to test stationarity in\u00a0python.</p>\n<h3><strong>Stationarity</strong></h3>\n<p>Stationarity means statistical properties do not change over time. Stationary data must meet the following assumptions:</p>\n<ul>\n<li>\n<strong>Constant Mean</strong>. The average value of the data remains consistent over time. No any significant trend or fluctuation is crucial for reliable data analysis and modeling.</li>\n<li>\n<strong>Constant Variance</strong>. The dispersion of data points remains constant over time. The absence of drastic changes in variance ensures that the data behaves predictably, allowing for better model accuracy.</li>\n<li>\n<strong>Constant Autocorrelation</strong>. The relationship between data points at different time lags remains constant over time. The constant correlated pattern between data points is pivotal for understanding the time series structure.</li>\n<li>\n<strong>No Trend or Seasonality.</strong> Trend refers to a long-term upward or downward movement in the data, while seasonality involves repeating patterns at fixed intervals. The absence of these patterns in stationary data simplifies modeling and prediction tasks.</li>\n</ul>\n<h3><strong>Testing for Stationarity</strong></h3>\n<p>There are several ways to test stationarity. We are going to explore three of the most common\u00a0ones.</p>\n<h4><strong>visualization</strong></h4>\n<p>visualization\u200a\u2014\u200aplotting the data and checking for statistical properties is he most basic one to test stationarity. We can looks at the data and the Autocorrelation functions(ACF) plots for checking statical properties.</p>\n<ul><li><strong>Looking at the\u00a0Data</strong></li></ul>\n<p>Some properties that can be detected very easily from the plot of the data. For example, if the data has an upward or downward trend, and if the variance appears consistent over time. Let\u2019s take a look at the plots of a series of white noise and randowwalk.</p>\n<pre>import numpy as np<br>import matplotlib.pyplot as plt<br><br>np.random.seed(202404)<br><br>num_of_samples = 100<br><br>def white_norse(num_of_samples):<br>    return np.random.standard_normal(num_of_samples)<br><br>def randomwalk(n):<br>    x = 0<br>    start = x<br>    xposition = []<br>    probabilities = [-1, 1]<br>    for _ in range(n):<br>        x += np.random.choice(probabilities)<br>        xposition.append(x)<br>    return np.array(xposition)<br><br>white_norse_samples = white_norse(num_of_samples)<br>randomwalk_samples = randomwalk(num_of_samples)<br>fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True)<br>ax1.set_title(\"White Noise\")<br>ax1.plot(white_norse_samples)<br>ax2.set_title(\"Romdanwalk\")<br>ax2.plot(randomwalk_samples)</pre>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/554/1*vnygzQyjE2X7JcoRMewgpw.png\"></figure><p>Obviously, the while noise has consistent mean and various over time. It is stationary data. On the other hand, the randomwalk has a downward trend, does not have a consistent mean or variance over time. It is non-stationary data.</p>\n<ul><li><strong>Looking at the Autocorrelation functions(ACF) plots</strong></li></ul>\n<p>Let\u2019s see the ACF plots of above\u00a0data.</p>\n<pre>from statsmodels.graphics.tsaplots import plot_acf<br><br>fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True)<br><br>plot_acf(white_norse_samples, ax1, lags = 99)<br>ax1.set_title(\"ACF Plot for White Norse\")<br><br>plot_acf(randomwalk_samples, ax2, lags = 99)<br>ax2.set_title(\"ACF Plot for Randomwalk\")</pre>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/559/1*TJ8Qy7yFfeW6neTI9HXvNw.png\"></figure><p>The plot for white noise, the value of ACF drops to zero quikly. It is the case of stationary data. However, the plot for randomwalk, the value of ACF decreases slowly. It is non-stationary data.</p>\n<p>Visualization is usually used to get a preliminary idea of stationarity in data. A more rigorous approach is using statistical tests developed to detect specific types of stationarity. The two of common statistical tests are <strong>Augmented Dickey-Fuller Test (ADF)</strong> and <strong>Kwiatkowski-Phillips-Schmidt-Shin Test (KPSS)</strong>. Let\u2019s confirm our above visualization test with ADF and\u00a0KPSS.</p>\n<h4><strong>Augmented Dickey-Fuller Test\u00a0(ADF)</strong></h4>\n<p>Augmented Dickey-Fuller test is one of the most used tests for stationarity. It tests the following hypothesis:</p>\n<ul>\n<li><em>Null hypothesis, H0\u200a\u2014\u200athe time series is not stationary.</em></li>\n<li><em>Alternative Hypothesis, H1\u200a\u2014\u200athe time series is stationary.</em></li>\n</ul>\n<p>We can use the adfuller method from the statsmodels library to perform this test in Python. Then, compares the value of the <strong>test statistics</strong> or the <strong>p-value</strong>. The test result list as\u00a0follows:</p>\n<p>1. Compares the value of the test statistics:</p>\n<ul>\n<li><em>Stationary\u200a\u2014\u200athe absolute value is greater than the critical\u00a0value</em></li>\n<li><em>Non-stationary\u200a\u2014\u200athe absolute value is less than the crucial\u00a0value</em></li>\n</ul>\n<p>2. Compares\u00a0p-value:</p>\n<ul>\n<li><em>Stationary\u200a\u2014\u200ap-value &lt;=\u00a00.05</em></li>\n<li><em>Non-stationary\u200a\u2014\u200ap-value &gt;\u00a00.05</em></li>\n</ul>\n<p>Here is the python\u00a0scripts:</p>\n<pre>from statsmodels.tsa.stattools import adfuller<br>from pprint import pprint<br><br>def adf_test(samples):<br><br><br> test_statistic, p_value, *_ = adfuller(samples)<br> print(f'Test Statistic: {test_statistic}')<br> print(f'P-value: {p_value}')<br><br> # interpret the results<br> if p_value &lt;= 0.05:<br>  print('Reject the null hypothesis: The time series is stationary.')<br> else:<br>  print('Fail to reject the null hypothesis: The time series is non-stationary.')<br><br>adf_test(white_norse_samples)<br># Test Statistic: -6.416288343797171<br># P-value: 1.8378154405121545e-08<br># Reject the null hypothesis: The time series is stationary.<br><br>adf_test(randomwalk_samples)<br># Test Statistic: -2.2091400629727627<br># P-value: 0.20294488186347692<br># Fail to reject the null hypothesis: The time series is non-stationary.</pre>\n<h4><strong>Kwiatkowski-Phillips-Schmidt-Shin Test (KPSS\u00a0Test)</strong></h4>\n<p>The KPSS test is another hypothesis test used to check for stationarity in a time\u00a0series.</p>\n<p>It tests the following hypothesis:</p>\n<ul>\n<li><em>Null hypothesis, H0\u200a\u2014\u200athe time series is stationary.</em></li>\n<li><em>Alternative Hypothesis, H1\u200a\u2014\u200athe time series is not stationary.</em></li>\n</ul>\n<p>We can use the kpss method from the statsmodels library to perform this test in Python. Then, compares the value of the test statistics or the p-value. Since the hypothesis is the opposite of the ADF test, the interpretation of the p-value is also opposite:</p>\n<p>1. Compares the value of the test statistics:</p>\n<ul>\n<li><em>Stationary\u200a\u2014\u200athe absolute value is less than the crucial\u00a0value</em></li>\n<li><em>Non-stationary\u200a\u2014\u200athe absolute value is greater than the critical\u00a0value</em></li>\n</ul>\n<p>2. Compares\u00a0p-value:</p>\n<ul>\n<li><em>Stationary\u200a\u2014\u200ap-value &gt;\u00a00.05</em></li>\n<li><em>Non-stationary\u200a\u2014\u200ap-value &lt;=\u00a00.05</em></li>\n</ul>\n<p>Here is the python\u00a0scripts:</p>\n<pre>from statsmodels.tsa.stattools import kpss<br>import warnings<br>from statsmodels.tools.sm_exceptions import InterpolationWarning<br>warnings.simplefilter('ignore', InterpolationWarning)<br><br>def kpss_test(samples):<br> test_statistic, p_value, *_ = kpss(samples, regression='c')<br><br> print(f'Test Statistic: {test_statistic}')<br> print(f'P-value: {p_value}')<br><br> if p_value &gt; 0.05:<br>  print('Fail to reject the null hypothesis: The time series is stationary.')<br> else:<br>  print('Reject the null hypothesis: The time series is non-stationary.')<br><br>kpss_test(white_norse_samples)<br># Test Statistic: 0.10503398480585609<br># P-value: 0.1<br># Fail to reject the null hypothesis: The time series is stationary.<br><br>kpss_test(randomwalk_samples)<br># Test Statistic: 1.5771286573497258<br># P-value: 0.01<br># Reject the null hypothesis: The time series is non-stationary.</pre>\n<h3>Conclusion</h3>\n<p>Stationarity is crucial in time series analysis. Stationarity is a fundamental assumption for many time series analysis techniques. The three of most common ways for testing stationarity is Visualization, ADF test and KPSS test. For ADF test and KPSS test, we compares the p-value or statistics value to determine the stationarity. It\u2019s often beneficial to perform both ADF and KPSS tests and interpret their results in combination.</p>\n<h3>Jason \ud83d\ude80</h3>\n<p><em>Thank you for reading until the end. Before you\u00a0go:</em></p>\n<p>\ud83d\udc4f Please <strong><em>clap</em></strong> and <strong><em>follow</em></strong>\u00a0me</p>\n<p>\ud83d\udcec <a href=\"https://medium.com/@xuzhusheng/subscribe\">Subscribe</a> to my Medium newsletter for email\u00a0updates!</p>\n<p>\u2615 or just <a href=\"https://www.buymeacoffee.com/jason.xu\">buy me a\u00a0coffee</a></p>\n<h3>In Plain English\u00a0\ud83d\ude80</h3>\n<p><em>Thank you for being a part of the </em><a href=\"https://plainenglish.io/\"><strong><em>In Plain English</em></strong></a><em> community! Before you\u00a0go:</em></p>\n<ul>\n<li>Be sure to <strong>clap</strong> and <strong>follow</strong> the writer\u00a0\ufe0f\ud83d\udc4f<strong>\ufe0f\ufe0f</strong>\n</li>\n<li>Follow us: <a href=\"https://twitter.com/inPlainEngHQ\"><strong>X</strong></a><strong> | </strong><a href=\"https://www.linkedin.com/company/inplainenglish/\"><strong>LinkedIn</strong></a><strong> | </strong><a href=\"https://www.youtube.com/channel/UCtipWUghju290NWcn8jhyAw\"><strong>YouTube</strong></a><strong> | </strong><a href=\"https://discord.gg/in-plain-english-709094664682340443\"><strong>Discord</strong></a><strong> | </strong><a href=\"https://newsletter.plainenglish.io/\"><strong>Newsletter</strong></a>\n</li>\n<li>Visit our other platforms: <a href=\"https://stackademic.com/\"><strong>Stackademic</strong></a><strong> | </strong><a href=\"https://cofeed.app/\"><strong>CoFeed</strong></a><strong> | </strong><a href=\"https://venturemagazine.net/\"><strong>Venture</strong></a><strong> |\u00a0</strong><a href=\"https://blog.cubed.run/\"><strong>Cubed</strong></a>\n</li>\n<li>More content at <a href=\"https://plainenglish.io/\"><strong>PlainEnglish.io</strong></a>\n</li>\n</ul>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=044401094749\" width=\"1\" height=\"1\" alt=\"\"><hr>\n<p><a href=\"https://python.plainenglish.io/testing-for-stationarity-in-time-series-data-044401094749\">Testing for Stationarity in Time Series Data</a> was originally published in <a href=\"https://python.plainenglish.io/\">Python in Plain English</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n",
            "content": "\n<h4>Machine Learning</h4>\n<h4>Explore stationarity and the most common ways to test stationarity in\u00a0python.</h4>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*eqs_lEJTW9WI1Ulo\"><figcaption>Photo by <a href=\"https://unsplash.com/@lukechesser?utm_source=medium&amp;utm_medium=referral\">Luke Chesser</a> on\u00a0<a href=\"https://unsplash.com/?utm_source=medium&amp;utm_medium=referral\">Unsplash</a></figcaption></figure><p>Stationarity is a crucial concept in time series analysis. It influencing how data is perceived and predicted. Stationarity is a fundamental assumption for many time series analysis techniques. Non-stationary data are often transformed to become stationary.</p>\n<p>In this article, we are going to explore what is stationarity, how to test stationarity in\u00a0python.</p>\n<h3><strong>Stationarity</strong></h3>\n<p>Stationarity means statistical properties do not change over time. Stationary data must meet the following assumptions:</p>\n<ul>\n<li>\n<strong>Constant Mean</strong>. The average value of the data remains consistent over time. No any significant trend or fluctuation is crucial for reliable data analysis and modeling.</li>\n<li>\n<strong>Constant Variance</strong>. The dispersion of data points remains constant over time. The absence of drastic changes in variance ensures that the data behaves predictably, allowing for better model accuracy.</li>\n<li>\n<strong>Constant Autocorrelation</strong>. The relationship between data points at different time lags remains constant over time. The constant correlated pattern between data points is pivotal for understanding the time series structure.</li>\n<li>\n<strong>No Trend or Seasonality.</strong> Trend refers to a long-term upward or downward movement in the data, while seasonality involves repeating patterns at fixed intervals. The absence of these patterns in stationary data simplifies modeling and prediction tasks.</li>\n</ul>\n<h3><strong>Testing for Stationarity</strong></h3>\n<p>There are several ways to test stationarity. We are going to explore three of the most common\u00a0ones.</p>\n<h4><strong>visualization</strong></h4>\n<p>visualization\u200a\u2014\u200aplotting the data and checking for statistical properties is he most basic one to test stationarity. We can looks at the data and the Autocorrelation functions(ACF) plots for checking statical properties.</p>\n<ul><li><strong>Looking at the\u00a0Data</strong></li></ul>\n<p>Some properties that can be detected very easily from the plot of the data. For example, if the data has an upward or downward trend, and if the variance appears consistent over time. Let\u2019s take a look at the plots of a series of white noise and randowwalk.</p>\n<pre>import numpy as np<br>import matplotlib.pyplot as plt<br><br>np.random.seed(202404)<br><br>num_of_samples = 100<br><br>def white_norse(num_of_samples):<br>    return np.random.standard_normal(num_of_samples)<br><br>def randomwalk(n):<br>    x = 0<br>    start = x<br>    xposition = []<br>    probabilities = [-1, 1]<br>    for _ in range(n):<br>        x += np.random.choice(probabilities)<br>        xposition.append(x)<br>    return np.array(xposition)<br><br>white_norse_samples = white_norse(num_of_samples)<br>randomwalk_samples = randomwalk(num_of_samples)<br>fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True)<br>ax1.set_title(\"White Noise\")<br>ax1.plot(white_norse_samples)<br>ax2.set_title(\"Romdanwalk\")<br>ax2.plot(randomwalk_samples)</pre>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/554/1*vnygzQyjE2X7JcoRMewgpw.png\"></figure><p>Obviously, the while noise has consistent mean and various over time. It is stationary data. On the other hand, the randomwalk has a downward trend, does not have a consistent mean or variance over time. It is non-stationary data.</p>\n<ul><li><strong>Looking at the Autocorrelation functions(ACF) plots</strong></li></ul>\n<p>Let\u2019s see the ACF plots of above\u00a0data.</p>\n<pre>from statsmodels.graphics.tsaplots import plot_acf<br><br>fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True)<br><br>plot_acf(white_norse_samples, ax1, lags = 99)<br>ax1.set_title(\"ACF Plot for White Norse\")<br><br>plot_acf(randomwalk_samples, ax2, lags = 99)<br>ax2.set_title(\"ACF Plot for Randomwalk\")</pre>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/559/1*TJ8Qy7yFfeW6neTI9HXvNw.png\"></figure><p>The plot for white noise, the value of ACF drops to zero quikly. It is the case of stationary data. However, the plot for randomwalk, the value of ACF decreases slowly. It is non-stationary data.</p>\n<p>Visualization is usually used to get a preliminary idea of stationarity in data. A more rigorous approach is using statistical tests developed to detect specific types of stationarity. The two of common statistical tests are <strong>Augmented Dickey-Fuller Test (ADF)</strong> and <strong>Kwiatkowski-Phillips-Schmidt-Shin Test (KPSS)</strong>. Let\u2019s confirm our above visualization test with ADF and\u00a0KPSS.</p>\n<h4><strong>Augmented Dickey-Fuller Test\u00a0(ADF)</strong></h4>\n<p>Augmented Dickey-Fuller test is one of the most used tests for stationarity. It tests the following hypothesis:</p>\n<ul>\n<li><em>Null hypothesis, H0\u200a\u2014\u200athe time series is not stationary.</em></li>\n<li><em>Alternative Hypothesis, H1\u200a\u2014\u200athe time series is stationary.</em></li>\n</ul>\n<p>We can use the adfuller method from the statsmodels library to perform this test in Python. Then, compares the value of the <strong>test statistics</strong> or the <strong>p-value</strong>. The test result list as\u00a0follows:</p>\n<p>1. Compares the value of the test statistics:</p>\n<ul>\n<li><em>Stationary\u200a\u2014\u200athe absolute value is greater than the critical\u00a0value</em></li>\n<li><em>Non-stationary\u200a\u2014\u200athe absolute value is less than the crucial\u00a0value</em></li>\n</ul>\n<p>2. Compares\u00a0p-value:</p>\n<ul>\n<li><em>Stationary\u200a\u2014\u200ap-value &lt;=\u00a00.05</em></li>\n<li><em>Non-stationary\u200a\u2014\u200ap-value &gt;\u00a00.05</em></li>\n</ul>\n<p>Here is the python\u00a0scripts:</p>\n<pre>from statsmodels.tsa.stattools import adfuller<br>from pprint import pprint<br><br>def adf_test(samples):<br><br><br> test_statistic, p_value, *_ = adfuller(samples)<br> print(f'Test Statistic: {test_statistic}')<br> print(f'P-value: {p_value}')<br><br> # interpret the results<br> if p_value &lt;= 0.05:<br>  print('Reject the null hypothesis: The time series is stationary.')<br> else:<br>  print('Fail to reject the null hypothesis: The time series is non-stationary.')<br><br>adf_test(white_norse_samples)<br># Test Statistic: -6.416288343797171<br># P-value: 1.8378154405121545e-08<br># Reject the null hypothesis: The time series is stationary.<br><br>adf_test(randomwalk_samples)<br># Test Statistic: -2.2091400629727627<br># P-value: 0.20294488186347692<br># Fail to reject the null hypothesis: The time series is non-stationary.</pre>\n<h4><strong>Kwiatkowski-Phillips-Schmidt-Shin Test (KPSS\u00a0Test)</strong></h4>\n<p>The KPSS test is another hypothesis test used to check for stationarity in a time\u00a0series.</p>\n<p>It tests the following hypothesis:</p>\n<ul>\n<li><em>Null hypothesis, H0\u200a\u2014\u200athe time series is stationary.</em></li>\n<li><em>Alternative Hypothesis, H1\u200a\u2014\u200athe time series is not stationary.</em></li>\n</ul>\n<p>We can use the kpss method from the statsmodels library to perform this test in Python. Then, compares the value of the test statistics or the p-value. Since the hypothesis is the opposite of the ADF test, the interpretation of the p-value is also opposite:</p>\n<p>1. Compares the value of the test statistics:</p>\n<ul>\n<li><em>Stationary\u200a\u2014\u200athe absolute value is less than the crucial\u00a0value</em></li>\n<li><em>Non-stationary\u200a\u2014\u200athe absolute value is greater than the critical\u00a0value</em></li>\n</ul>\n<p>2. Compares\u00a0p-value:</p>\n<ul>\n<li><em>Stationary\u200a\u2014\u200ap-value &gt;\u00a00.05</em></li>\n<li><em>Non-stationary\u200a\u2014\u200ap-value &lt;=\u00a00.05</em></li>\n</ul>\n<p>Here is the python\u00a0scripts:</p>\n<pre>from statsmodels.tsa.stattools import kpss<br>import warnings<br>from statsmodels.tools.sm_exceptions import InterpolationWarning<br>warnings.simplefilter('ignore', InterpolationWarning)<br><br>def kpss_test(samples):<br> test_statistic, p_value, *_ = kpss(samples, regression='c')<br><br> print(f'Test Statistic: {test_statistic}')<br> print(f'P-value: {p_value}')<br><br> if p_value &gt; 0.05:<br>  print('Fail to reject the null hypothesis: The time series is stationary.')<br> else:<br>  print('Reject the null hypothesis: The time series is non-stationary.')<br><br>kpss_test(white_norse_samples)<br># Test Statistic: 0.10503398480585609<br># P-value: 0.1<br># Fail to reject the null hypothesis: The time series is stationary.<br><br>kpss_test(randomwalk_samples)<br># Test Statistic: 1.5771286573497258<br># P-value: 0.01<br># Reject the null hypothesis: The time series is non-stationary.</pre>\n<h3>Conclusion</h3>\n<p>Stationarity is crucial in time series analysis. Stationarity is a fundamental assumption for many time series analysis techniques. The three of most common ways for testing stationarity is Visualization, ADF test and KPSS test. For ADF test and KPSS test, we compares the p-value or statistics value to determine the stationarity. It\u2019s often beneficial to perform both ADF and KPSS tests and interpret their results in combination.</p>\n<h3>Jason \ud83d\ude80</h3>\n<p><em>Thank you for reading until the end. Before you\u00a0go:</em></p>\n<p>\ud83d\udc4f Please <strong><em>clap</em></strong> and <strong><em>follow</em></strong>\u00a0me</p>\n<p>\ud83d\udcec <a href=\"https://medium.com/@xuzhusheng/subscribe\">Subscribe</a> to my Medium newsletter for email\u00a0updates!</p>\n<p>\u2615 or just <a href=\"https://www.buymeacoffee.com/jason.xu\">buy me a\u00a0coffee</a></p>\n<h3>In Plain English\u00a0\ud83d\ude80</h3>\n<p><em>Thank you for being a part of the </em><a href=\"https://plainenglish.io/\"><strong><em>In Plain English</em></strong></a><em> community! Before you\u00a0go:</em></p>\n<ul>\n<li>Be sure to <strong>clap</strong> and <strong>follow</strong> the writer\u00a0\ufe0f\ud83d\udc4f<strong>\ufe0f\ufe0f</strong>\n</li>\n<li>Follow us: <a href=\"https://twitter.com/inPlainEngHQ\"><strong>X</strong></a><strong> | </strong><a href=\"https://www.linkedin.com/company/inplainenglish/\"><strong>LinkedIn</strong></a><strong> | </strong><a href=\"https://www.youtube.com/channel/UCtipWUghju290NWcn8jhyAw\"><strong>YouTube</strong></a><strong> | </strong><a href=\"https://discord.gg/in-plain-english-709094664682340443\"><strong>Discord</strong></a><strong> | </strong><a href=\"https://newsletter.plainenglish.io/\"><strong>Newsletter</strong></a>\n</li>\n<li>Visit our other platforms: <a href=\"https://stackademic.com/\"><strong>Stackademic</strong></a><strong> | </strong><a href=\"https://cofeed.app/\"><strong>CoFeed</strong></a><strong> | </strong><a href=\"https://venturemagazine.net/\"><strong>Venture</strong></a><strong> |\u00a0</strong><a href=\"https://blog.cubed.run/\"><strong>Cubed</strong></a>\n</li>\n<li>More content at <a href=\"https://plainenglish.io/\"><strong>PlainEnglish.io</strong></a>\n</li>\n</ul>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=044401094749\" width=\"1\" height=\"1\" alt=\"\"><hr>\n<p><a href=\"https://python.plainenglish.io/testing-for-stationarity-in-time-series-data-044401094749\">Testing for Stationarity in Time Series Data</a> was originally published in <a href=\"https://python.plainenglish.io/\">Python in Plain English</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n",
            "enclosure": {},
            "categories": [
                "data-science",
                "python",
                "time-series-analysis",
                "data-analysis",
                "machine-learning"
            ]
        },
        {
            "title": "Accuracy, Precision, Recall and F-score in Machine Learning",
            "pubDate": "2024-03-26 04:35:17",
            "link": "https://python.plainenglish.io/precision-recall-and-f-score-614e00f5c15c?source=rss-41bd992616fb------2",
            "guid": "https://medium.com/p/614e00f5c15c",
            "author": "Jason",
            "thumbnail": "",
            "description": "\n<h4>Machine Learning</h4>\n<h4>What is the differnet? Which one should we\u00a0choose?</h4>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*QTkItc7UFREV0umY\"><figcaption>Photo by <a href=\"https://unsplash.com/@javaistan?utm_source=medium&amp;utm_medium=referral\">Afif Ramdhasuma</a> on\u00a0<a href=\"https://unsplash.com/?utm_source=medium&amp;utm_medium=referral\">Unsplash</a></figcaption></figure><p>In machine learning, there are various metrics, such as accuracy, precision, recall, and the F1 score for evaluating the performance of a classification model. What is the difference? Which one should we\u00a0choose?</p>\n<p>In This article, we are going to explore the metrics: accuracy, precision, recall, and F-score. Before we start, we need to comprehend the confusion matrix\u00a0first.</p>\n<h3>Confusion Matrix</h3>\n<p>A confusion matrix represents the predictive performance of a classification model on a dataset. Here is a confusion matrix structure:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/421/1*eRytmm4XurqgAvZbo01FBg.png\"></figure><p>For classification tasks, the terms positive and negative refer to the classifier\u2019s prediction, and the terms true and false refer to whether that prediction is correct. The combinations of these terms are the four essential components of a confusion matrix:</p>\n<ul>\n<li><em>True Positives (TP): Number of items correctly predicted as positive.</em></li>\n<li><em>False Positives (FP): Number of items wrongly predicted as positive.</em></li>\n<li><em>True Negatives (TN): Number of items correctly predicted as negative.</em></li>\n<li><em>False Negatives (FN): Number of items wrongly predicted as negative.</em></li>\n</ul>\n<h4>\n<strong>Compute </strong>Confusion Matrix<strong> in\u00a0Python</strong>\n</h4>\n<p>We could compute confusion matrix in 3\u00a0steps:</p>\n<ol>\n<li>Maps TP, FP, TN, FN to binary 11, 01, 00,\u00a010</li>\n<li>marks which quadrant a item belong by bitwise operation y_true &lt; 1 |\u00a0y_pred</li>\n<li>counts marks for each\u00a0quadrant</li>\n</ol>\n<p>Here is the\u00a0scripts:</p>\n<pre>from collections import Counter<br>import sklearn.metrics as metrics<br>import numpy as np<br><br>np.random.seed(202403)<br><br># preparing data<br>y_true, y_pred = np.random.randint(0, 2, size=[2, 100])<br><br><br>MATRIX_TP_INDEX = 1,1<br>MATRIX_FP_INDEX = 0,1<br>MATRIX_TN_INDEX = 0,0<br>MATRIX_FN_INDEX = 1,0<br><br># returned matrix is consistent with the one computed by sciket-learn package<br># TN: c_{0,0}<br># FN: c_{1,0}<br># FP: c_{0,1}<br># TP: c_{1,1}<br>def confusion_matrix(y_true, y_pred):<br>    counter = Counter(y_true &lt;&lt; 1 | y_pred)<br>    matrix = np.zeros((2,2), dtype=np.int32)<br>    for i in range(2):<br>        for j in range(2):<br>            matrix[i, j] = counter[i &lt;&lt; 1 | j]<br>    return matrix<br><br>matrix = confusion_matrix(y_true, y_pred)<br>print(matrix)  <br># [[30 21]<br>#  [27 22]]<br><br>print(f'TP: {matrix[MATRIX_TP_INDEX]}') #TP: 22<br>print(f'FP: {matrix[MATRIX_FP_INDEX]}') #FP: 21<br>print(f'TN: {matrix[MATRIX_TN_INDEX]}') #TN: 30<br>print(f'FN: {matrix[MATRIX_FN_INDEX]}') #FN: 27<br><br># computed by scikit-learn package for contrast<br>print(metrics.confusion_matrix(y_true, y_pred))  <br># [[30 21]<br>#  [27 22]]</pre>\n<h3>Accuracy</h3>\n<p><strong>Accuracy</strong> represents the number of items predicted correctly divided by total number of\u00a0items:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/677/1*2Kp8TPmrdvo3FCdJq-Vrng.png\"></figure><p>The number of items predicted correctly is the sum of TP + TN and the total number is the sum of TP + TN + FP + FN, Mathmaticly, accuracy defined as\u00a0follows:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/677/1*sT6uSQVXnf-q4iPpPE2SOg.png\"></figure><h4><strong>Calculate Accuracy in\u00a0Python</strong></h4>\n<p>According to the defination, accuracy could be calculated as\u00a0follows:</p>\n<pre>def accuracy_score(y_true, y_pred):<br>    matrix = confusion_matrix(y_true, y_pred)<br>    tp = matrix[MATRIX_TP_INDEX]<br>    fp = matrix[MATRIX_FP_INDEX]<br>    tn = matrix[MATRIX_TN_INDEX]<br>    fn = matrix[MATRIX_FN_INDEX]<br>    return (tp + tn) / (tp + fp + tn + fn)<br><br>print(accuracy_score(y_true, y_pred))  #0.52<br>print(metrics.accuracy_score(y_true, y_pred))  #0.52</pre>\n<h4><strong>Limitation of\u00a0Accuracy</strong></h4>\n<p>The accuracy rate can evluate the total correct rate, but accuracy could be misled in imbalanced dataset. For example, detecting spam in emails. Assume 95% of emails are spam, a model simply predict all of emails are spam, the accuracy of this model is 95%, which make no sense. Accuracy is not valid for imbalanced dataset.</p>\n<h3><strong>Precision and\u00a0Recall</strong></h3>\n<h4><strong>Precision</strong></h4>\n<p><strong>Precision</strong> (also called positive predictive value) represents the number of items correctly predicted as positive(TP) divided by the total number of items predicted as positive:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/677/1*qSo58VUIMLt3Yh3orIQfFQ.png\"></figure><p>The total number of items predicted as positive is the sum of true positives(TP) and false positives(FP). Precision mathmaticly defined\u00a0as:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/677/1*PPclrOn1eF1IcJDzV8dNzA.png\"></figure><h4><strong>Recall</strong></h4>\n<p><strong>Recall</strong> (also known as sensitivity) represents the number of true positives divided by the total number of items that actually belong to the positive\u00a0class.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/677/1*lryGgGmqtlePkIgxSIA3rA.png\"></figure><p>The total number of items that actually belong to the positive class is the sum of true positives(TP) and false negatives(FN). Recall mathmaticly defined\u00a0as:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/677/1*nncPuOe2L12HImryaKl-Mw.png\"></figure><h4>Compute Precision and Recall in\u00a0Python</h4>\n<pre>def precision_score(y_true, y_pred):<br>    matrix = confusion_matrix(y_true, y_pred)<br>    tp = matrix[MATRIX_TP_INDEX]<br>    fp = matrix[MATRIX_FP_INDEX]<br>    return tp / (tp + fp)<br><br>print(precision_score(y_true, y_pred))  #0.5116279069767442<br>print(metrics.precision_score(y_true, y_pred))  #0.5116279069767442<br><br>def recall_score(y_true, y_pred):<br>    matrix = confusion_matrix(y_true, y_pred)<br>    tp = matrix[MATRIX_TP_INDEX]<br>    fn = matrix[MATRIX_FN_INDEX]<br>    return tp / (tp + fn)<br><br>print(recall_score(y_true, y_pred)) #0.4489795918367347<br>print(metrics.recall_score(y_true, y_pred)) #0.4489795918367347</pre>\n<h4><strong>Precision vs.\u00a0Recall</strong></h4>\n<p>Precision and recall are not particularly useful metrics when used in isolation. It is possible to have perfect recall by retrieving every single item. Likewise, it is possible to have near-perfect precision by selecting only a very small number of extremely likely items. We need to take both precision and recall into account. Ideally, we want to maximize both precision and recall\u00a0metrics.</p>\n<p>However, there is an inverse relationship between precision and recall, where it is possible to increase one at the cost of reducing the other. How to balance between precision and recall is the\u00a0dilemma.</p>\n<p>A measure combines precision and recall, symmetrically represents both measures in one metric is F-measure, also called\u00a0F-score.</p>\n<h3><strong>F-score/F-measure</strong></h3>\n<p>The F-score combines precision and recall using their harmonic mean, and maximizing the F score implies simultaneously maximizing both precision and recall. There are two different variations of F-score: F1 score and F\u03b2\u00a0Score.</p>\n<h4><strong>F1 Score</strong></h4>\n<p>F1 score is the traditional F-measure or balanced F-score. It is the harmonic mean of the precision and recall. F1 score defined as\u00a0follows:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/677/1*QM3HjjmEmddOqKYYexKsiw.png\"></figure><p>By replacing the expressions for precision and recall scores in the equation above, the F1 score can also be written as\u00a0follows:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/677/1*u2SLUm-wsP4UgAV8OerCng.png\"></figure><p>The highest possible value of an F-score is 1.0, indicating perfect precision and recall, and the lowest possible value is 0, if either precision or recall are\u00a0zero.</p>\n<p>The more generic F-score applies additional weights \u03b2 is F\u03b2 score. We will discuss it later. Before that, let\u2019s see how to compute F1 score in\u00a0Python.</p>\n<h4>Compute F1 Score in\u00a0Python</h4>\n<pre>def f1_score(y_true, y_pred):<br>    matrix = confusion_matrix(y_true, y_pred)<br>    tp = matrix[MATRIX_TP_INDEX]<br>    fp = matrix[MATRIX_FP_INDEX]<br>    fn = matrix[MATRIX_FN_INDEX]<br>    return 2 * tp / (2 * tp + fp + fn)<br><br>print(f1_score(y_true, y_pred)) #0.4782608695652174<br>print(metrics.f1_score(y_true, y_pred)) #0.47826086956521735</pre>\n<h4><strong>F\u03b2 Score</strong></h4>\n<p>F\u03b2 Score is a general F score. It uses a positive real factor \u03b2, where recall is considered</p>\n<p>\u03b2 times as important as precision. F\u03b2 Score defined as\u00a0follows:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/677/1*2OsIhnny3N_vCFMiYiayTg.png\"></figure><p>There are two other commonly used F\u03b2 measures:</p>\n<ul>\n<li>F2 measure\u200a\u2014\u200aweights recall higher than precision</li>\n<li>F0.5 measure\u200a\u2014\u200aputs more emphasis on precision than\u00a0recall.</li>\n</ul>\n<p>The F\u03b2 score is useful when we want to prioritize one measure while preserving results from the other\u00a0measure.</p>\n<p>For example, the COVID-19 detection, False Negative results are detrimental (Since a COVID positive patient is diagnosed as COVID negative, leading to the spread of the disease). In this case, the F2 measure is more useful to minimize the False Negatives while also trying to keep the precision score as high as possible. however, for general medical diagnosis, a false positive test can lead to unnecessary treatment and expenses, it is necessary to reduce the False Positives, with a lower \u03b2 value (like an F0.5\u00a0score).</p>\n<h3><strong>Conclusion</strong></h3>\n<p>Accuracy works good for balanced dataset, but is not valid for imbalanced dataset.</p>\n<p>Precision and recall also could be deceived when used in isolation, it is quite tricky to balance\u00a0both.</p>\n<p>F1 score offers a more balanced assessment through the harmonic mean of precision and recall. It is a much more comprehensive evaluation metric in comparison with precision and\u00a0recall.</p>\n<p>Furthermore, F\u03b2 score, allow controlling the F score metric based on the problem at hand by prioritizing the minimization of either false positive or false negative\u00a0losses.</p>\n<h3>Jason \ud83d\ude80</h3>\n<p><em>Thank you for reading until the end. Before you\u00a0go:</em></p>\n<p>\ud83d\udc4f Please <strong><em>clap</em></strong> and <strong><em>follow</em></strong>\u00a0me</p>\n<p>\ud83d\udcec <a href=\"https://medium.com/@xuzhusheng/subscribe\">Subscribe</a> to my Medium newsletter for email\u00a0updates!</p>\n<p>\u2615 or just <a href=\"https://www.buymeacoffee.com/jason.xu\">buy me a\u00a0coffee</a></p>\n<h3>In Plain English\u00a0\ud83d\ude80</h3>\n<p><em>Thank you for being a part of the </em><a href=\"https://plainenglish.io/\"><strong><em>In Plain English</em></strong></a><em> community! Before you\u00a0go:</em></p>\n<ul>\n<li>Be sure to <strong>clap</strong> and <strong>follow</strong> the writer\u00a0\ufe0f\ud83d\udc4f<strong>\ufe0f\ufe0f</strong>\n</li>\n<li>Follow us: <a href=\"https://twitter.com/inPlainEngHQ\"><strong>X</strong></a><strong> | </strong><a href=\"https://www.linkedin.com/company/inplainenglish/\"><strong>LinkedIn</strong></a><strong> | </strong><a href=\"https://www.youtube.com/channel/UCtipWUghju290NWcn8jhyAw\"><strong>YouTube</strong></a><strong> | </strong><a href=\"https://discord.gg/in-plain-english-709094664682340443\"><strong>Discord</strong></a><strong> | </strong><a href=\"https://newsletter.plainenglish.io/\"><strong>Newsletter</strong></a>\n</li>\n<li>Visit our other platforms: <a href=\"https://stackademic.com/\"><strong>Stackademic</strong></a><strong> | </strong><a href=\"https://cofeed.app/\"><strong>CoFeed</strong></a><strong> | </strong><a href=\"https://venturemagazine.net/\"><strong>Venture</strong></a><strong> |\u00a0</strong><a href=\"https://blog.cubed.run/\"><strong>Cubed</strong></a>\n</li>\n<li>More content at <a href=\"https://plainenglish.io/\"><strong>PlainEnglish.io</strong></a>\n</li>\n</ul>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=614e00f5c15c\" width=\"1\" height=\"1\" alt=\"\"><hr>\n<p><a href=\"https://python.plainenglish.io/precision-recall-and-f-score-614e00f5c15c\">Accuracy, Precision, Recall and F-score in Machine Learning</a> was originally published in <a href=\"https://python.plainenglish.io/\">Python in Plain English</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n",
            "content": "\n<h4>Machine Learning</h4>\n<h4>What is the differnet? Which one should we\u00a0choose?</h4>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*QTkItc7UFREV0umY\"><figcaption>Photo by <a href=\"https://unsplash.com/@javaistan?utm_source=medium&amp;utm_medium=referral\">Afif Ramdhasuma</a> on\u00a0<a href=\"https://unsplash.com/?utm_source=medium&amp;utm_medium=referral\">Unsplash</a></figcaption></figure><p>In machine learning, there are various metrics, such as accuracy, precision, recall, and the F1 score for evaluating the performance of a classification model. What is the difference? Which one should we\u00a0choose?</p>\n<p>In This article, we are going to explore the metrics: accuracy, precision, recall, and F-score. Before we start, we need to comprehend the confusion matrix\u00a0first.</p>\n<h3>Confusion Matrix</h3>\n<p>A confusion matrix represents the predictive performance of a classification model on a dataset. Here is a confusion matrix structure:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/421/1*eRytmm4XurqgAvZbo01FBg.png\"></figure><p>For classification tasks, the terms positive and negative refer to the classifier\u2019s prediction, and the terms true and false refer to whether that prediction is correct. The combinations of these terms are the four essential components of a confusion matrix:</p>\n<ul>\n<li><em>True Positives (TP): Number of items correctly predicted as positive.</em></li>\n<li><em>False Positives (FP): Number of items wrongly predicted as positive.</em></li>\n<li><em>True Negatives (TN): Number of items correctly predicted as negative.</em></li>\n<li><em>False Negatives (FN): Number of items wrongly predicted as negative.</em></li>\n</ul>\n<h4>\n<strong>Compute </strong>Confusion Matrix<strong> in\u00a0Python</strong>\n</h4>\n<p>We could compute confusion matrix in 3\u00a0steps:</p>\n<ol>\n<li>Maps TP, FP, TN, FN to binary 11, 01, 00,\u00a010</li>\n<li>marks which quadrant a item belong by bitwise operation y_true &lt; 1 |\u00a0y_pred</li>\n<li>counts marks for each\u00a0quadrant</li>\n</ol>\n<p>Here is the\u00a0scripts:</p>\n<pre>from collections import Counter<br>import sklearn.metrics as metrics<br>import numpy as np<br><br>np.random.seed(202403)<br><br># preparing data<br>y_true, y_pred = np.random.randint(0, 2, size=[2, 100])<br><br><br>MATRIX_TP_INDEX = 1,1<br>MATRIX_FP_INDEX = 0,1<br>MATRIX_TN_INDEX = 0,0<br>MATRIX_FN_INDEX = 1,0<br><br># returned matrix is consistent with the one computed by sciket-learn package<br># TN: c_{0,0}<br># FN: c_{1,0}<br># FP: c_{0,1}<br># TP: c_{1,1}<br>def confusion_matrix(y_true, y_pred):<br>    counter = Counter(y_true &lt;&lt; 1 | y_pred)<br>    matrix = np.zeros((2,2), dtype=np.int32)<br>    for i in range(2):<br>        for j in range(2):<br>            matrix[i, j] = counter[i &lt;&lt; 1 | j]<br>    return matrix<br><br>matrix = confusion_matrix(y_true, y_pred)<br>print(matrix)  <br># [[30 21]<br>#  [27 22]]<br><br>print(f'TP: {matrix[MATRIX_TP_INDEX]}') #TP: 22<br>print(f'FP: {matrix[MATRIX_FP_INDEX]}') #FP: 21<br>print(f'TN: {matrix[MATRIX_TN_INDEX]}') #TN: 30<br>print(f'FN: {matrix[MATRIX_FN_INDEX]}') #FN: 27<br><br># computed by scikit-learn package for contrast<br>print(metrics.confusion_matrix(y_true, y_pred))  <br># [[30 21]<br>#  [27 22]]</pre>\n<h3>Accuracy</h3>\n<p><strong>Accuracy</strong> represents the number of items predicted correctly divided by total number of\u00a0items:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/677/1*2Kp8TPmrdvo3FCdJq-Vrng.png\"></figure><p>The number of items predicted correctly is the sum of TP + TN and the total number is the sum of TP + TN + FP + FN, Mathmaticly, accuracy defined as\u00a0follows:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/677/1*sT6uSQVXnf-q4iPpPE2SOg.png\"></figure><h4><strong>Calculate Accuracy in\u00a0Python</strong></h4>\n<p>According to the defination, accuracy could be calculated as\u00a0follows:</p>\n<pre>def accuracy_score(y_true, y_pred):<br>    matrix = confusion_matrix(y_true, y_pred)<br>    tp = matrix[MATRIX_TP_INDEX]<br>    fp = matrix[MATRIX_FP_INDEX]<br>    tn = matrix[MATRIX_TN_INDEX]<br>    fn = matrix[MATRIX_FN_INDEX]<br>    return (tp + tn) / (tp + fp + tn + fn)<br><br>print(accuracy_score(y_true, y_pred))  #0.52<br>print(metrics.accuracy_score(y_true, y_pred))  #0.52</pre>\n<h4><strong>Limitation of\u00a0Accuracy</strong></h4>\n<p>The accuracy rate can evluate the total correct rate, but accuracy could be misled in imbalanced dataset. For example, detecting spam in emails. Assume 95% of emails are spam, a model simply predict all of emails are spam, the accuracy of this model is 95%, which make no sense. Accuracy is not valid for imbalanced dataset.</p>\n<h3><strong>Precision and\u00a0Recall</strong></h3>\n<h4><strong>Precision</strong></h4>\n<p><strong>Precision</strong> (also called positive predictive value) represents the number of items correctly predicted as positive(TP) divided by the total number of items predicted as positive:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/677/1*qSo58VUIMLt3Yh3orIQfFQ.png\"></figure><p>The total number of items predicted as positive is the sum of true positives(TP) and false positives(FP). Precision mathmaticly defined\u00a0as:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/677/1*PPclrOn1eF1IcJDzV8dNzA.png\"></figure><h4><strong>Recall</strong></h4>\n<p><strong>Recall</strong> (also known as sensitivity) represents the number of true positives divided by the total number of items that actually belong to the positive\u00a0class.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/677/1*lryGgGmqtlePkIgxSIA3rA.png\"></figure><p>The total number of items that actually belong to the positive class is the sum of true positives(TP) and false negatives(FN). Recall mathmaticly defined\u00a0as:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/677/1*nncPuOe2L12HImryaKl-Mw.png\"></figure><h4>Compute Precision and Recall in\u00a0Python</h4>\n<pre>def precision_score(y_true, y_pred):<br>    matrix = confusion_matrix(y_true, y_pred)<br>    tp = matrix[MATRIX_TP_INDEX]<br>    fp = matrix[MATRIX_FP_INDEX]<br>    return tp / (tp + fp)<br><br>print(precision_score(y_true, y_pred))  #0.5116279069767442<br>print(metrics.precision_score(y_true, y_pred))  #0.5116279069767442<br><br>def recall_score(y_true, y_pred):<br>    matrix = confusion_matrix(y_true, y_pred)<br>    tp = matrix[MATRIX_TP_INDEX]<br>    fn = matrix[MATRIX_FN_INDEX]<br>    return tp / (tp + fn)<br><br>print(recall_score(y_true, y_pred)) #0.4489795918367347<br>print(metrics.recall_score(y_true, y_pred)) #0.4489795918367347</pre>\n<h4><strong>Precision vs.\u00a0Recall</strong></h4>\n<p>Precision and recall are not particularly useful metrics when used in isolation. It is possible to have perfect recall by retrieving every single item. Likewise, it is possible to have near-perfect precision by selecting only a very small number of extremely likely items. We need to take both precision and recall into account. Ideally, we want to maximize both precision and recall\u00a0metrics.</p>\n<p>However, there is an inverse relationship between precision and recall, where it is possible to increase one at the cost of reducing the other. How to balance between precision and recall is the\u00a0dilemma.</p>\n<p>A measure combines precision and recall, symmetrically represents both measures in one metric is F-measure, also called\u00a0F-score.</p>\n<h3><strong>F-score/F-measure</strong></h3>\n<p>The F-score combines precision and recall using their harmonic mean, and maximizing the F score implies simultaneously maximizing both precision and recall. There are two different variations of F-score: F1 score and F\u03b2\u00a0Score.</p>\n<h4><strong>F1 Score</strong></h4>\n<p>F1 score is the traditional F-measure or balanced F-score. It is the harmonic mean of the precision and recall. F1 score defined as\u00a0follows:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/677/1*QM3HjjmEmddOqKYYexKsiw.png\"></figure><p>By replacing the expressions for precision and recall scores in the equation above, the F1 score can also be written as\u00a0follows:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/677/1*u2SLUm-wsP4UgAV8OerCng.png\"></figure><p>The highest possible value of an F-score is 1.0, indicating perfect precision and recall, and the lowest possible value is 0, if either precision or recall are\u00a0zero.</p>\n<p>The more generic F-score applies additional weights \u03b2 is F\u03b2 score. We will discuss it later. Before that, let\u2019s see how to compute F1 score in\u00a0Python.</p>\n<h4>Compute F1 Score in\u00a0Python</h4>\n<pre>def f1_score(y_true, y_pred):<br>    matrix = confusion_matrix(y_true, y_pred)<br>    tp = matrix[MATRIX_TP_INDEX]<br>    fp = matrix[MATRIX_FP_INDEX]<br>    fn = matrix[MATRIX_FN_INDEX]<br>    return 2 * tp / (2 * tp + fp + fn)<br><br>print(f1_score(y_true, y_pred)) #0.4782608695652174<br>print(metrics.f1_score(y_true, y_pred)) #0.47826086956521735</pre>\n<h4><strong>F\u03b2 Score</strong></h4>\n<p>F\u03b2 Score is a general F score. It uses a positive real factor \u03b2, where recall is considered</p>\n<p>\u03b2 times as important as precision. F\u03b2 Score defined as\u00a0follows:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/677/1*2OsIhnny3N_vCFMiYiayTg.png\"></figure><p>There are two other commonly used F\u03b2 measures:</p>\n<ul>\n<li>F2 measure\u200a\u2014\u200aweights recall higher than precision</li>\n<li>F0.5 measure\u200a\u2014\u200aputs more emphasis on precision than\u00a0recall.</li>\n</ul>\n<p>The F\u03b2 score is useful when we want to prioritize one measure while preserving results from the other\u00a0measure.</p>\n<p>For example, the COVID-19 detection, False Negative results are detrimental (Since a COVID positive patient is diagnosed as COVID negative, leading to the spread of the disease). In this case, the F2 measure is more useful to minimize the False Negatives while also trying to keep the precision score as high as possible. however, for general medical diagnosis, a false positive test can lead to unnecessary treatment and expenses, it is necessary to reduce the False Positives, with a lower \u03b2 value (like an F0.5\u00a0score).</p>\n<h3><strong>Conclusion</strong></h3>\n<p>Accuracy works good for balanced dataset, but is not valid for imbalanced dataset.</p>\n<p>Precision and recall also could be deceived when used in isolation, it is quite tricky to balance\u00a0both.</p>\n<p>F1 score offers a more balanced assessment through the harmonic mean of precision and recall. It is a much more comprehensive evaluation metric in comparison with precision and\u00a0recall.</p>\n<p>Furthermore, F\u03b2 score, allow controlling the F score metric based on the problem at hand by prioritizing the minimization of either false positive or false negative\u00a0losses.</p>\n<h3>Jason \ud83d\ude80</h3>\n<p><em>Thank you for reading until the end. Before you\u00a0go:</em></p>\n<p>\ud83d\udc4f Please <strong><em>clap</em></strong> and <strong><em>follow</em></strong>\u00a0me</p>\n<p>\ud83d\udcec <a href=\"https://medium.com/@xuzhusheng/subscribe\">Subscribe</a> to my Medium newsletter for email\u00a0updates!</p>\n<p>\u2615 or just <a href=\"https://www.buymeacoffee.com/jason.xu\">buy me a\u00a0coffee</a></p>\n<h3>In Plain English\u00a0\ud83d\ude80</h3>\n<p><em>Thank you for being a part of the </em><a href=\"https://plainenglish.io/\"><strong><em>In Plain English</em></strong></a><em> community! Before you\u00a0go:</em></p>\n<ul>\n<li>Be sure to <strong>clap</strong> and <strong>follow</strong> the writer\u00a0\ufe0f\ud83d\udc4f<strong>\ufe0f\ufe0f</strong>\n</li>\n<li>Follow us: <a href=\"https://twitter.com/inPlainEngHQ\"><strong>X</strong></a><strong> | </strong><a href=\"https://www.linkedin.com/company/inplainenglish/\"><strong>LinkedIn</strong></a><strong> | </strong><a href=\"https://www.youtube.com/channel/UCtipWUghju290NWcn8jhyAw\"><strong>YouTube</strong></a><strong> | </strong><a href=\"https://discord.gg/in-plain-english-709094664682340443\"><strong>Discord</strong></a><strong> | </strong><a href=\"https://newsletter.plainenglish.io/\"><strong>Newsletter</strong></a>\n</li>\n<li>Visit our other platforms: <a href=\"https://stackademic.com/\"><strong>Stackademic</strong></a><strong> | </strong><a href=\"https://cofeed.app/\"><strong>CoFeed</strong></a><strong> | </strong><a href=\"https://venturemagazine.net/\"><strong>Venture</strong></a><strong> |\u00a0</strong><a href=\"https://blog.cubed.run/\"><strong>Cubed</strong></a>\n</li>\n<li>More content at <a href=\"https://plainenglish.io/\"><strong>PlainEnglish.io</strong></a>\n</li>\n</ul>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=614e00f5c15c\" width=\"1\" height=\"1\" alt=\"\"><hr>\n<p><a href=\"https://python.plainenglish.io/precision-recall-and-f-score-614e00f5c15c\">Accuracy, Precision, Recall and F-score in Machine Learning</a> was originally published in <a href=\"https://python.plainenglish.io/\">Python in Plain English</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n",
            "enclosure": {},
            "categories": [
                "data-science",
                "data-analysis",
                "statistics",
                "machine-learning",
                "python"
            ]
        },
        {
            "title": "Constructs Bounding Volume Hierarchy(BVH) with Surface Area Heuristic(SAH) in Python",
            "pubDate": "2024-03-14 11:01:47",
            "link": "https://python.plainenglish.io/constructs-bounding-volume-hierarchy-bvh-with-surface-area-heuristic-sah-in-python-89c14afb2f03?source=rss-41bd992616fb------2",
            "guid": "https://medium.com/p/89c14afb2f03",
            "author": "Jason",
            "thumbnail": "",
            "description": "\n<h4>algorithm</h4>\n<h4>A step by step guide go build Bounding Volume Hierarchy(BVH) with Surface Area Heuristic(SAH) in\u00a0Python</h4>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*t76pREm7YKp9PbBg\"><figcaption>Photo by <a href=\"https://unsplash.com/@dkoi?utm_source=medium&amp;utm_medium=referral\">D koi</a> on\u00a0<a href=\"https://unsplash.com/?utm_source=medium&amp;utm_medium=referral\">Unsplash</a></figcaption></figure><p><strong>Bounding volume hierarchy</strong> (<strong>BVH</strong>) is an advanced data structure widely used in computer graphics, especially in ray tracing algorithms. It is uesed to effectively organize geometric data, such as polygons or triangles that compose a 3D model, such as 3d-tiles. All geometric objects, which form the leaf nodes of the tree, are wrapped in bounding\u00a0volumes.</p>\n<p>In this article, we are going to explore how to construct bounding volume hierarchy (BVH) with Surface Area Heuristic(SAH).</p>\n<h3>\n<strong>Bounding Volume Hierarchy</strong> Data Structure</h3>\n<p>Bounding volume hierarchy (BVH) is a tree structure on a set of geometric objects.</p>\n<ul>\n<li>All geometric objects, which form the leaf nodes of the tree, are wrapped in bounding\u00a0volumes.</li>\n<li>These nodes are then grouped as small sets and enclosed within larger bounding volumes. These, in turn, are also grouped and enclosed within other larger bounding volumes in a recursive fashion, forming the hierarchy of the\u00a0tree.</li>\n<li>A bounding volume can take various forms, such as a sphere, a box (AABB\u200a\u2014\u200aAxis Aligned Bounding Box), or an oriented bounding box (OBB), depending on the application\u2019s specific requirements.</li>\n</ul>\n<p>Here is a example of a bounding volume hierarchy using rectangles as bounding volumes from <a href=\"https://en.wikipedia.org/\">wikipedia</a>.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/534/1*oFx736LEYo1tuK4gji3fCg.png\"></figure><h3>Surface Area Heuristic</h3>\n<p>A common method for constructing a high-quality BVH is using the Surface Area Heuristic. The idea of using SAH is based on two main principles:</p>\n<ol>\n<li>Minimize the probability of intersection for BHV\u00a0nodes</li>\n<li>The probability of intersection of a node is proportional to its surface area, under certain conditions.</li>\n</ol>\n<h4>SAH Formula</h4>\n<p>Here is the SAH\u00a0formula</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/505/0*9xrJTx8W-9owWJWh\"></figure><ul>\n<li><em>C(A, B)\u200a\u2014\u200athe cost for splitting a node into volumes A and\u00a0B</em></li>\n<li><em>t_traversal\u200a\u2014\u200athe time to traverse an interior\u00a0node</em></li>\n<li><em>P(A) and P(B)\u200a\u2014\u200athe probabilities that the ray passes through the volumes A and\u00a0B</em></li>\n<li><em>N_A and N_B\u200a\u2014\u200aare the number of triangles in volumes A and\u00a0B</em></li>\n<li><em>a_i and b_i\u200a\u2014\u200aare the ith triangle in volumes A and\u00a0B</em></li>\n<li><em>t_intersect - is the cost for one ray-triangle intersection.</em></li>\n</ul>\n<p>We can compute P(A) and P(B)\u00a0as:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/174/0*l1SaElXNgQ_y6jw_\"></figure><ul>\n<li><em>C\u200a\u2014\u200athe parent node of A and\u00a0B</em></li>\n<li><em>S_A, S_B, and S_C\u200a\u2014\u200athe surface areas of volumes A, B and C (We can simply compute the surface area of a node by summing all faces of a\u00a0node)</em></li>\n<li><em>P(A|C) and P(B|C)\u200a\u2014\u200athe conditional probability that a random ray passing through C will also pass through A or B, given that A or B is a convex volume in another convex volume\u00a0C.</em></li>\n</ul>\n<p>Replace P(A) and P(B) at the SAH formula, we\u00a0get:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/473/0*2I9CU-aGMMgXfAQX\"></figure><p>Since our goal is find the minimal cost, the actual cost value does not matter. Assume t_traversal as the constant 0, and t_intersect as the constant 1, we get a simplify form of SAH\u00a0formula\uff1a</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/234/0*7oJo7Vz07tPs3If-\"></figure><p>Here is the scripts to calculate SAH\u00a0cost:</p>\n<pre>def sah_cost(surface_area, count):<br>    return surface_area * count</pre>\n<h3>Constructing BVH with\u00a0SAH</h3>\n<h4>Preparing Data</h4>\n<p>we generates 10 triangles as testing data for construction BVH as followed\u00a0figure:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/552/1*qfKAzgmjDCCFpS7LvpadHQ.png\"></figure><p>Here is the generation scripts:</p>\n<pre>import numpy as np<br><br>np.random.seed(202403)<br><br>MIN_ANGLE = np.pi / 6<br>MAX_ANGLE = np.pi / 2<br><br>def make_triangle(max_length, max_translation):<br>    edge_a, edge_b = np.random.uniform(1, max_length, size = 2)<br>    alpha = np.random.uniform(0, np.pi * 2)<br>    beta = alpha + np.random.uniform(MIN_ANGLE, MAX_ANGLE)<br>    point_a = edge_a * np.cos(alpha), edge_a * np.sin(alpha)<br>    point_b = edge_b * np.cos(beta), edge_a * np.sin(beta)<br>    points = np.array([(0, 0), point_a, point_b])<br>    translation = np.random.uniform(max_length, max_translation, size=(1, 2))<br>    return points + translation<br><br>TRINGLES_NUM = 10<br>triangles = [make_triangle(3, 27) for _ in range(TRINGLES_NUM)]</pre>\n<h4>Bounding Volume\u200a\u2014\u200aAABB</h4>\n<p>We use AABB(Axis Aligned Bounding Box) to wrap geometries. An minimal AABB class must have below fields and\u00a0methods:</p>\n<p><strong>Fields:</strong></p>\n<ul>\n<li><em>centroid\u200a\u2014\u200aused to sort nodes before spliting nodes to two\u00a0groups</em></li>\n<li><em>surface_area\u200a\u2014\u200acalculated surface area, used to calculate SAH\u00a0cost</em></li>\n</ul>\n<p><strong>Methods:</strong></p>\n<ul><li><em>union\u200a\u2014\u200acalcualte the new bounding volume when merging\u00a0boxes</em></li></ul>\n<p>Here is the scripts for box\u00a0class:</p>\n<pre>class Box2:<br>    def __init__(self, min=[np.inf] * 2, max = [-np.inf] * 2) -&gt; None:<br>        self.__min = np.array(min)<br>        self.__max = np.array(max)<br><br>    @classmethod<br>    def from_geometries(cls, geometries):<br>        return cls(geometries.min(0), geometries.max(0))<br><br>    @property<br>    def anchor(self):<br>        return self.__min<br><br>    @property<br>    def size(self):<br>        return self.__max - self.__min<br><br>    @property<br>    def centroid(self):<br>        return ((self.__max + self.__min) / 2).tolist()<br><br>    @property<br>    def min(self):<br>        return self.__min<br><br>    @property<br>    def max(self):<br>        return self.__max<br><br>    def union(self, box):<br>        self.__max = np.maximum(self.__max, box.max)<br>        self.__min = np.minimum(self.__min, box.min)<br>        return self<br><br>    @property<br>    def surface_area(self):<br>        width, height = self.size<br>        return width * height</pre>\n<h4>BVH Node</h4>\n<p>A BVH node is tree node with geometries data and bounding volume. Here is the\u00a0scrpts:</p>\n<pre>class Node:<br>    def __init__(self, geometries = None) -&gt; None:<br>        self.geometries = geometries<br>        self.left = None<br>        self.right = None<br><br>    def add_children(self, left = None, right = None):<br>        self.left = left<br>        self.right = right<br><br>        return self<br><br>    @property    <br>    def box(self):<br>        if self.geometries is not None:<br>            return Box2.from_geometries(self.geometries)<br><br>        box = Box2()<br>        if self.left:<br>            box.union(self.left.box)<br><br>        if self.right:<br>            box.union(self.right.box)<br><br>        return box<br></pre>\n<h4>Splitting Nodes at Minimal Cost on One\u00a0Axis</h4>\n<p>We find the split with minimal cost in 3\u00a0steps:</p>\n<ol>\n<li><em>Sorts nodes by the controid of bounding\u00a0box</em></li>\n<li><em>Calculates SAH cost for every possible\u00a0split</em></li>\n<li><em>Finds the split with minimal\u00a0cost</em></li>\n</ol>\n<p>Here is the\u00a0scripts:</p>\n<pre>def calculate_split_costs(nodes):<br>    box = Box2()<br>    costs = []<br>    for i, node in enumerate(nodes, 1):<br>        box = box.union(node.box)<br>        costs.append(sah_cost(box.surface_area, i))<br><br>    return costs[:-1]<br><br>def find_min_cost_split(nodes, axis):    <br>    sorted_nodes = sorted(nodes, key=lambda node: node.box.centroid[axis])<br>    left_costs = calculate_split_costs(sorted_nodes)<br><br>    right_costs = reversed(calculate_split_costs(list(reversed(sorted_nodes))))<br>    costs = list(<br>        map(lambda l, r: l + r, left_costs, right_costs))<br>    min_cost = min(costs)<br>    split_index = np.argmin(costs) + 1<br>    return min_cost, split_index</pre>\n<h4>Building BVH\u00a0Tree</h4>\n<p>The last is actually build the tree. The building can be done in\u00a0steps:</p>\n<ol>\n<li><em>Return the node if there is only one node left; Return an interior with two nodes as children if there are two nodes\u00a0left</em></li>\n<li><em>Finds the axis and split index with minimal\u00a0cost</em></li>\n<li><em>Sorts the nodes by centroid of bounding box on the\u00a0axis</em></li>\n<li><em>Splits the nodes to two\u00a0group</em></li>\n<li><em>Repeats steps 1\u20134 recursively for both splited group until there are less then 3\u00a0nodes</em></li>\n</ol>\n<p>Let\u2019s show an animation of splitting process:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/640/1*B1uyiDUZoF2ubtXdrJuEDg.gif\"></figure><p>Here is the\u00a0scripts:</p>\n<pre>DIMENSIONS = 2<br><br>def build_bvh(nodes):<br>    if len(nodes) == 1:<br>        return nodes[0]<br><br>    if len(nodes) == 2:<br>        return Node().add_children(*nodes)<br><br>    min_costs_splits = [find_min_cost_split(nodes, axis) for axis in range(DIMENSIONS)]<br>    axis, _ = np.argmin(min_splits, 0, keepdims=False)<br>    _ , split_index = min_splits[axis]<br>    sorted_nodes = sorted(nodes, key=lambda node: node.box.centroid[axis])<br>    return Node().add_children(left = build_bvh(sorted_nodes[:split_index]), right = build_bvh(sorted_nodes[split_index:]))<br><br>nodes = list(map(Node, triangles))<br>tree = build_bvh(nodes)</pre>\n<h3>What About 3 Dimensions?</h3>\n<p>We\u2019ve covered building BVH for 2 dimensions. For 3 dimensions, we need only little changes for calculating the surface area. We create a class Box3 for\u00a0this.</p>\n<pre>class Box3(Box2):<br><br>    @property<br>    def surface_area(self):<br>        a, b, c = self.size<br>        return a * b + b * c + c * a</pre>\n<p>The last thing to do is update the constant DIMENSIONS to 3 and replace Box2 with\u00a0Box3.</p>\n<h3>Jason \ud83d\ude80</h3>\n<p><em>Thank you for reading until the end. Before you\u00a0go:</em></p>\n<p>\ud83d\udc4f Please <strong><em>Clap</em></strong> and <strong><em>follow</em></strong>\u00a0me</p>\n<p>\ud83d\udcec <a href=\"https://medium.com/@xuzhusheng/subscribe\">Subscribe</a> to my Medium newsletter for email\u00a0updates!</p>\n<p>\u2615 or just <a href=\"https://www.buymeacoffee.com/jason.xu\">buy me a\u00a0coffee</a></p>\n<h3>In Plain English\u00a0\ud83d\ude80</h3>\n<p><em>Thank you for being a part of the </em><a href=\"https://plainenglish.io/\"><strong><em>In Plain English</em></strong></a><em> community! Before you\u00a0go:</em></p>\n<ul>\n<li>Be sure to <strong>clap</strong> and <strong>follow</strong> the writer\u00a0\ufe0f\ud83d\udc4f<strong>\ufe0f\ufe0f</strong>\n</li>\n<li>Follow us: <a href=\"https://twitter.com/inPlainEngHQ\"><strong>X</strong></a><strong> | </strong><a href=\"https://www.linkedin.com/company/inplainenglish/\"><strong>LinkedIn</strong></a><strong> | </strong><a href=\"https://www.youtube.com/channel/UCtipWUghju290NWcn8jhyAw\"><strong>YouTube</strong></a><strong> | </strong><a href=\"https://discord.gg/in-plain-english-709094664682340443\"><strong>Discord</strong></a><strong> | </strong><a href=\"https://newsletter.plainenglish.io/\"><strong>Newsletter</strong></a>\n</li>\n<li>Visit our other platforms: <a href=\"https://stackademic.com/\"><strong>Stackademic</strong></a><strong> | </strong><a href=\"https://cofeed.app/\"><strong>CoFeed</strong></a><strong> | </strong><a href=\"https://venturemagazine.net/\"><strong>Venture</strong></a><strong> |\u00a0</strong><a href=\"https://blog.cubed.run/\"><strong>Cubed</strong></a>\n</li>\n<li>More content at <a href=\"https://plainenglish.io/\"><strong>PlainEnglish.io</strong></a>\n</li>\n</ul>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=89c14afb2f03\" width=\"1\" height=\"1\" alt=\"\"><hr>\n<p><a href=\"https://python.plainenglish.io/constructs-bounding-volume-hierarchy-bvh-with-surface-area-heuristic-sah-in-python-89c14afb2f03\">Constructs Bounding Volume Hierarchy(BVH) with Surface Area Heuristic(SAH) in Python</a> was originally published in <a href=\"https://python.plainenglish.io/\">Python in Plain English</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n",
            "content": "\n<h4>algorithm</h4>\n<h4>A step by step guide go build Bounding Volume Hierarchy(BVH) with Surface Area Heuristic(SAH) in\u00a0Python</h4>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*t76pREm7YKp9PbBg\"><figcaption>Photo by <a href=\"https://unsplash.com/@dkoi?utm_source=medium&amp;utm_medium=referral\">D koi</a> on\u00a0<a href=\"https://unsplash.com/?utm_source=medium&amp;utm_medium=referral\">Unsplash</a></figcaption></figure><p><strong>Bounding volume hierarchy</strong> (<strong>BVH</strong>) is an advanced data structure widely used in computer graphics, especially in ray tracing algorithms. It is uesed to effectively organize geometric data, such as polygons or triangles that compose a 3D model, such as 3d-tiles. All geometric objects, which form the leaf nodes of the tree, are wrapped in bounding\u00a0volumes.</p>\n<p>In this article, we are going to explore how to construct bounding volume hierarchy (BVH) with Surface Area Heuristic(SAH).</p>\n<h3>\n<strong>Bounding Volume Hierarchy</strong> Data Structure</h3>\n<p>Bounding volume hierarchy (BVH) is a tree structure on a set of geometric objects.</p>\n<ul>\n<li>All geometric objects, which form the leaf nodes of the tree, are wrapped in bounding\u00a0volumes.</li>\n<li>These nodes are then grouped as small sets and enclosed within larger bounding volumes. These, in turn, are also grouped and enclosed within other larger bounding volumes in a recursive fashion, forming the hierarchy of the\u00a0tree.</li>\n<li>A bounding volume can take various forms, such as a sphere, a box (AABB\u200a\u2014\u200aAxis Aligned Bounding Box), or an oriented bounding box (OBB), depending on the application\u2019s specific requirements.</li>\n</ul>\n<p>Here is a example of a bounding volume hierarchy using rectangles as bounding volumes from <a href=\"https://en.wikipedia.org/\">wikipedia</a>.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/534/1*oFx736LEYo1tuK4gji3fCg.png\"></figure><h3>Surface Area Heuristic</h3>\n<p>A common method for constructing a high-quality BVH is using the Surface Area Heuristic. The idea of using SAH is based on two main principles:</p>\n<ol>\n<li>Minimize the probability of intersection for BHV\u00a0nodes</li>\n<li>The probability of intersection of a node is proportional to its surface area, under certain conditions.</li>\n</ol>\n<h4>SAH Formula</h4>\n<p>Here is the SAH\u00a0formula</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/505/0*9xrJTx8W-9owWJWh\"></figure><ul>\n<li><em>C(A, B)\u200a\u2014\u200athe cost for splitting a node into volumes A and\u00a0B</em></li>\n<li><em>t_traversal\u200a\u2014\u200athe time to traverse an interior\u00a0node</em></li>\n<li><em>P(A) and P(B)\u200a\u2014\u200athe probabilities that the ray passes through the volumes A and\u00a0B</em></li>\n<li><em>N_A and N_B\u200a\u2014\u200aare the number of triangles in volumes A and\u00a0B</em></li>\n<li><em>a_i and b_i\u200a\u2014\u200aare the ith triangle in volumes A and\u00a0B</em></li>\n<li><em>t_intersect - is the cost for one ray-triangle intersection.</em></li>\n</ul>\n<p>We can compute P(A) and P(B)\u00a0as:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/174/0*l1SaElXNgQ_y6jw_\"></figure><ul>\n<li><em>C\u200a\u2014\u200athe parent node of A and\u00a0B</em></li>\n<li><em>S_A, S_B, and S_C\u200a\u2014\u200athe surface areas of volumes A, B and C (We can simply compute the surface area of a node by summing all faces of a\u00a0node)</em></li>\n<li><em>P(A|C) and P(B|C)\u200a\u2014\u200athe conditional probability that a random ray passing through C will also pass through A or B, given that A or B is a convex volume in another convex volume\u00a0C.</em></li>\n</ul>\n<p>Replace P(A) and P(B) at the SAH formula, we\u00a0get:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/473/0*2I9CU-aGMMgXfAQX\"></figure><p>Since our goal is find the minimal cost, the actual cost value does not matter. Assume t_traversal as the constant 0, and t_intersect as the constant 1, we get a simplify form of SAH\u00a0formula\uff1a</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/234/0*7oJo7Vz07tPs3If-\"></figure><p>Here is the scripts to calculate SAH\u00a0cost:</p>\n<pre>def sah_cost(surface_area, count):<br>    return surface_area * count</pre>\n<h3>Constructing BVH with\u00a0SAH</h3>\n<h4>Preparing Data</h4>\n<p>we generates 10 triangles as testing data for construction BVH as followed\u00a0figure:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/552/1*qfKAzgmjDCCFpS7LvpadHQ.png\"></figure><p>Here is the generation scripts:</p>\n<pre>import numpy as np<br><br>np.random.seed(202403)<br><br>MIN_ANGLE = np.pi / 6<br>MAX_ANGLE = np.pi / 2<br><br>def make_triangle(max_length, max_translation):<br>    edge_a, edge_b = np.random.uniform(1, max_length, size = 2)<br>    alpha = np.random.uniform(0, np.pi * 2)<br>    beta = alpha + np.random.uniform(MIN_ANGLE, MAX_ANGLE)<br>    point_a = edge_a * np.cos(alpha), edge_a * np.sin(alpha)<br>    point_b = edge_b * np.cos(beta), edge_a * np.sin(beta)<br>    points = np.array([(0, 0), point_a, point_b])<br>    translation = np.random.uniform(max_length, max_translation, size=(1, 2))<br>    return points + translation<br><br>TRINGLES_NUM = 10<br>triangles = [make_triangle(3, 27) for _ in range(TRINGLES_NUM)]</pre>\n<h4>Bounding Volume\u200a\u2014\u200aAABB</h4>\n<p>We use AABB(Axis Aligned Bounding Box) to wrap geometries. An minimal AABB class must have below fields and\u00a0methods:</p>\n<p><strong>Fields:</strong></p>\n<ul>\n<li><em>centroid\u200a\u2014\u200aused to sort nodes before spliting nodes to two\u00a0groups</em></li>\n<li><em>surface_area\u200a\u2014\u200acalculated surface area, used to calculate SAH\u00a0cost</em></li>\n</ul>\n<p><strong>Methods:</strong></p>\n<ul><li><em>union\u200a\u2014\u200acalcualte the new bounding volume when merging\u00a0boxes</em></li></ul>\n<p>Here is the scripts for box\u00a0class:</p>\n<pre>class Box2:<br>    def __init__(self, min=[np.inf] * 2, max = [-np.inf] * 2) -&gt; None:<br>        self.__min = np.array(min)<br>        self.__max = np.array(max)<br><br>    @classmethod<br>    def from_geometries(cls, geometries):<br>        return cls(geometries.min(0), geometries.max(0))<br><br>    @property<br>    def anchor(self):<br>        return self.__min<br><br>    @property<br>    def size(self):<br>        return self.__max - self.__min<br><br>    @property<br>    def centroid(self):<br>        return ((self.__max + self.__min) / 2).tolist()<br><br>    @property<br>    def min(self):<br>        return self.__min<br><br>    @property<br>    def max(self):<br>        return self.__max<br><br>    def union(self, box):<br>        self.__max = np.maximum(self.__max, box.max)<br>        self.__min = np.minimum(self.__min, box.min)<br>        return self<br><br>    @property<br>    def surface_area(self):<br>        width, height = self.size<br>        return width * height</pre>\n<h4>BVH Node</h4>\n<p>A BVH node is tree node with geometries data and bounding volume. Here is the\u00a0scrpts:</p>\n<pre>class Node:<br>    def __init__(self, geometries = None) -&gt; None:<br>        self.geometries = geometries<br>        self.left = None<br>        self.right = None<br><br>    def add_children(self, left = None, right = None):<br>        self.left = left<br>        self.right = right<br><br>        return self<br><br>    @property    <br>    def box(self):<br>        if self.geometries is not None:<br>            return Box2.from_geometries(self.geometries)<br><br>        box = Box2()<br>        if self.left:<br>            box.union(self.left.box)<br><br>        if self.right:<br>            box.union(self.right.box)<br><br>        return box<br></pre>\n<h4>Splitting Nodes at Minimal Cost on One\u00a0Axis</h4>\n<p>We find the split with minimal cost in 3\u00a0steps:</p>\n<ol>\n<li><em>Sorts nodes by the controid of bounding\u00a0box</em></li>\n<li><em>Calculates SAH cost for every possible\u00a0split</em></li>\n<li><em>Finds the split with minimal\u00a0cost</em></li>\n</ol>\n<p>Here is the\u00a0scripts:</p>\n<pre>def calculate_split_costs(nodes):<br>    box = Box2()<br>    costs = []<br>    for i, node in enumerate(nodes, 1):<br>        box = box.union(node.box)<br>        costs.append(sah_cost(box.surface_area, i))<br><br>    return costs[:-1]<br><br>def find_min_cost_split(nodes, axis):    <br>    sorted_nodes = sorted(nodes, key=lambda node: node.box.centroid[axis])<br>    left_costs = calculate_split_costs(sorted_nodes)<br><br>    right_costs = reversed(calculate_split_costs(list(reversed(sorted_nodes))))<br>    costs = list(<br>        map(lambda l, r: l + r, left_costs, right_costs))<br>    min_cost = min(costs)<br>    split_index = np.argmin(costs) + 1<br>    return min_cost, split_index</pre>\n<h4>Building BVH\u00a0Tree</h4>\n<p>The last is actually build the tree. The building can be done in\u00a0steps:</p>\n<ol>\n<li><em>Return the node if there is only one node left; Return an interior with two nodes as children if there are two nodes\u00a0left</em></li>\n<li><em>Finds the axis and split index with minimal\u00a0cost</em></li>\n<li><em>Sorts the nodes by centroid of bounding box on the\u00a0axis</em></li>\n<li><em>Splits the nodes to two\u00a0group</em></li>\n<li><em>Repeats steps 1\u20134 recursively for both splited group until there are less then 3\u00a0nodes</em></li>\n</ol>\n<p>Let\u2019s show an animation of splitting process:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/640/1*B1uyiDUZoF2ubtXdrJuEDg.gif\"></figure><p>Here is the\u00a0scripts:</p>\n<pre>DIMENSIONS = 2<br><br>def build_bvh(nodes):<br>    if len(nodes) == 1:<br>        return nodes[0]<br><br>    if len(nodes) == 2:<br>        return Node().add_children(*nodes)<br><br>    min_costs_splits = [find_min_cost_split(nodes, axis) for axis in range(DIMENSIONS)]<br>    axis, _ = np.argmin(min_splits, 0, keepdims=False)<br>    _ , split_index = min_splits[axis]<br>    sorted_nodes = sorted(nodes, key=lambda node: node.box.centroid[axis])<br>    return Node().add_children(left = build_bvh(sorted_nodes[:split_index]), right = build_bvh(sorted_nodes[split_index:]))<br><br>nodes = list(map(Node, triangles))<br>tree = build_bvh(nodes)</pre>\n<h3>What About 3 Dimensions?</h3>\n<p>We\u2019ve covered building BVH for 2 dimensions. For 3 dimensions, we need only little changes for calculating the surface area. We create a class Box3 for\u00a0this.</p>\n<pre>class Box3(Box2):<br><br>    @property<br>    def surface_area(self):<br>        a, b, c = self.size<br>        return a * b + b * c + c * a</pre>\n<p>The last thing to do is update the constant DIMENSIONS to 3 and replace Box2 with\u00a0Box3.</p>\n<h3>Jason \ud83d\ude80</h3>\n<p><em>Thank you for reading until the end. Before you\u00a0go:</em></p>\n<p>\ud83d\udc4f Please <strong><em>Clap</em></strong> and <strong><em>follow</em></strong>\u00a0me</p>\n<p>\ud83d\udcec <a href=\"https://medium.com/@xuzhusheng/subscribe\">Subscribe</a> to my Medium newsletter for email\u00a0updates!</p>\n<p>\u2615 or just <a href=\"https://www.buymeacoffee.com/jason.xu\">buy me a\u00a0coffee</a></p>\n<h3>In Plain English\u00a0\ud83d\ude80</h3>\n<p><em>Thank you for being a part of the </em><a href=\"https://plainenglish.io/\"><strong><em>In Plain English</em></strong></a><em> community! Before you\u00a0go:</em></p>\n<ul>\n<li>Be sure to <strong>clap</strong> and <strong>follow</strong> the writer\u00a0\ufe0f\ud83d\udc4f<strong>\ufe0f\ufe0f</strong>\n</li>\n<li>Follow us: <a href=\"https://twitter.com/inPlainEngHQ\"><strong>X</strong></a><strong> | </strong><a href=\"https://www.linkedin.com/company/inplainenglish/\"><strong>LinkedIn</strong></a><strong> | </strong><a href=\"https://www.youtube.com/channel/UCtipWUghju290NWcn8jhyAw\"><strong>YouTube</strong></a><strong> | </strong><a href=\"https://discord.gg/in-plain-english-709094664682340443\"><strong>Discord</strong></a><strong> | </strong><a href=\"https://newsletter.plainenglish.io/\"><strong>Newsletter</strong></a>\n</li>\n<li>Visit our other platforms: <a href=\"https://stackademic.com/\"><strong>Stackademic</strong></a><strong> | </strong><a href=\"https://cofeed.app/\"><strong>CoFeed</strong></a><strong> | </strong><a href=\"https://venturemagazine.net/\"><strong>Venture</strong></a><strong> |\u00a0</strong><a href=\"https://blog.cubed.run/\"><strong>Cubed</strong></a>\n</li>\n<li>More content at <a href=\"https://plainenglish.io/\"><strong>PlainEnglish.io</strong></a>\n</li>\n</ul>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=89c14afb2f03\" width=\"1\" height=\"1\" alt=\"\"><hr>\n<p><a href=\"https://python.plainenglish.io/constructs-bounding-volume-hierarchy-bvh-with-surface-area-heuristic-sah-in-python-89c14afb2f03\">Constructs Bounding Volume Hierarchy(BVH) with Surface Area Heuristic(SAH) in Python</a> was originally published in <a href=\"https://python.plainenglish.io/\">Python in Plain English</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n",
            "enclosure": {},
            "categories": [
                "python",
                "computer-graphics",
                "3d",
                "numpy",
                "algorithms"
            ]
        },
        {
            "title": "3D Affine Transformation Matrices Implementation with NumPy",
            "pubDate": "2024-03-04 04:01:07",
            "link": "https://python.plainenglish.io/3d-affine-transformation-matrices-implementation-with-numpy-57f92058403c?source=rss-41bd992616fb------2",
            "guid": "https://medium.com/p/57f92058403c",
            "author": "Jason",
            "thumbnail": "",
            "description": "\n<h4>3D Affine Transformation</h4>\n<h4>Explores 3D affine transformation matrices and implements it with\u00a0NumPy</h4>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*YhbgLSfLA9RgoDNE\"><figcaption>Photo by <a href=\"https://unsplash.com/@mariolagr?utm_source=medium&amp;utm_medium=referral\">MARIOLA GROBELSKA</a> on\u00a0<a href=\"https://unsplash.com/?utm_source=medium&amp;utm_medium=referral\">Unsplash</a></figcaption></figure><p>In computer graphics, af\ufb01ne transformation is the most general transformations model. Any combination of translation, rotations, scalings/re\ufb02ections and shears can be combined in a single 4 by 4 af\ufb01ne transformation matrix.</p>\n<p>In this article, we are going to explore common 3d affine transformation matrices and implement it with\u00a0NumPy.</p>\n<h3><strong>3D Affine Transformation Matrices</strong></h3>\n<p>Here is a af\ufb01ne transformation matrix that transforms point (or vector) x to point (or vector)\u00a0y.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/217/0*RcVfjT1NLncBvUDl\"></figure><p>The upper-left 3 \u00d7 3 sub-matrix of the matrix represents a rotation transform (include scales and shears). The last column of the matrix represents a translation. When used as a coordinate system, the upper-left 3 x 3 sub-matrix represents an orientation in space while the last column vector represents a position in space. The transformation of point x to point y is obtained by performing the matrix-vector multiplication Mx:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/61/0*BOHJ7Z2VcigfKx9I\"></figure><p>The transformation matrix uses homogeneous coordinates, which allow to distinguish between points and vectors. Vectors have a direction and magnitude whereas points are positions. Points and vectors are both represented as mathematical column vectors in homogeneous coordinates. The only difference is points have a 1 in the fourth position whereas vectors have a zero at this position, which removes translation operations (4th column) for\u00a0vectors.</p>\n<p>The transformation of point x to point y using homogeneous matrix is written\u00a0as:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/112/0*5GRNCeZyUUCvgjum\"></figure><p><strong>Implements matrix with\u00a0NumPy</strong></p>\n<p>Matrix is easy to be Implemented with NumPy. Let\u2019s see how to construct a matrix with\u00a0NumPy:</p>\n<pre>import numpy as np<br><br>elements = [<br>    [1,2,3,4],<br>    [4,6,7,8],<br>    [9,10,11,12],<br>    [13,14,15,16]<br>]<br>matrix = np.array(elements)<br>print(matrix)<br># [[ 1  2  3  4]<br>#  [ 4  6  7  8]<br>#  [ 9 10 11 12]<br>#  [13 14 15 16]]</pre>\n<p>Since affine transformation matrix is used to represent object\u2019s rotaion and translation in 3D models, serialization and deserialization is common scenario. Here is code snippets for constructing matrix from list and converting it to a\u00a0list:</p>\n<pre>import numpy as np<br><br># constructs from list<br>elements = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]<br>matrix = np.array(elements)<br>matrix = matrix.reshape(4,4)<br>print(matrix)<br># [[ 1  2  3  4]<br>#  [ 5  6  7  8]<br>#  [ 9 10 11 12]<br>#  [13 14 15 16]]<br><br># converts to list<br>print(matrix.reshape(-1).tolist())<br># [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]</pre>\n<h3>Translation</h3>\n<p>A translation operation will translate a point(or an object) from an initial position to a new position based on a linear shift. Here equation of translate a point (x, y, z) to point (x', y',\u00a0z')</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/83/0*v6bX_KcpXD19QEsW\"></figure><p>And the transformation matrix\u00a0form:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/297/0*9vAyfWIAClT_y9yn\"></figure><p><strong>Implements translation matrix with\u00a0NumPy</strong></p>\n<pre>def translation_matrix(tx, ty, tz):<br>    matrix = [<br>        [1,0,0,tx],<br>        [0,1,0,ty],<br>        [0,0,1,tz],<br>        [0,0,0,1]<br>    ]<br>    return np.array(matrix)<br><br>np.random.seed(202403)<br><br>tx, ty, tz = np.random.randint(10, size=3)<br>print(tx, ty, tz)   #5 5 2<br><br>matrix = translation_matrix(tx, ty, tz)<br>print(matrix)<br># [[1 0 0 5]<br>#  [0 1 0 5]<br>#  [0 0 1 2]<br>#  [0 0 0 1]]<br><br># translates a point x, y, z<br>x, y, z = np.random.randint(10, size = 3)<br>print(x, y, z)  #3 6 8<br>translated_point = matrix @ [x,y,z,1]<br>print(translated_point[:3]) #[ 8 11 10]<br><br>#decompose translation from translation_matrix<br>tx, ty, tz = matrix[:3,3]<br>print(tx, ty, tz)   #5 5 2</pre>\n<h3>Scaling</h3>\n<p>A scale operation will shift a point(or an object) from an initial position to a new position based on a scaling. Here is the equation of scaling\u00a0point:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/63/0*-fXUxB6sHg76_ye3\"></figure><p>And the transformation matrix\u00a0form:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/293/0*LGM6KAFwo6l-9a3Z\"></figure><p><strong>Implements scaling matrix with\u00a0NumPy</strong></p>\n<pre>def scaling_matrix(sx, sy, sz):<br>    matrix = [<br>        [sx,0,0,0],<br>        [0,sy,0,0],<br>        [0,0,sz,0],<br>        [0,0,0,1]<br>    ]<br><br>    return np.array(matrix)<br><br>np.random.seed(202403)<br><br>sx, sy, sz = np.random.rand(3)<br>print(sx, sy, sz)   #0.5243255319030659 0.4804928539608385 0.07838680854264224<br><br>matrix = scaling_matrix(sx, sy, sz)<br>print(matrix)<br># [[0.52432553 0.         0.         0.        ]<br>#  [0.         0.48049285 0.         0.        ]<br>#  [0.         0.         0.07838681 0.        ]<br>#  [0.         0.         0.         1.        ]]<br><br># scales a point x, y, z<br>x, y, z = np.random.randint(10, size = 3)<br>print(x, y, z)  #6 8 8<br>scaled_point = matrix @ [x,y,z,1]<br>print(scaled_point[:3]) #[3.14595319 3.84394283 0.62709447]</pre>\n<h3>Rotation</h3>\n<p>A rotation operation will shift a point(or an object) from an initial position to a new position based on a rotation about a given axis or any arbitrary vector.</p>\n<p>The rotation matrix is more complex than the scaling and translation matrix since the whole 3x3 upper-left matrix is needed to express complex rotations. It is common to specify arbitrary rotations with a sequence of simpler ones each along one of the three axes. In each case, the rotation is through an angle, about the given axis. Let\u2019s explore rotation matrix around single axis one by one. Notice that the signs of rotation angles are defined using a right-hand rule convention in the following sections.</p>\n<h4><strong>Rotation around the\u00a0x-axis</strong></h4>\n<p>Here is the matrix for rotating a point through the angle alpha around the\u00a0x-axis</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/242/0*f7mNutLhtBwhaV-5\"></figure><p><strong>Implements x-axis rotation matrix with\u00a0NumPy</strong></p>\n<pre>def rotation_matrix_x(alpha_degree):<br>    alpha_radian = np.deg2rad(alpha_degree)<br><br>    rotation_alpha = [<br>        [1, 0, 0, 0],<br>        [0, np.cos(alpha_radian), -np.sin(alpha_radian), 0],<br>        [0, np.sin(alpha_radian), np.cos(alpha_radian), 0],<br>        [0, 0, 0, 1]<br>    ]<br><br>    return np.array(rotation_alpha)<br><br>rotated_point = rotation_matrix_x(90) @ [0, 1, 0, 1]<br>print(rotated_point[:3])    #[0.000000e+00 6.123234e-17 1.000000e+00]</pre>\n<h4><strong>Rotation around the\u00a0y-axis</strong></h4>\n<p>Here is the matrix for rotating a point through the angle beta around the\u00a0y-axis</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/240/0*S-iwiCWThje9iEH7\"></figure><p><strong>Implements y-axis rotation matrix with\u00a0NumPy</strong></p>\n<pre>def rotation_matrix_y(beta_degree):<br>    beta_radian = np.deg2rad(beta_degree)<br><br>    rotation_beta = [<br>        [np.cos(beta_radian), 0, np.sin(beta_radian), 0],<br>        [0, 1, 0, 0],<br>        [-np.sin(beta_radian), 0, np.cos(beta_radian), 0],<br>        [0, 0, 0, 1]<br>    ]<br><br>    return np.array(rotation_beta)<br><br>rotated_point = rotation_matrix_y(90) @ [1, 0, 0, 1]<br>print(rotated_point[:3])    #[ 6.123234e-17  0.000000e+00 -1.000000e+00]</pre>\n<h4><strong>Rotation around the\u00a0z-axis</strong></h4>\n<p>Here is the matrix for rotating a point through the angle gamma around the\u00a0z-axis</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/238/0*kYV9Lk6bofzHe5FW\"></figure><p><strong>Implements z-axis rotation matrix with\u00a0NumPy</strong></p>\n<pre>def rotation_matrix_z(gamma_degree):<br>    gamma_radian = np.deg2rad(gamma_degree)<br><br>    rotation_gamma = [<br>        [np.cos(gamma_radian), -np.sin(gamma_radian), 0, 0],<br>        [np.sin(gamma_radian), np.cos(gamma_radian), 0, 0],<br>        [0, 0, 1, 0],<br>        [0, 0, 0, 1]<br>    ]<br><br>    return np.array(rotation_gamma)<br><br>rotated_point = rotation_matrix_z(90) @ [1, 0, 0, 1]<br>print(rotated_point[:3])    #[6.123234e-17 1.000000e+00 0.000000e+00]</pre>\n<h4>General rotation</h4>\n<p>General rotation matrix around 3 axes can be composed by concatenating matrices around each axis using matrix multiplication. Here is a general rotation\u00a0matrix:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/690/0*506QFJ0Nj_SowMTp\"></figure><p><strong>Compose general rotaton matrix with\u00a0NumPy</strong></p>\n<pre>def rotation_matrix(alpha, beta, gamma):<br>    return rotation_matrix_x(alpha) @ rotation_matrix_y(beta) @ rotation_matrix_z(gamma)<br><br>np.random.seed(202403)<br><br>alpha, beta, gamma = np.random.randint(0, 360, size = 3)<br>print(alpha, beta, gamma)   #165 77 117<br><br>x, y, z = np.random.randint(10, size = 3)<br>print(x, y, z)  #2 3 6<br>rotated_point = rotation_matrix(alpha, beta, gamma) @ [x,y,z,1]<br><br>print(rotated_point[:3]) #[ 5.04067053 -1.65813521 -4.56532892]</pre>\n<h3>Jason \ud83d\ude80</h3>\n<p><em>Thank you for reading until the end. Before you\u00a0go:</em></p>\n<p>\ud83d\udc4f Please <strong><em>Clap</em></strong> and <strong><em>follow</em></strong>\u00a0me</p>\n<p>\ud83d\udcec <a href=\"https://medium.com/@xuzhusheng/subscribe\">Subscribe</a> to my Medium newsletter for email\u00a0updates!</p>\n<p>\u2615 or just <a href=\"https://www.buymeacoffee.com/jason.xu\">buy me a\u00a0coffee</a></p>\n<h3>In Plain English\u00a0\ud83d\ude80</h3>\n<p><em>Thank you for being a part of the </em><a href=\"https://plainenglish.io/\"><strong><em>In Plain English</em></strong></a><em> community! Before you\u00a0go:</em></p>\n<ul>\n<li>Be sure to <strong>clap</strong> and <strong>follow</strong> the writer\u00a0\ufe0f\ud83d\udc4f<strong>\ufe0f\ufe0f</strong>\n</li>\n<li>Follow us: <a href=\"https://twitter.com/inPlainEngHQ\"><strong>X</strong></a><strong> | </strong><a href=\"https://www.linkedin.com/company/inplainenglish/\"><strong>LinkedIn</strong></a><strong> | </strong><a href=\"https://www.youtube.com/channel/UCtipWUghju290NWcn8jhyAw\"><strong>YouTube</strong></a><strong> | </strong><a href=\"https://discord.gg/in-plain-english-709094664682340443\"><strong>Discord</strong></a><strong> | </strong><a href=\"https://newsletter.plainenglish.io/\"><strong>Newsletter</strong></a>\n</li>\n<li>Visit our other platforms: <a href=\"https://stackademic.com/\"><strong>Stackademic</strong></a><strong> | </strong><a href=\"https://cofeed.app/\"><strong>CoFeed</strong></a><strong> | </strong><a href=\"https://venturemagazine.net/\"><strong>Venture</strong></a><strong> |\u00a0</strong><a href=\"https://blog.cubed.run/\"><strong>Cubed</strong></a>\n</li>\n<li>More content at <a href=\"https://plainenglish.io/\"><strong>PlainEnglish.io</strong></a>\n</li>\n</ul>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=57f92058403c\" width=\"1\" height=\"1\" alt=\"\"><hr>\n<p><a href=\"https://python.plainenglish.io/3d-affine-transformation-matrices-implementation-with-numpy-57f92058403c\">3D Affine Transformation Matrices Implementation with NumPy</a> was originally published in <a href=\"https://python.plainenglish.io/\">Python in Plain English</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n",
            "content": "\n<h4>3D Affine Transformation</h4>\n<h4>Explores 3D affine transformation matrices and implements it with\u00a0NumPy</h4>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*YhbgLSfLA9RgoDNE\"><figcaption>Photo by <a href=\"https://unsplash.com/@mariolagr?utm_source=medium&amp;utm_medium=referral\">MARIOLA GROBELSKA</a> on\u00a0<a href=\"https://unsplash.com/?utm_source=medium&amp;utm_medium=referral\">Unsplash</a></figcaption></figure><p>In computer graphics, af\ufb01ne transformation is the most general transformations model. Any combination of translation, rotations, scalings/re\ufb02ections and shears can be combined in a single 4 by 4 af\ufb01ne transformation matrix.</p>\n<p>In this article, we are going to explore common 3d affine transformation matrices and implement it with\u00a0NumPy.</p>\n<h3><strong>3D Affine Transformation Matrices</strong></h3>\n<p>Here is a af\ufb01ne transformation matrix that transforms point (or vector) x to point (or vector)\u00a0y.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/217/0*RcVfjT1NLncBvUDl\"></figure><p>The upper-left 3 \u00d7 3 sub-matrix of the matrix represents a rotation transform (include scales and shears). The last column of the matrix represents a translation. When used as a coordinate system, the upper-left 3 x 3 sub-matrix represents an orientation in space while the last column vector represents a position in space. The transformation of point x to point y is obtained by performing the matrix-vector multiplication Mx:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/61/0*BOHJ7Z2VcigfKx9I\"></figure><p>The transformation matrix uses homogeneous coordinates, which allow to distinguish between points and vectors. Vectors have a direction and magnitude whereas points are positions. Points and vectors are both represented as mathematical column vectors in homogeneous coordinates. The only difference is points have a 1 in the fourth position whereas vectors have a zero at this position, which removes translation operations (4th column) for\u00a0vectors.</p>\n<p>The transformation of point x to point y using homogeneous matrix is written\u00a0as:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/112/0*5GRNCeZyUUCvgjum\"></figure><p><strong>Implements matrix with\u00a0NumPy</strong></p>\n<p>Matrix is easy to be Implemented with NumPy. Let\u2019s see how to construct a matrix with\u00a0NumPy:</p>\n<pre>import numpy as np<br><br>elements = [<br>    [1,2,3,4],<br>    [4,6,7,8],<br>    [9,10,11,12],<br>    [13,14,15,16]<br>]<br>matrix = np.array(elements)<br>print(matrix)<br># [[ 1  2  3  4]<br>#  [ 4  6  7  8]<br>#  [ 9 10 11 12]<br>#  [13 14 15 16]]</pre>\n<p>Since affine transformation matrix is used to represent object\u2019s rotaion and translation in 3D models, serialization and deserialization is common scenario. Here is code snippets for constructing matrix from list and converting it to a\u00a0list:</p>\n<pre>import numpy as np<br><br># constructs from list<br>elements = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]<br>matrix = np.array(elements)<br>matrix = matrix.reshape(4,4)<br>print(matrix)<br># [[ 1  2  3  4]<br>#  [ 5  6  7  8]<br>#  [ 9 10 11 12]<br>#  [13 14 15 16]]<br><br># converts to list<br>print(matrix.reshape(-1).tolist())<br># [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]</pre>\n<h3>Translation</h3>\n<p>A translation operation will translate a point(or an object) from an initial position to a new position based on a linear shift. Here equation of translate a point (x, y, z) to point (x', y',\u00a0z')</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/83/0*v6bX_KcpXD19QEsW\"></figure><p>And the transformation matrix\u00a0form:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/297/0*9vAyfWIAClT_y9yn\"></figure><p><strong>Implements translation matrix with\u00a0NumPy</strong></p>\n<pre>def translation_matrix(tx, ty, tz):<br>    matrix = [<br>        [1,0,0,tx],<br>        [0,1,0,ty],<br>        [0,0,1,tz],<br>        [0,0,0,1]<br>    ]<br>    return np.array(matrix)<br><br>np.random.seed(202403)<br><br>tx, ty, tz = np.random.randint(10, size=3)<br>print(tx, ty, tz)   #5 5 2<br><br>matrix = translation_matrix(tx, ty, tz)<br>print(matrix)<br># [[1 0 0 5]<br>#  [0 1 0 5]<br>#  [0 0 1 2]<br>#  [0 0 0 1]]<br><br># translates a point x, y, z<br>x, y, z = np.random.randint(10, size = 3)<br>print(x, y, z)  #3 6 8<br>translated_point = matrix @ [x,y,z,1]<br>print(translated_point[:3]) #[ 8 11 10]<br><br>#decompose translation from translation_matrix<br>tx, ty, tz = matrix[:3,3]<br>print(tx, ty, tz)   #5 5 2</pre>\n<h3>Scaling</h3>\n<p>A scale operation will shift a point(or an object) from an initial position to a new position based on a scaling. Here is the equation of scaling\u00a0point:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/63/0*-fXUxB6sHg76_ye3\"></figure><p>And the transformation matrix\u00a0form:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/293/0*LGM6KAFwo6l-9a3Z\"></figure><p><strong>Implements scaling matrix with\u00a0NumPy</strong></p>\n<pre>def scaling_matrix(sx, sy, sz):<br>    matrix = [<br>        [sx,0,0,0],<br>        [0,sy,0,0],<br>        [0,0,sz,0],<br>        [0,0,0,1]<br>    ]<br><br>    return np.array(matrix)<br><br>np.random.seed(202403)<br><br>sx, sy, sz = np.random.rand(3)<br>print(sx, sy, sz)   #0.5243255319030659 0.4804928539608385 0.07838680854264224<br><br>matrix = scaling_matrix(sx, sy, sz)<br>print(matrix)<br># [[0.52432553 0.         0.         0.        ]<br>#  [0.         0.48049285 0.         0.        ]<br>#  [0.         0.         0.07838681 0.        ]<br>#  [0.         0.         0.         1.        ]]<br><br># scales a point x, y, z<br>x, y, z = np.random.randint(10, size = 3)<br>print(x, y, z)  #6 8 8<br>scaled_point = matrix @ [x,y,z,1]<br>print(scaled_point[:3]) #[3.14595319 3.84394283 0.62709447]</pre>\n<h3>Rotation</h3>\n<p>A rotation operation will shift a point(or an object) from an initial position to a new position based on a rotation about a given axis or any arbitrary vector.</p>\n<p>The rotation matrix is more complex than the scaling and translation matrix since the whole 3x3 upper-left matrix is needed to express complex rotations. It is common to specify arbitrary rotations with a sequence of simpler ones each along one of the three axes. In each case, the rotation is through an angle, about the given axis. Let\u2019s explore rotation matrix around single axis one by one. Notice that the signs of rotation angles are defined using a right-hand rule convention in the following sections.</p>\n<h4><strong>Rotation around the\u00a0x-axis</strong></h4>\n<p>Here is the matrix for rotating a point through the angle alpha around the\u00a0x-axis</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/242/0*f7mNutLhtBwhaV-5\"></figure><p><strong>Implements x-axis rotation matrix with\u00a0NumPy</strong></p>\n<pre>def rotation_matrix_x(alpha_degree):<br>    alpha_radian = np.deg2rad(alpha_degree)<br><br>    rotation_alpha = [<br>        [1, 0, 0, 0],<br>        [0, np.cos(alpha_radian), -np.sin(alpha_radian), 0],<br>        [0, np.sin(alpha_radian), np.cos(alpha_radian), 0],<br>        [0, 0, 0, 1]<br>    ]<br><br>    return np.array(rotation_alpha)<br><br>rotated_point = rotation_matrix_x(90) @ [0, 1, 0, 1]<br>print(rotated_point[:3])    #[0.000000e+00 6.123234e-17 1.000000e+00]</pre>\n<h4><strong>Rotation around the\u00a0y-axis</strong></h4>\n<p>Here is the matrix for rotating a point through the angle beta around the\u00a0y-axis</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/240/0*S-iwiCWThje9iEH7\"></figure><p><strong>Implements y-axis rotation matrix with\u00a0NumPy</strong></p>\n<pre>def rotation_matrix_y(beta_degree):<br>    beta_radian = np.deg2rad(beta_degree)<br><br>    rotation_beta = [<br>        [np.cos(beta_radian), 0, np.sin(beta_radian), 0],<br>        [0, 1, 0, 0],<br>        [-np.sin(beta_radian), 0, np.cos(beta_radian), 0],<br>        [0, 0, 0, 1]<br>    ]<br><br>    return np.array(rotation_beta)<br><br>rotated_point = rotation_matrix_y(90) @ [1, 0, 0, 1]<br>print(rotated_point[:3])    #[ 6.123234e-17  0.000000e+00 -1.000000e+00]</pre>\n<h4><strong>Rotation around the\u00a0z-axis</strong></h4>\n<p>Here is the matrix for rotating a point through the angle gamma around the\u00a0z-axis</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/238/0*kYV9Lk6bofzHe5FW\"></figure><p><strong>Implements z-axis rotation matrix with\u00a0NumPy</strong></p>\n<pre>def rotation_matrix_z(gamma_degree):<br>    gamma_radian = np.deg2rad(gamma_degree)<br><br>    rotation_gamma = [<br>        [np.cos(gamma_radian), -np.sin(gamma_radian), 0, 0],<br>        [np.sin(gamma_radian), np.cos(gamma_radian), 0, 0],<br>        [0, 0, 1, 0],<br>        [0, 0, 0, 1]<br>    ]<br><br>    return np.array(rotation_gamma)<br><br>rotated_point = rotation_matrix_z(90) @ [1, 0, 0, 1]<br>print(rotated_point[:3])    #[6.123234e-17 1.000000e+00 0.000000e+00]</pre>\n<h4>General rotation</h4>\n<p>General rotation matrix around 3 axes can be composed by concatenating matrices around each axis using matrix multiplication. Here is a general rotation\u00a0matrix:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/690/0*506QFJ0Nj_SowMTp\"></figure><p><strong>Compose general rotaton matrix with\u00a0NumPy</strong></p>\n<pre>def rotation_matrix(alpha, beta, gamma):<br>    return rotation_matrix_x(alpha) @ rotation_matrix_y(beta) @ rotation_matrix_z(gamma)<br><br>np.random.seed(202403)<br><br>alpha, beta, gamma = np.random.randint(0, 360, size = 3)<br>print(alpha, beta, gamma)   #165 77 117<br><br>x, y, z = np.random.randint(10, size = 3)<br>print(x, y, z)  #2 3 6<br>rotated_point = rotation_matrix(alpha, beta, gamma) @ [x,y,z,1]<br><br>print(rotated_point[:3]) #[ 5.04067053 -1.65813521 -4.56532892]</pre>\n<h3>Jason \ud83d\ude80</h3>\n<p><em>Thank you for reading until the end. Before you\u00a0go:</em></p>\n<p>\ud83d\udc4f Please <strong><em>Clap</em></strong> and <strong><em>follow</em></strong>\u00a0me</p>\n<p>\ud83d\udcec <a href=\"https://medium.com/@xuzhusheng/subscribe\">Subscribe</a> to my Medium newsletter for email\u00a0updates!</p>\n<p>\u2615 or just <a href=\"https://www.buymeacoffee.com/jason.xu\">buy me a\u00a0coffee</a></p>\n<h3>In Plain English\u00a0\ud83d\ude80</h3>\n<p><em>Thank you for being a part of the </em><a href=\"https://plainenglish.io/\"><strong><em>In Plain English</em></strong></a><em> community! Before you\u00a0go:</em></p>\n<ul>\n<li>Be sure to <strong>clap</strong> and <strong>follow</strong> the writer\u00a0\ufe0f\ud83d\udc4f<strong>\ufe0f\ufe0f</strong>\n</li>\n<li>Follow us: <a href=\"https://twitter.com/inPlainEngHQ\"><strong>X</strong></a><strong> | </strong><a href=\"https://www.linkedin.com/company/inplainenglish/\"><strong>LinkedIn</strong></a><strong> | </strong><a href=\"https://www.youtube.com/channel/UCtipWUghju290NWcn8jhyAw\"><strong>YouTube</strong></a><strong> | </strong><a href=\"https://discord.gg/in-plain-english-709094664682340443\"><strong>Discord</strong></a><strong> | </strong><a href=\"https://newsletter.plainenglish.io/\"><strong>Newsletter</strong></a>\n</li>\n<li>Visit our other platforms: <a href=\"https://stackademic.com/\"><strong>Stackademic</strong></a><strong> | </strong><a href=\"https://cofeed.app/\"><strong>CoFeed</strong></a><strong> | </strong><a href=\"https://venturemagazine.net/\"><strong>Venture</strong></a><strong> |\u00a0</strong><a href=\"https://blog.cubed.run/\"><strong>Cubed</strong></a>\n</li>\n<li>More content at <a href=\"https://plainenglish.io/\"><strong>PlainEnglish.io</strong></a>\n</li>\n</ul>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=57f92058403c\" width=\"1\" height=\"1\" alt=\"\"><hr>\n<p><a href=\"https://python.plainenglish.io/3d-affine-transformation-matrices-implementation-with-numpy-57f92058403c\">3D Affine Transformation Matrices Implementation with NumPy</a> was originally published in <a href=\"https://python.plainenglish.io/\">Python in Plain English</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n",
            "enclosure": {},
            "categories": [
                "computer-graphics",
                "3d",
                "mathematics",
                "numpy",
                "python"
            ]
        },
        {
            "title": "Manipulate JSON with Python Dynamic Object",
            "pubDate": "2024-02-14 02:12:37",
            "link": "https://python.plainenglish.io/manipulate-json-with-python-dynamic-object-fe885394d17f?source=rss-41bd992616fb------2",
            "guid": "https://medium.com/p/fe885394d17f",
            "author": "Jason",
            "thumbnail": "",
            "description": "\n<h4>Code Snippets</h4>\n<h4>Avoid code duplication with python dynamic\u00a0object</h4>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*tmSiQ9rxkxOG1cJX\"><figcaption>Photo by <a href=\"https://unsplash.com/@hiteshchoudhary?utm_source=medium&amp;utm_medium=referral\">Hitesh Choudhary</a> on\u00a0<a href=\"https://unsplash.com/?utm_source=medium&amp;utm_medium=referral\">Unsplash</a></figcaption></figure><p>JSON (JavaScript Object Notation) is a lightweight, text-based data format used for storing and exchanging data. It\u2019s a simple and flexible way of representing data that can be easily understood and parsed by both humans and machines. JSON has become one of the most popular in standard.</p>\n<p>Python provides variou tools for parsing and manipulating JSON data. JSON string can be parsed into corresponding dictionary or custom python object. It is a commom pratice parse JSON string to custom object. However, we have to define corresponding class in advance. It can be a bunch of codes, especially for complex\u00a0class.</p>\n<p>In this article, I am going to share my code snippets for mapping JSON to python object without predefined attribtute at my\u00a0project:</p>\n<p><a href=\"https://github.com/xuzhusheng/gltf-to-3d-tiles\">GitHub - xuzhusheng/gltf-to-3d-tiles: glTF to 3d Tiles Converter. Convert glTF model to Glb, b3dm or 3d tiles format.</a></p>\n<p>Let\u2019s get start we a briefing about JSON data structure we are going to deal with - glTF\u00a0file.</p>\n<h3>Briefing about The JSON Data Structure</h3>\n<p>The JSON data we are going to manipulate is <strong>glTF</strong> (Graphics Library Transmission Format), a <a href=\"https://en.wikipedia.org/wiki/List_of_file_formats#3D_graphics\">standard file format</a> for <a href=\"https://en.wikipedia.org/wiki/3D_modeling\">three-dimensional scenes and models</a>. Here is a minimal glTF\u00a0file:</p>\n<pre>{<br>  \"scene\": 0,<br>  \"scenes\" : [<br>    {<br>      \"nodes\" : [ 0 ]<br>    }<br>  ],<br><br>  \"nodes\" : [<br>    {<br>      \"mesh\" : 0<br>    }<br>  ],<br><br>  \"meshes\" : [<br>    {<br>      \"primitives\" : [ {<br>        \"attributes\" : {<br>          \"POSITION\" : 1<br>        },<br>        \"indices\" : 0<br>      } ]<br>    }<br>  ],<br><br>  \"buffers\" : [<br>    {<br>      \"uri\" : \"data:application/octet-stream;base64,AAABAAIAAAAAAAAAAAAAAAAAAAAAAIA/AAAAAAAAAAAAAAAAAACAPwAAAAA=\",<br>      \"byteLength\" : 44<br>    }<br>  ],<br>  \"bufferViews\" : [<br>    {<br>      \"buffer\" : 0,<br>      \"byteOffset\" : 0,<br>      \"byteLength\" : 6,<br>      \"target\" : 34963<br>    },<br>    {<br>      \"buffer\" : 0,<br>      \"byteOffset\" : 8,<br>      \"byteLength\" : 36,<br>      \"target\" : 34962<br>    }<br>  ],<br>  \"accessors\" : [<br>    {<br>      \"bufferView\" : 0,<br>      \"byteOffset\" : 0,<br>      \"componentType\" : 5123,<br>      \"count\" : 3,<br>      \"type\" : \"SCALAR\",<br>      \"max\" : [ 2 ],<br>      \"min\" : [ 0 ]<br>    },<br>    {<br>      \"bufferView\" : 1,<br>      \"byteOffset\" : 0,<br>      \"componentType\" : 5126,<br>      \"count\" : 3,<br>      \"type\" : \"VEC3\",<br>      \"max\" : [ 1.0, 1.0, 0.0 ],<br>      \"min\" : [ 0.0, 0.0, 0.0 ]<br>    }<br>  ],<br><br>  \"asset\" : {<br>    \"version\" : \"2.0\"<br>  }<br>}</pre>\n<p>Let\u2019s save this file as minimal.gltf. We are going to load and convert this file to a dynamic object in next\u00a0section.</p>\n<h3>Converting JSON to Python Dynamic\u00a0Object</h3>\n<p>JSON could converted to python object in two\u00a0steps:</p>\n<ol>\n<li>converts JSON data to a dictionary object by json.load()</li>\n<li>converts dictionary object to dynamic\u00a0object.</li>\n</ol>\n<p>The second step could be done with the function setattr(). Let\u2019s get into the\u00a0codes.</p>\n<pre>class GltfModel:<br><br>    def __init__(self) -&gt; None:<br>        ...<br><br>    @classmethod<br>    def from_kwargs(cls, **kwargs):<br><br>        obj = cls()<br><br>        for key, value in kwargs.items():<br>            if type(value) == dict:<br>                setattr(obj, key, cls.from_kwargs(**value))<br>            elif type(value) == list:<br>                setattr(obj, key, [cls.from_kwargs(**item) if type(item) == dict else item for item in value])<br>            elif value is not None:<br>                setattr(obj, key, value)<br><br>        return obj</pre>\n<p><strong>Codes walk\u00a0throuth:</strong></p>\n<ol>\n<li>Defines a class funcion from_kwargs() accepts keyword arguments to create and initialize dynamic object - @classmethod def from_kwargs(cls, **kwargs)</li>\n<li>Creates object from class cls - obj =\u00a0cls()</li>\n<li>Parses keyword arguments in a loop - for key, value in kwargs.items()</li>\n<li>Creates a nested object attribute by calling cls.from_kwargs() recursively for dict value - if type(value) == dict: setattr(obj, key, cls.from_kwargs(**value))</li>\n<li>Creates an array attribute with primary data type value or nested object for list value - elif type(value) == list: setattr(obj, key, [cls.from_kwargs(**item) if type(item) == dict else item for item in\u00a0value])</li>\n<li>Creates an attribute with primary data type for other not none value - elif value is not None: setattr(obj, key,\u00a0value)</li>\n</ol>\n<h3>Access and Manipulate Attributes</h3>\n<p>Afte converted the minial.gltf to a dynamic object, we can access and manipulate attributes with dot notation like model.scene. It is much nicer and cleaner than model[\"scene\"] or model.get(\"scene\"). However, there are some optional node in gltf data structure. Correspondingly, there are some optional attributes. If we access any optioanl attribute that does not exist with dot notation model.not_exist_attribute, we will get a AttributeError. To avoid this, we need to override the __getattr__() magic function of class GltfModel:</p>\n<pre>def __getattr__(self, name):<br>        return None</pre>\n<p>Than, if we access any none exist attribute with mode.not_exist_attribute, it return\u00a0None</p>\n<h3>Naming convention</h3>\n<p>The JSON in minimal.gltf using camal case naming convention violates python PEP 8 standard. I using the code snippets to convert camel case to snake\u00a0case:</p>\n<pre>import re<br><br>CAMEL_PATTERN = r'(?&lt;!^)(?=[A-Z])'<br>camel_to_snake = lambda name : re.sub(CAMEL_PATTERN, '_', name).lower()</pre>\n<p>For converting between snake case and camel case, please read my\u00a0article:</p>\n<p><a href=\"https://xuzhusheng.medium.com/converting-between-naming-convention-with-python-2d91032bd0dc\">Converting between Snake Case and Camel Case</a></p>\n<h3>Conclusion</h3>\n<p>The completed code snippets as\u00a0below:</p>\n<pre>import re<br><br>CAMEL_PATTERN = r'(?&lt;!^)(?=[A-Z])'<br>camel_to_snake = lambda name : re.sub(CAMEL_PATTERN, '_', name).lower()<br><br>class GltfModel:<br><br>    def __init__(self) -&gt; None:<br>        ...<br><br>    @classmethod<br>    def from_kwargs(cls, **kwargs):<br><br>        obj = cls()<br><br>        for key, value in kwargs.items():<br>            key = camel_to_snake(key)<br>            if type(value) == dict:<br>                setattr(obj, key, cls.from_kwargs(**value))<br>            elif type(value) == list:<br>                setattr(obj, key, [cls.from_kwargs(**item) if type(item) == dict else item for item in value])<br>            elif value is not None:<br>                setattr(obj, key, value)<br><br>        return obj<br><br>    def __getattr__(self, name):<br>        return None<br><br>with open(\"minimal.gltf\", encoding='utf-8') as f:<br>    data = json.load(f)<br><br>gltf = GltfModel.from_kwargs(**data)<br><br>print(gltf.scene) # 0<br>print(gltf.not_exist_attribute) # None</pre>\n<h3>Jason \ud83d\ude80</h3>\n<p><em>Thank you for reading until the end. Before you\u00a0go:</em></p>\n<p>\ud83d\udc4f Please <strong><em>Clap</em></strong> and <strong><em>follow</em></strong>\u00a0me</p>\n<p>\ud83d\udcec <a href=\"https://medium.com/@xuzhusheng/subscribe\">Subscribe</a> to my Medium newsletter for email\u00a0updates!</p>\n<p>\u2615 or just <a href=\"https://www.buymeacoffee.com/jason.xu\">buy me a\u00a0coffee</a></p>\n<h3>In Plain English\u00a0\ud83d\ude80</h3>\n<p><em>Thank you for being a part of the </em><a href=\"https://plainenglish.io/\"><strong><em>In Plain English</em></strong></a><em> community! Before you\u00a0go:</em></p>\n<ul>\n<li>Be sure to <strong>clap</strong> and <strong>follow</strong> the writer\u00a0\ufe0f\ud83d\udc4f<strong>\ufe0f\ufe0f</strong>\n</li>\n<li>Follow us: <a href=\"https://twitter.com/inPlainEngHQ\"><strong>X</strong></a><strong> | </strong><a href=\"https://www.linkedin.com/company/inplainenglish/\"><strong>LinkedIn</strong></a><strong> | </strong><a href=\"https://www.youtube.com/channel/UCtipWUghju290NWcn8jhyAw\"><strong>YouTube</strong></a><strong> | </strong><a href=\"https://discord.gg/in-plain-english-709094664682340443\"><strong>Discord</strong></a><strong> | </strong><a href=\"https://newsletter.plainenglish.io/\"><strong>Newsletter</strong></a>\n</li>\n<li>Visit our other platforms: <a href=\"https://stackademic.com/\"><strong>Stackademic</strong></a><strong> | </strong><a href=\"https://cofeed.app/\"><strong>CoFeed</strong></a><strong> | </strong><a href=\"https://venturemagazine.net/\"><strong>Venture</strong></a><strong> |\u00a0</strong><a href=\"https://blog.cubed.run/\"><strong>Cubed</strong></a>\n</li>\n<li>More content at <a href=\"https://plainenglish.io/\"><strong>PlainEnglish.io</strong></a>\n</li>\n</ul>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=fe885394d17f\" width=\"1\" height=\"1\" alt=\"\"><hr>\n<p><a href=\"https://python.plainenglish.io/manipulate-json-with-python-dynamic-object-fe885394d17f\">Manipulate JSON with Python Dynamic Object</a> was originally published in <a href=\"https://python.plainenglish.io/\">Python in Plain English</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n",
            "content": "\n<h4>Code Snippets</h4>\n<h4>Avoid code duplication with python dynamic\u00a0object</h4>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*tmSiQ9rxkxOG1cJX\"><figcaption>Photo by <a href=\"https://unsplash.com/@hiteshchoudhary?utm_source=medium&amp;utm_medium=referral\">Hitesh Choudhary</a> on\u00a0<a href=\"https://unsplash.com/?utm_source=medium&amp;utm_medium=referral\">Unsplash</a></figcaption></figure><p>JSON (JavaScript Object Notation) is a lightweight, text-based data format used for storing and exchanging data. It\u2019s a simple and flexible way of representing data that can be easily understood and parsed by both humans and machines. JSON has become one of the most popular in standard.</p>\n<p>Python provides variou tools for parsing and manipulating JSON data. JSON string can be parsed into corresponding dictionary or custom python object. It is a commom pratice parse JSON string to custom object. However, we have to define corresponding class in advance. It can be a bunch of codes, especially for complex\u00a0class.</p>\n<p>In this article, I am going to share my code snippets for mapping JSON to python object without predefined attribtute at my\u00a0project:</p>\n<p><a href=\"https://github.com/xuzhusheng/gltf-to-3d-tiles\">GitHub - xuzhusheng/gltf-to-3d-tiles: glTF to 3d Tiles Converter. Convert glTF model to Glb, b3dm or 3d tiles format.</a></p>\n<p>Let\u2019s get start we a briefing about JSON data structure we are going to deal with - glTF\u00a0file.</p>\n<h3>Briefing about The JSON Data Structure</h3>\n<p>The JSON data we are going to manipulate is <strong>glTF</strong> (Graphics Library Transmission Format), a <a href=\"https://en.wikipedia.org/wiki/List_of_file_formats#3D_graphics\">standard file format</a> for <a href=\"https://en.wikipedia.org/wiki/3D_modeling\">three-dimensional scenes and models</a>. Here is a minimal glTF\u00a0file:</p>\n<pre>{<br>  \"scene\": 0,<br>  \"scenes\" : [<br>    {<br>      \"nodes\" : [ 0 ]<br>    }<br>  ],<br><br>  \"nodes\" : [<br>    {<br>      \"mesh\" : 0<br>    }<br>  ],<br><br>  \"meshes\" : [<br>    {<br>      \"primitives\" : [ {<br>        \"attributes\" : {<br>          \"POSITION\" : 1<br>        },<br>        \"indices\" : 0<br>      } ]<br>    }<br>  ],<br><br>  \"buffers\" : [<br>    {<br>      \"uri\" : \"data:application/octet-stream;base64,AAABAAIAAAAAAAAAAAAAAAAAAAAAAIA/AAAAAAAAAAAAAAAAAACAPwAAAAA=\",<br>      \"byteLength\" : 44<br>    }<br>  ],<br>  \"bufferViews\" : [<br>    {<br>      \"buffer\" : 0,<br>      \"byteOffset\" : 0,<br>      \"byteLength\" : 6,<br>      \"target\" : 34963<br>    },<br>    {<br>      \"buffer\" : 0,<br>      \"byteOffset\" : 8,<br>      \"byteLength\" : 36,<br>      \"target\" : 34962<br>    }<br>  ],<br>  \"accessors\" : [<br>    {<br>      \"bufferView\" : 0,<br>      \"byteOffset\" : 0,<br>      \"componentType\" : 5123,<br>      \"count\" : 3,<br>      \"type\" : \"SCALAR\",<br>      \"max\" : [ 2 ],<br>      \"min\" : [ 0 ]<br>    },<br>    {<br>      \"bufferView\" : 1,<br>      \"byteOffset\" : 0,<br>      \"componentType\" : 5126,<br>      \"count\" : 3,<br>      \"type\" : \"VEC3\",<br>      \"max\" : [ 1.0, 1.0, 0.0 ],<br>      \"min\" : [ 0.0, 0.0, 0.0 ]<br>    }<br>  ],<br><br>  \"asset\" : {<br>    \"version\" : \"2.0\"<br>  }<br>}</pre>\n<p>Let\u2019s save this file as minimal.gltf. We are going to load and convert this file to a dynamic object in next\u00a0section.</p>\n<h3>Converting JSON to Python Dynamic\u00a0Object</h3>\n<p>JSON could converted to python object in two\u00a0steps:</p>\n<ol>\n<li>converts JSON data to a dictionary object by json.load()</li>\n<li>converts dictionary object to dynamic\u00a0object.</li>\n</ol>\n<p>The second step could be done with the function setattr(). Let\u2019s get into the\u00a0codes.</p>\n<pre>class GltfModel:<br><br>    def __init__(self) -&gt; None:<br>        ...<br><br>    @classmethod<br>    def from_kwargs(cls, **kwargs):<br><br>        obj = cls()<br><br>        for key, value in kwargs.items():<br>            if type(value) == dict:<br>                setattr(obj, key, cls.from_kwargs(**value))<br>            elif type(value) == list:<br>                setattr(obj, key, [cls.from_kwargs(**item) if type(item) == dict else item for item in value])<br>            elif value is not None:<br>                setattr(obj, key, value)<br><br>        return obj</pre>\n<p><strong>Codes walk\u00a0throuth:</strong></p>\n<ol>\n<li>Defines a class funcion from_kwargs() accepts keyword arguments to create and initialize dynamic object - @classmethod def from_kwargs(cls, **kwargs)</li>\n<li>Creates object from class cls - obj =\u00a0cls()</li>\n<li>Parses keyword arguments in a loop - for key, value in kwargs.items()</li>\n<li>Creates a nested object attribute by calling cls.from_kwargs() recursively for dict value - if type(value) == dict: setattr(obj, key, cls.from_kwargs(**value))</li>\n<li>Creates an array attribute with primary data type value or nested object for list value - elif type(value) == list: setattr(obj, key, [cls.from_kwargs(**item) if type(item) == dict else item for item in\u00a0value])</li>\n<li>Creates an attribute with primary data type for other not none value - elif value is not None: setattr(obj, key,\u00a0value)</li>\n</ol>\n<h3>Access and Manipulate Attributes</h3>\n<p>Afte converted the minial.gltf to a dynamic object, we can access and manipulate attributes with dot notation like model.scene. It is much nicer and cleaner than model[\"scene\"] or model.get(\"scene\"). However, there are some optional node in gltf data structure. Correspondingly, there are some optional attributes. If we access any optioanl attribute that does not exist with dot notation model.not_exist_attribute, we will get a AttributeError. To avoid this, we need to override the __getattr__() magic function of class GltfModel:</p>\n<pre>def __getattr__(self, name):<br>        return None</pre>\n<p>Than, if we access any none exist attribute with mode.not_exist_attribute, it return\u00a0None</p>\n<h3>Naming convention</h3>\n<p>The JSON in minimal.gltf using camal case naming convention violates python PEP 8 standard. I using the code snippets to convert camel case to snake\u00a0case:</p>\n<pre>import re<br><br>CAMEL_PATTERN = r'(?&lt;!^)(?=[A-Z])'<br>camel_to_snake = lambda name : re.sub(CAMEL_PATTERN, '_', name).lower()</pre>\n<p>For converting between snake case and camel case, please read my\u00a0article:</p>\n<p><a href=\"https://xuzhusheng.medium.com/converting-between-naming-convention-with-python-2d91032bd0dc\">Converting between Snake Case and Camel Case</a></p>\n<h3>Conclusion</h3>\n<p>The completed code snippets as\u00a0below:</p>\n<pre>import re<br><br>CAMEL_PATTERN = r'(?&lt;!^)(?=[A-Z])'<br>camel_to_snake = lambda name : re.sub(CAMEL_PATTERN, '_', name).lower()<br><br>class GltfModel:<br><br>    def __init__(self) -&gt; None:<br>        ...<br><br>    @classmethod<br>    def from_kwargs(cls, **kwargs):<br><br>        obj = cls()<br><br>        for key, value in kwargs.items():<br>            key = camel_to_snake(key)<br>            if type(value) == dict:<br>                setattr(obj, key, cls.from_kwargs(**value))<br>            elif type(value) == list:<br>                setattr(obj, key, [cls.from_kwargs(**item) if type(item) == dict else item for item in value])<br>            elif value is not None:<br>                setattr(obj, key, value)<br><br>        return obj<br><br>    def __getattr__(self, name):<br>        return None<br><br>with open(\"minimal.gltf\", encoding='utf-8') as f:<br>    data = json.load(f)<br><br>gltf = GltfModel.from_kwargs(**data)<br><br>print(gltf.scene) # 0<br>print(gltf.not_exist_attribute) # None</pre>\n<h3>Jason \ud83d\ude80</h3>\n<p><em>Thank you for reading until the end. Before you\u00a0go:</em></p>\n<p>\ud83d\udc4f Please <strong><em>Clap</em></strong> and <strong><em>follow</em></strong>\u00a0me</p>\n<p>\ud83d\udcec <a href=\"https://medium.com/@xuzhusheng/subscribe\">Subscribe</a> to my Medium newsletter for email\u00a0updates!</p>\n<p>\u2615 or just <a href=\"https://www.buymeacoffee.com/jason.xu\">buy me a\u00a0coffee</a></p>\n<h3>In Plain English\u00a0\ud83d\ude80</h3>\n<p><em>Thank you for being a part of the </em><a href=\"https://plainenglish.io/\"><strong><em>In Plain English</em></strong></a><em> community! Before you\u00a0go:</em></p>\n<ul>\n<li>Be sure to <strong>clap</strong> and <strong>follow</strong> the writer\u00a0\ufe0f\ud83d\udc4f<strong>\ufe0f\ufe0f</strong>\n</li>\n<li>Follow us: <a href=\"https://twitter.com/inPlainEngHQ\"><strong>X</strong></a><strong> | </strong><a href=\"https://www.linkedin.com/company/inplainenglish/\"><strong>LinkedIn</strong></a><strong> | </strong><a href=\"https://www.youtube.com/channel/UCtipWUghju290NWcn8jhyAw\"><strong>YouTube</strong></a><strong> | </strong><a href=\"https://discord.gg/in-plain-english-709094664682340443\"><strong>Discord</strong></a><strong> | </strong><a href=\"https://newsletter.plainenglish.io/\"><strong>Newsletter</strong></a>\n</li>\n<li>Visit our other platforms: <a href=\"https://stackademic.com/\"><strong>Stackademic</strong></a><strong> | </strong><a href=\"https://cofeed.app/\"><strong>CoFeed</strong></a><strong> | </strong><a href=\"https://venturemagazine.net/\"><strong>Venture</strong></a><strong> |\u00a0</strong><a href=\"https://blog.cubed.run/\"><strong>Cubed</strong></a>\n</li>\n<li>More content at <a href=\"https://plainenglish.io/\"><strong>PlainEnglish.io</strong></a>\n</li>\n</ul>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=fe885394d17f\" width=\"1\" height=\"1\" alt=\"\"><hr>\n<p><a href=\"https://python.plainenglish.io/manipulate-json-with-python-dynamic-object-fe885394d17f\">Manipulate JSON with Python Dynamic Object</a> was originally published in <a href=\"https://python.plainenglish.io/\">Python in Plain English</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n",
            "enclosure": {},
            "categories": ["json", "programming", "code", "python", "coding"]
        },
        {
            "title": "Converting between Snake Case and Camel Case",
            "pubDate": "2024-02-02 14:29:50",
            "link": "https://python.plainenglish.io/converting-between-naming-convention-with-python-2d91032bd0dc?source=rss-41bd992616fb------2",
            "guid": "https://medium.com/p/2d91032bd0dc",
            "author": "Jason",
            "thumbnail": "",
            "description": "\n<h4>code snippets</h4>\n<h4>Elegant Python code snippets for converting between snake case and camel\u00a0case</h4>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*Rz_NQ08qJUTzulHH\"><figcaption>Photo by <a href=\"https://unsplash.com/@cdr6934?utm_source=medium&amp;utm_medium=referral\">Chris Ried</a> on\u00a0<a href=\"https://unsplash.com/?utm_source=medium&amp;utm_medium=referral\">Unsplash</a></figcaption></figure><p>I shared my code snippets about manipulate JSON with python dynamic object in my\u00a0article:</p>\n<p><a href=\"https://xuzhusheng.medium.com/manipulate-json-with-python-dynamic-object-fe885394d17f\">Manipulate JSON with Python Dynamic Object</a></p>\n<p>But the JSON data using camel case, it\u2019s naming convention violates python PEP 8 standard. we need to convert the camel case to snake\u00a0case.</p>\n<p>In this articl, we are intruduces some elegant code snippets to converting between and camel case. Before we start, let\u2019s review the relative name conventions first.</p>\n<h3>Naming Conventions</h3>\n<p>Here listed the snake case, camel case and pascal case naming conventions:</p>\n<ul>\n<li>Snake Case - Separates the words with underscore, e.g. snake_case</li>\n<li>Camel Case - All words start with a capital letter except the first one, e.g. camelCase</li>\n<li>Pascal Case - All words start with a capital letter, e.g. PascalCase</li>\n</ul>\n<p>Pascal Case is also mentioned above, because pascal case acted as a median naing convention between snake case and camel case. We are converts snake case to pascal case, and then converts pascal case to camel case in coming sesction.</p>\n<p>The only different between camel case and the pascal case is whether the first letter is capital. Let\u2019s warm up with the easiest one, converting between pascal case and camel\u00a0case.</p>\n<h3>Converting between Pascal Case and Camel\u00a0Case</h3>\n<p>The only thing we need to do is convert the first letters to upper case or otherwise. The scripts as\u00a0below:</p>\n<pre>def pascal_to_camel(name):<br>    return name[0].lower() + name[1:]<br><br>print(pascal_to_camel(\"CamelCase\")) #camelCase<br><br>def camel_to_pascal(name):<br>    return name[0].upper() + name[1:]<br><br>print(camel_to_pascal(\"PascalCase\")) #PascalCase</pre>\n<h3>Snake Case to Pascal\u00a0Case</h3>\n<p>Converts from snake case to pascal case, we need to convert the first letter of each word to upper case and remove the underscore seperator. Here is the\u00a0script:</p>\n<pre>def snake_to_pascal(name):<br>    return ''.join(name.title().split('_'))<br><br>print(snake_to_pascal(\"pascal_case\")) # PascalCase</pre>\n<h3>Snake Case to Camel\u00a0Case</h3>\n<p>Combines snake_to_pascal and pascal_to_camel, we could converts the snake case to camel\u00a0case:</p>\n<pre>def snake_to_camel(name):<br>    return pascal_to_camel(camel_to_pascal(name))<br><br>print(snake_to_camel(\"camel_case\")) # camelCase</pre>\n<h3>Converting to Snake\u00a0Case</h3>\n<p>Converting camel case or pascal case to snake case is the same. It could be done by 2\u00a0steps:</p>\n<ol>\n<li>Inserts a underscore seperator before each upper case\u00a0letter.</li>\n<li>converts string to lower\u00a0case.</li>\n</ol>\n<p>It can be done by re.sub() function:</p>\n<pre>import re<br><br>CAMEL_PATTERN = r'(?&lt;!^)(?=[A-Z])'<br><br>def camel_to_snake(name):<br>    return re.sub(CAMEL_PATTERN, '_', name).lower()<br><br>print(camel_to_snake(\"cnakeCase\")) # snake_case</pre>\n<p>Since compile the regex can take times, we could do it beforehand to improve performance:</p>\n<pre>import re<br>CAMEL_PATTERN = re.compile(r'(?&lt;!^)(?=[A-Z])')<br>def camel_to_snake(name):<br>    return CAMEL_PATTERN.sub('_', name).lower()<br><br>print(camel_to_snake(\"SnakeCase\")) # snake_case<br>print(camel_to_snake(\"HTTPStatus\")) # h_t_t_p_status</pre>\n<p>It was suppose to convert HTTPStatus to http_status. To handle this case, we need a different approach.</p>\n<h4>Advanced Cases (Not Reversible)</h4>\n<p>These cases is <strong>not reversible</strong>, once we convert HTTPStatus to http_status, There is no way we can convert back to HTTPStatus. Also two steps to get it\u00a0done:</p>\n<ol>\n<li>Looks for every upper case letter that following lower case letter ( letter C in snakeCase ) or followed by lower case letter (letter S in HTTPStatus ), then insert a underscore seperator before\u00a0each.</li>\n<li>Converts string to lower\u00a0case.</li>\n</ol>\n<p>Here is the\u00a0script:</p>\n<pre>ADVANCED_CAMEL_PATTERN = re.compile(r'(?&lt;=[a-z])[A-Z]|(?&lt;!^)[A-Z](?=[a-z])')<br>def advanced_camel_to_snake(name):<br>    return re.sub(ADVANCED_CAMEL_PATTERN, r\"_\\g&lt;0&gt;\", name).lower()<br><br>print(advanced_camel_to_snake(\"snakeCase\")) # snake_case<br>print(advanced_camel_to_snake(\"SnakeCase\"))  # snake_case<br>print(advanced_camel_to_snake(\"HTTPStatus\")) # http_status<br>print(advanced_camel_to_snake(\"HTTPStatusXYZ\")) # http_status_xyz<br>print(advanced_camel_to_snake(\"getHTTPStatus\")) # get_http_status<br>print(advanced_camel_to_snake(\"GetHTTPStatus\")) # get_http_status</pre>\n<h3>Conclusion</h3>\n<p>We\u2019ve covered code snippets for converting between snake case, camel case and pascal case. I put all of the converting functions together as\u00a0below:</p>\n<a href=\"https://medium.com/media/c0ae932bbd2bffeb19a2c7a0a42b07d1/href\">https://medium.com/media/c0ae932bbd2bffeb19a2c7a0a42b07d1/href</a><h3>Jason \ud83d\ude80</h3>\n<p><em>Thank you for reading until the end. Before you\u00a0go:</em></p>\n<p>\ud83d\udc4f Please <strong><em>Clap</em></strong> and <strong><em>follow</em></strong>\u00a0me</p>\n<p>\ud83d\udcec <a href=\"https://medium.com/@xuzhusheng/subscribe\">Subscribe</a> to my Medium newsletter for email\u00a0updates!</p>\n<p>\u2615 or just <a href=\"https://www.buymeacoffee.com/jason.xu\">buy me a\u00a0coffee</a></p>\n<h3>In Plain English\u00a0\ud83d\ude80</h3>\n<p><em>Thank you for being a part of the </em><a href=\"https://plainenglish.io/\"><strong><em>In Plain English</em></strong></a><em> community! Before you\u00a0go:</em></p>\n<ul>\n<li>Be sure to <strong>clap</strong> and <strong>follow</strong> the writer\u00a0\ufe0f\ud83d\udc4f<strong>\ufe0f\ufe0f</strong>\n</li>\n<li>Follow us: <a href=\"https://twitter.com/inPlainEngHQ\"><strong>X</strong></a><strong> | </strong><a href=\"https://www.linkedin.com/company/inplainenglish/\"><strong>LinkedIn</strong></a><strong> | </strong><a href=\"https://www.youtube.com/channel/UCtipWUghju290NWcn8jhyAw\"><strong>YouTube</strong></a><strong> | </strong><a href=\"https://discord.gg/in-plain-english-709094664682340443\"><strong>Discord</strong></a><strong> | </strong><a href=\"https://newsletter.plainenglish.io/\"><strong>Newsletter</strong></a>\n</li>\n<li>Visit our other platforms: <a href=\"https://stackademic.com/\"><strong>Stackademic</strong></a><strong> | </strong><a href=\"https://cofeed.app/\"><strong>CoFeed</strong></a><strong> | </strong><a href=\"https://venturemagazine.net/\"><strong>Venture</strong></a><strong> |\u00a0</strong><a href=\"https://blog.cubed.run/\"><strong>Cubed</strong></a>\n</li>\n<li>More content at <a href=\"https://plainenglish.io/\"><strong>PlainEnglish.io</strong></a>\n</li>\n</ul>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=2d91032bd0dc\" width=\"1\" height=\"1\" alt=\"\"><hr>\n<p><a href=\"https://python.plainenglish.io/converting-between-naming-convention-with-python-2d91032bd0dc\">Converting between Snake Case and Camel Case</a> was originally published in <a href=\"https://python.plainenglish.io/\">Python in Plain English</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n",
            "content": "\n<h4>code snippets</h4>\n<h4>Elegant Python code snippets for converting between snake case and camel\u00a0case</h4>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*Rz_NQ08qJUTzulHH\"><figcaption>Photo by <a href=\"https://unsplash.com/@cdr6934?utm_source=medium&amp;utm_medium=referral\">Chris Ried</a> on\u00a0<a href=\"https://unsplash.com/?utm_source=medium&amp;utm_medium=referral\">Unsplash</a></figcaption></figure><p>I shared my code snippets about manipulate JSON with python dynamic object in my\u00a0article:</p>\n<p><a href=\"https://xuzhusheng.medium.com/manipulate-json-with-python-dynamic-object-fe885394d17f\">Manipulate JSON with Python Dynamic Object</a></p>\n<p>But the JSON data using camel case, it\u2019s naming convention violates python PEP 8 standard. we need to convert the camel case to snake\u00a0case.</p>\n<p>In this articl, we are intruduces some elegant code snippets to converting between and camel case. Before we start, let\u2019s review the relative name conventions first.</p>\n<h3>Naming Conventions</h3>\n<p>Here listed the snake case, camel case and pascal case naming conventions:</p>\n<ul>\n<li>Snake Case - Separates the words with underscore, e.g. snake_case</li>\n<li>Camel Case - All words start with a capital letter except the first one, e.g. camelCase</li>\n<li>Pascal Case - All words start with a capital letter, e.g. PascalCase</li>\n</ul>\n<p>Pascal Case is also mentioned above, because pascal case acted as a median naing convention between snake case and camel case. We are converts snake case to pascal case, and then converts pascal case to camel case in coming sesction.</p>\n<p>The only different between camel case and the pascal case is whether the first letter is capital. Let\u2019s warm up with the easiest one, converting between pascal case and camel\u00a0case.</p>\n<h3>Converting between Pascal Case and Camel\u00a0Case</h3>\n<p>The only thing we need to do is convert the first letters to upper case or otherwise. The scripts as\u00a0below:</p>\n<pre>def pascal_to_camel(name):<br>    return name[0].lower() + name[1:]<br><br>print(pascal_to_camel(\"CamelCase\")) #camelCase<br><br>def camel_to_pascal(name):<br>    return name[0].upper() + name[1:]<br><br>print(camel_to_pascal(\"PascalCase\")) #PascalCase</pre>\n<h3>Snake Case to Pascal\u00a0Case</h3>\n<p>Converts from snake case to pascal case, we need to convert the first letter of each word to upper case and remove the underscore seperator. Here is the\u00a0script:</p>\n<pre>def snake_to_pascal(name):<br>    return ''.join(name.title().split('_'))<br><br>print(snake_to_pascal(\"pascal_case\")) # PascalCase</pre>\n<h3>Snake Case to Camel\u00a0Case</h3>\n<p>Combines snake_to_pascal and pascal_to_camel, we could converts the snake case to camel\u00a0case:</p>\n<pre>def snake_to_camel(name):<br>    return pascal_to_camel(camel_to_pascal(name))<br><br>print(snake_to_camel(\"camel_case\")) # camelCase</pre>\n<h3>Converting to Snake\u00a0Case</h3>\n<p>Converting camel case or pascal case to snake case is the same. It could be done by 2\u00a0steps:</p>\n<ol>\n<li>Inserts a underscore seperator before each upper case\u00a0letter.</li>\n<li>converts string to lower\u00a0case.</li>\n</ol>\n<p>It can be done by re.sub() function:</p>\n<pre>import re<br><br>CAMEL_PATTERN = r'(?&lt;!^)(?=[A-Z])'<br><br>def camel_to_snake(name):<br>    return re.sub(CAMEL_PATTERN, '_', name).lower()<br><br>print(camel_to_snake(\"cnakeCase\")) # snake_case</pre>\n<p>Since compile the regex can take times, we could do it beforehand to improve performance:</p>\n<pre>import re<br>CAMEL_PATTERN = re.compile(r'(?&lt;!^)(?=[A-Z])')<br>def camel_to_snake(name):<br>    return CAMEL_PATTERN.sub('_', name).lower()<br><br>print(camel_to_snake(\"SnakeCase\")) # snake_case<br>print(camel_to_snake(\"HTTPStatus\")) # h_t_t_p_status</pre>\n<p>It was suppose to convert HTTPStatus to http_status. To handle this case, we need a different approach.</p>\n<h4>Advanced Cases (Not Reversible)</h4>\n<p>These cases is <strong>not reversible</strong>, once we convert HTTPStatus to http_status, There is no way we can convert back to HTTPStatus. Also two steps to get it\u00a0done:</p>\n<ol>\n<li>Looks for every upper case letter that following lower case letter ( letter C in snakeCase ) or followed by lower case letter (letter S in HTTPStatus ), then insert a underscore seperator before\u00a0each.</li>\n<li>Converts string to lower\u00a0case.</li>\n</ol>\n<p>Here is the\u00a0script:</p>\n<pre>ADVANCED_CAMEL_PATTERN = re.compile(r'(?&lt;=[a-z])[A-Z]|(?&lt;!^)[A-Z](?=[a-z])')<br>def advanced_camel_to_snake(name):<br>    return re.sub(ADVANCED_CAMEL_PATTERN, r\"_\\g&lt;0&gt;\", name).lower()<br><br>print(advanced_camel_to_snake(\"snakeCase\")) # snake_case<br>print(advanced_camel_to_snake(\"SnakeCase\"))  # snake_case<br>print(advanced_camel_to_snake(\"HTTPStatus\")) # http_status<br>print(advanced_camel_to_snake(\"HTTPStatusXYZ\")) # http_status_xyz<br>print(advanced_camel_to_snake(\"getHTTPStatus\")) # get_http_status<br>print(advanced_camel_to_snake(\"GetHTTPStatus\")) # get_http_status</pre>\n<h3>Conclusion</h3>\n<p>We\u2019ve covered code snippets for converting between snake case, camel case and pascal case. I put all of the converting functions together as\u00a0below:</p>\n<a href=\"https://medium.com/media/c0ae932bbd2bffeb19a2c7a0a42b07d1/href\">https://medium.com/media/c0ae932bbd2bffeb19a2c7a0a42b07d1/href</a><h3>Jason \ud83d\ude80</h3>\n<p><em>Thank you for reading until the end. Before you\u00a0go:</em></p>\n<p>\ud83d\udc4f Please <strong><em>Clap</em></strong> and <strong><em>follow</em></strong>\u00a0me</p>\n<p>\ud83d\udcec <a href=\"https://medium.com/@xuzhusheng/subscribe\">Subscribe</a> to my Medium newsletter for email\u00a0updates!</p>\n<p>\u2615 or just <a href=\"https://www.buymeacoffee.com/jason.xu\">buy me a\u00a0coffee</a></p>\n<h3>In Plain English\u00a0\ud83d\ude80</h3>\n<p><em>Thank you for being a part of the </em><a href=\"https://plainenglish.io/\"><strong><em>In Plain English</em></strong></a><em> community! Before you\u00a0go:</em></p>\n<ul>\n<li>Be sure to <strong>clap</strong> and <strong>follow</strong> the writer\u00a0\ufe0f\ud83d\udc4f<strong>\ufe0f\ufe0f</strong>\n</li>\n<li>Follow us: <a href=\"https://twitter.com/inPlainEngHQ\"><strong>X</strong></a><strong> | </strong><a href=\"https://www.linkedin.com/company/inplainenglish/\"><strong>LinkedIn</strong></a><strong> | </strong><a href=\"https://www.youtube.com/channel/UCtipWUghju290NWcn8jhyAw\"><strong>YouTube</strong></a><strong> | </strong><a href=\"https://discord.gg/in-plain-english-709094664682340443\"><strong>Discord</strong></a><strong> | </strong><a href=\"https://newsletter.plainenglish.io/\"><strong>Newsletter</strong></a>\n</li>\n<li>Visit our other platforms: <a href=\"https://stackademic.com/\"><strong>Stackademic</strong></a><strong> | </strong><a href=\"https://cofeed.app/\"><strong>CoFeed</strong></a><strong> | </strong><a href=\"https://venturemagazine.net/\"><strong>Venture</strong></a><strong> |\u00a0</strong><a href=\"https://blog.cubed.run/\"><strong>Cubed</strong></a>\n</li>\n<li>More content at <a href=\"https://plainenglish.io/\"><strong>PlainEnglish.io</strong></a>\n</li>\n</ul>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=2d91032bd0dc\" width=\"1\" height=\"1\" alt=\"\"><hr>\n<p><a href=\"https://python.plainenglish.io/converting-between-naming-convention-with-python-2d91032bd0dc\">Converting between Snake Case and Camel Case</a> was originally published in <a href=\"https://python.plainenglish.io/\">Python in Plain English</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n",
            "enclosure": {},
            "categories": [
                "code",
                "python",
                "programming",
                "coding",
                "python-programming"
            ]
        },
        {
            "title": "Loads millions of Rows into MySQL in Seconds",
            "pubDate": "2024-01-28 11:32:39",
            "link": "https://python.plainenglish.io/how-to-load-millions-of-rows-csv-data-into-mysql-in-seconds-05805e5c1e39?source=rss-41bd992616fb------2",
            "guid": "https://medium.com/p/05805e5c1e39",
            "author": "Jason",
            "thumbnail": "",
            "description": "\n<h4>Data Manipulation</h4>\n<h4>Two efficient methods to load millions of rows CSV data into MySQL in several\u00a0seconds</h4>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*8OY5u8tQOpR10Jep\"><figcaption>Photo by <a href=\"https://unsplash.com/@sortino?utm_source=medium&amp;utm_medium=referral\">Joshua Sortino</a> on\u00a0<a href=\"https://unsplash.com/?utm_source=medium&amp;utm_medium=referral\">Unsplash</a></figcaption></figure><p>When we are doing data migrations or data cleaning, we might need to load millions of rows CSV data in to database. MySQL is one of the most popular database management system in the\u00a0world.</p>\n<p>In this article, we will cover two efficient methods to load CSV data to\u00a0MySQL.</p>\n<h3>Requirement</h3>\n<h4>Preparing Data</h4>\n<p>Suppose we need to load a person.csv file with millions of rows records to MySQL database table. Here is a sample\u00a0file:</p>\n<a href=\"https://medium.com/media/d36a65ec9a2e13c8c8db5cce4457ebb9/href\">https://medium.com/media/d36a65ec9a2e13c8c8db5cce4457ebb9/href</a><p>In real practic, our data might exported from another database system or scraped from web. For scraping data from web pages, please\u00a0read:</p>\n<p><a href=\"https://xuzhusheng.medium.com/playwright-web-scrapping-in-python-2024-def04f46a129\">Scrapes Interactive Pages with Playwright in Python</a></p>\n<p>In this article, we generages csv file with Faker. The generation scripts as\u00a0below:</p>\n<pre>from aiofile import async_open<br>from faker import Faker<br><br>Faker.seed(2024)    <br>faker = Faker()<br>async with async_open(\"person.csv\", \"w\", encoding=\"UTF-8\") as af:<br>    await af.write(\"name, age, birthday, phone_number, email\\n\")<br>    for _ in range(1000000):<br>        name = faker.name()<br>        age = faker.pyint(1, 115)<br>        birthday = faker.date_of_birth(minimum_age=1, maximum_age=115)<br>        phone_number = faker.phone_number()<br>        email = faker.ascii_free_email()<br>        line = f'{name}, {age}, {birthday}, {phone_number}, {email}\\n'<br>        await af.write(line)</pre>\n<h4>Creating Table</h4>\n<p>We need a table with corresponding columns and a id as primary key as\u00a0below:</p>\n<a href=\"https://medium.com/media/050a105f26c1afa71a3f11fcbadd20a3/href\">https://medium.com/media/050a105f26c1afa71a3f11fcbadd20a3/href</a><p>Here is the SQL\u00a0scripts:</p>\n<pre>CREATE TABLE person (<br>    `id` INT auto_increment primary key,<br>    `name` VARCHAR(255) NOT NULL,<br>    `age` TINYINT,<br>    `birthday` DATE NOT NULL,<br>    `phone_number` VARCHAR(30),<br>    `email` VARCHAR(255)<br>);</pre>\n<h3>Loading Data into\u00a0MySQL</h3>\n<p>Using the LOAD DATA statement is one of the most efficient methods to load data into MySQL. Let\u2019s cover this method\u00a0first.</p>\n<h4>Using LOAD DATA statement</h4>\n<p>Here is the LOAD DATA\u00a0scripts:</p>\n<pre>LOAD DATA LOCAL<br>    INFILE 'person.csv'<br>    INTO TABLE `person`<br>    FIELDS TERMINATED by ','<br>    LINES TERMINATED by '\\n'<br>    IGNORE 1 LINES<br>    (name, age, birthday, phone_number, email);</pre>\n<p><strong>Codes walk\u00a0through:</strong></p>\n<ul>\n<li>LOCAL specifies load data from client machine - LOAD DATA\u00a0LOCAL</li>\n<li>CSV file path - INFILE 'person.csv'</li>\n<li>Destination table - INTO TABLE\u00a0person</li>\n<li>CSV Delimiter - FIELDS TERMINATED by\u00a0','</li>\n<li>Line breaker - LINES TERMINATED by\u00a0'\\n'</li>\n<li>Ignore header - IGNORE 1\u00a0LINES</li>\n<li>Column mapping - (name, age, birthday, phone_number, email)</li>\n</ul>\n<p>The local data loading is disabled by default. We can enable it by set the global variable local_infile =\u00a0'ON'</p>\n<pre>set global local_infile = 'ON'</pre>\n<p>Run the script, all of the data in csv file will be loaded into mysql table. The loading take<strong> 6 - 7 seconds</strong> on my computer.</p>\n<p>Using LOAD DATA statement is alway my first option to load huge data into mysql. But what if we are not allowed to enable the local data loading setting? Is there other\u00a0options?</p>\n<h4>Using pandas</h4>\n<p>pandas is a fast and easy to use open source data analysis and manipulation python library. With pandas, it need just serval line of codes to get our task\u00a0done.</p>\n<p>Before getting start, we need to install libraries: spandas, sqlalchemy and mysqlclient. Pandas need sqlalchemy and mysqlclient to connect to MySQL database. The installation command as\u00a0below.</p>\n<pre>pip install pandas<br>pip install sqlalchemy<br>pip install mysqlclient</pre>\n<p>The load data scripts with pandas is very simple. Let\u2019s get into\u00a0it.</p>\n<pre>import pandas as pd<br>from sqlalchemy import create_engine<br><br>df = pd.read_csv(\"person.csv\", skipinitialspace=True)<br>engine = create_engine('mysql://root@127.0.0.1/db')<br>df.to_sql(name='person', con=engine, if_exists='append', index=False)</pre>\n<p><strong>Codes walk\u00a0through:</strong></p>\n<ul>\n<li>Import the necessary libraries - the first two\u00a0lines</li>\n<li>Read csv file by pd.read_csv(file) - df = pd.read_csv(\u201cperson.csv\u201d, skipinitialspace=True)</li>\n<li>Create engine for database connection by create_engine(url) - engine = create_engine(\u2018mysql://root@127.0.0.1/db\u2019)</li>\n<li>Load data into MySQL database - df.to_sql(name=\u2019person\u2019, con=engine, if_exists=\u2019append\u2019, index=False)</li>\n</ul>\n<p>This loading take <strong>22\u201324 seconds</strong> on my computer. It is slower, but it is simple and generic, easy to adapt to other source file format or database.</p>\n<p>We covered two methods for loading data with one million rows. What if there are much more data, hundres of millions rows\u00a0data?</p>\n<h3>Loading Hundreds of Millions Rows CSV\u00a0data</h3>\n<p>It is not feasible to load a file with hundres of millions row. In this case, we can split it into many files with one million rows, then load file with above methods. This can be done by the split\u00a0command.</p>\n<pre> split -d -l 1000000 person.csv person_ --additional-suffix .csv</pre>\n<h3>Conclusion</h3>\n<p>We\u2019ve covered two efficient methods to load huge csv data into mysql database.</p>\n<p>Using LOAD DATA statement is much more faster, but need permission to configurate database server, so that we can enable local data load. When we permission and the loading time is really crucial, using LOAD DATA statement is our\u00a0choice.</p>\n<p>When we are dealing with varied source file format or varied database, using pandas is more simple and adaptable.</p>\n<h3>Jason \ud83d\ude80</h3>\n<p><em>Thank you for reading until the end. Before you\u00a0go:</em></p>\n<p>\ud83d\udc4f Please <strong><em>Clap</em></strong> and <strong><em>follow</em></strong>\u00a0me</p>\n<p>\ud83d\udcec <a href=\"https://medium.com/@xuzhusheng/subscribe\">Subscribe</a> to my Medium newsletter for email\u00a0updates!</p>\n<p>\u2615 or just <a href=\"https://www.buymeacoffee.com/jason.xu\">buy me a\u00a0coffee</a></p>\n<h3>In Plain English\u00a0\ud83d\ude80</h3>\n<p><em>Thank you for being a part of the </em><a href=\"https://plainenglish.io/\"><strong><em>In Plain English</em></strong></a><em> community! Before you\u00a0go:</em></p>\n<ul>\n<li>Be sure to <strong>clap</strong> and <strong>follow</strong> the writer\u00a0\ufe0f\ud83d\udc4f<strong>\ufe0f\ufe0f</strong>\n</li>\n<li>Follow us: <a href=\"https://twitter.com/inPlainEngHQ\"><strong>X</strong></a><strong> | </strong><a href=\"https://www.linkedin.com/company/inplainenglish/\"><strong>LinkedIn</strong></a><strong> | </strong><a href=\"https://www.youtube.com/channel/UCtipWUghju290NWcn8jhyAw\"><strong>YouTube</strong></a><strong> | </strong><a href=\"https://discord.gg/in-plain-english-709094664682340443\"><strong>Discord</strong></a><strong> | </strong><a href=\"https://newsletter.plainenglish.io/\"><strong>Newsletter</strong></a>\n</li>\n<li>Visit our other platforms: <a href=\"https://stackademic.com/\"><strong>Stackademic</strong></a><strong> | </strong><a href=\"https://cofeed.app/\"><strong>CoFeed</strong></a><strong> | </strong><a href=\"https://venturemagazine.net/\"><strong>Venture</strong></a><strong> |\u00a0</strong><a href=\"https://blog.cubed.run/\"><strong>Cubed</strong></a>\n</li>\n<li>More content at <a href=\"https://plainenglish.io/\"><strong>PlainEnglish.io</strong></a>\n</li>\n</ul>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=05805e5c1e39\" width=\"1\" height=\"1\" alt=\"\"><hr>\n<p><a href=\"https://python.plainenglish.io/how-to-load-millions-of-rows-csv-data-into-mysql-in-seconds-05805e5c1e39\">Loads millions of Rows into MySQL in Seconds</a> was originally published in <a href=\"https://python.plainenglish.io/\">Python in Plain English</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n",
            "content": "\n<h4>Data Manipulation</h4>\n<h4>Two efficient methods to load millions of rows CSV data into MySQL in several\u00a0seconds</h4>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*8OY5u8tQOpR10Jep\"><figcaption>Photo by <a href=\"https://unsplash.com/@sortino?utm_source=medium&amp;utm_medium=referral\">Joshua Sortino</a> on\u00a0<a href=\"https://unsplash.com/?utm_source=medium&amp;utm_medium=referral\">Unsplash</a></figcaption></figure><p>When we are doing data migrations or data cleaning, we might need to load millions of rows CSV data in to database. MySQL is one of the most popular database management system in the\u00a0world.</p>\n<p>In this article, we will cover two efficient methods to load CSV data to\u00a0MySQL.</p>\n<h3>Requirement</h3>\n<h4>Preparing Data</h4>\n<p>Suppose we need to load a person.csv file with millions of rows records to MySQL database table. Here is a sample\u00a0file:</p>\n<a href=\"https://medium.com/media/d36a65ec9a2e13c8c8db5cce4457ebb9/href\">https://medium.com/media/d36a65ec9a2e13c8c8db5cce4457ebb9/href</a><p>In real practic, our data might exported from another database system or scraped from web. For scraping data from web pages, please\u00a0read:</p>\n<p><a href=\"https://xuzhusheng.medium.com/playwright-web-scrapping-in-python-2024-def04f46a129\">Scrapes Interactive Pages with Playwright in Python</a></p>\n<p>In this article, we generages csv file with Faker. The generation scripts as\u00a0below:</p>\n<pre>from aiofile import async_open<br>from faker import Faker<br><br>Faker.seed(2024)    <br>faker = Faker()<br>async with async_open(\"person.csv\", \"w\", encoding=\"UTF-8\") as af:<br>    await af.write(\"name, age, birthday, phone_number, email\\n\")<br>    for _ in range(1000000):<br>        name = faker.name()<br>        age = faker.pyint(1, 115)<br>        birthday = faker.date_of_birth(minimum_age=1, maximum_age=115)<br>        phone_number = faker.phone_number()<br>        email = faker.ascii_free_email()<br>        line = f'{name}, {age}, {birthday}, {phone_number}, {email}\\n'<br>        await af.write(line)</pre>\n<h4>Creating Table</h4>\n<p>We need a table with corresponding columns and a id as primary key as\u00a0below:</p>\n<a href=\"https://medium.com/media/050a105f26c1afa71a3f11fcbadd20a3/href\">https://medium.com/media/050a105f26c1afa71a3f11fcbadd20a3/href</a><p>Here is the SQL\u00a0scripts:</p>\n<pre>CREATE TABLE person (<br>    `id` INT auto_increment primary key,<br>    `name` VARCHAR(255) NOT NULL,<br>    `age` TINYINT,<br>    `birthday` DATE NOT NULL,<br>    `phone_number` VARCHAR(30),<br>    `email` VARCHAR(255)<br>);</pre>\n<h3>Loading Data into\u00a0MySQL</h3>\n<p>Using the LOAD DATA statement is one of the most efficient methods to load data into MySQL. Let\u2019s cover this method\u00a0first.</p>\n<h4>Using LOAD DATA statement</h4>\n<p>Here is the LOAD DATA\u00a0scripts:</p>\n<pre>LOAD DATA LOCAL<br>    INFILE 'person.csv'<br>    INTO TABLE `person`<br>    FIELDS TERMINATED by ','<br>    LINES TERMINATED by '\\n'<br>    IGNORE 1 LINES<br>    (name, age, birthday, phone_number, email);</pre>\n<p><strong>Codes walk\u00a0through:</strong></p>\n<ul>\n<li>LOCAL specifies load data from client machine - LOAD DATA\u00a0LOCAL</li>\n<li>CSV file path - INFILE 'person.csv'</li>\n<li>Destination table - INTO TABLE\u00a0person</li>\n<li>CSV Delimiter - FIELDS TERMINATED by\u00a0','</li>\n<li>Line breaker - LINES TERMINATED by\u00a0'\\n'</li>\n<li>Ignore header - IGNORE 1\u00a0LINES</li>\n<li>Column mapping - (name, age, birthday, phone_number, email)</li>\n</ul>\n<p>The local data loading is disabled by default. We can enable it by set the global variable local_infile =\u00a0'ON'</p>\n<pre>set global local_infile = 'ON'</pre>\n<p>Run the script, all of the data in csv file will be loaded into mysql table. The loading take<strong> 6 - 7 seconds</strong> on my computer.</p>\n<p>Using LOAD DATA statement is alway my first option to load huge data into mysql. But what if we are not allowed to enable the local data loading setting? Is there other\u00a0options?</p>\n<h4>Using pandas</h4>\n<p>pandas is a fast and easy to use open source data analysis and manipulation python library. With pandas, it need just serval line of codes to get our task\u00a0done.</p>\n<p>Before getting start, we need to install libraries: spandas, sqlalchemy and mysqlclient. Pandas need sqlalchemy and mysqlclient to connect to MySQL database. The installation command as\u00a0below.</p>\n<pre>pip install pandas<br>pip install sqlalchemy<br>pip install mysqlclient</pre>\n<p>The load data scripts with pandas is very simple. Let\u2019s get into\u00a0it.</p>\n<pre>import pandas as pd<br>from sqlalchemy import create_engine<br><br>df = pd.read_csv(\"person.csv\", skipinitialspace=True)<br>engine = create_engine('mysql://root@127.0.0.1/db')<br>df.to_sql(name='person', con=engine, if_exists='append', index=False)</pre>\n<p><strong>Codes walk\u00a0through:</strong></p>\n<ul>\n<li>Import the necessary libraries - the first two\u00a0lines</li>\n<li>Read csv file by pd.read_csv(file) - df = pd.read_csv(\u201cperson.csv\u201d, skipinitialspace=True)</li>\n<li>Create engine for database connection by create_engine(url) - engine = create_engine(\u2018mysql://root@127.0.0.1/db\u2019)</li>\n<li>Load data into MySQL database - df.to_sql(name=\u2019person\u2019, con=engine, if_exists=\u2019append\u2019, index=False)</li>\n</ul>\n<p>This loading take <strong>22\u201324 seconds</strong> on my computer. It is slower, but it is simple and generic, easy to adapt to other source file format or database.</p>\n<p>We covered two methods for loading data with one million rows. What if there are much more data, hundres of millions rows\u00a0data?</p>\n<h3>Loading Hundreds of Millions Rows CSV\u00a0data</h3>\n<p>It is not feasible to load a file with hundres of millions row. In this case, we can split it into many files with one million rows, then load file with above methods. This can be done by the split\u00a0command.</p>\n<pre> split -d -l 1000000 person.csv person_ --additional-suffix .csv</pre>\n<h3>Conclusion</h3>\n<p>We\u2019ve covered two efficient methods to load huge csv data into mysql database.</p>\n<p>Using LOAD DATA statement is much more faster, but need permission to configurate database server, so that we can enable local data load. When we permission and the loading time is really crucial, using LOAD DATA statement is our\u00a0choice.</p>\n<p>When we are dealing with varied source file format or varied database, using pandas is more simple and adaptable.</p>\n<h3>Jason \ud83d\ude80</h3>\n<p><em>Thank you for reading until the end. Before you\u00a0go:</em></p>\n<p>\ud83d\udc4f Please <strong><em>Clap</em></strong> and <strong><em>follow</em></strong>\u00a0me</p>\n<p>\ud83d\udcec <a href=\"https://medium.com/@xuzhusheng/subscribe\">Subscribe</a> to my Medium newsletter for email\u00a0updates!</p>\n<p>\u2615 or just <a href=\"https://www.buymeacoffee.com/jason.xu\">buy me a\u00a0coffee</a></p>\n<h3>In Plain English\u00a0\ud83d\ude80</h3>\n<p><em>Thank you for being a part of the </em><a href=\"https://plainenglish.io/\"><strong><em>In Plain English</em></strong></a><em> community! Before you\u00a0go:</em></p>\n<ul>\n<li>Be sure to <strong>clap</strong> and <strong>follow</strong> the writer\u00a0\ufe0f\ud83d\udc4f<strong>\ufe0f\ufe0f</strong>\n</li>\n<li>Follow us: <a href=\"https://twitter.com/inPlainEngHQ\"><strong>X</strong></a><strong> | </strong><a href=\"https://www.linkedin.com/company/inplainenglish/\"><strong>LinkedIn</strong></a><strong> | </strong><a href=\"https://www.youtube.com/channel/UCtipWUghju290NWcn8jhyAw\"><strong>YouTube</strong></a><strong> | </strong><a href=\"https://discord.gg/in-plain-english-709094664682340443\"><strong>Discord</strong></a><strong> | </strong><a href=\"https://newsletter.plainenglish.io/\"><strong>Newsletter</strong></a>\n</li>\n<li>Visit our other platforms: <a href=\"https://stackademic.com/\"><strong>Stackademic</strong></a><strong> | </strong><a href=\"https://cofeed.app/\"><strong>CoFeed</strong></a><strong> | </strong><a href=\"https://venturemagazine.net/\"><strong>Venture</strong></a><strong> |\u00a0</strong><a href=\"https://blog.cubed.run/\"><strong>Cubed</strong></a>\n</li>\n<li>More content at <a href=\"https://plainenglish.io/\"><strong>PlainEnglish.io</strong></a>\n</li>\n</ul>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=05805e5c1e39\" width=\"1\" height=\"1\" alt=\"\"><hr>\n<p><a href=\"https://python.plainenglish.io/how-to-load-millions-of-rows-csv-data-into-mysql-in-seconds-05805e5c1e39\">Loads millions of Rows into MySQL in Seconds</a> was originally published in <a href=\"https://python.plainenglish.io/\">Python in Plain English</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n",
            "enclosure": {},
            "categories": ["pandas", "mysql", "python", "data-science", "sql"]
        },
        {
            "title": "Scraping Interactive Pages with Playwright in Python",
            "pubDate": "2024-01-22 10:29:51",
            "link": "https://python.plainenglish.io/playwright-web-scrapping-in-python-2024-def04f46a129?source=rss-41bd992616fb------2",
            "guid": "https://medium.com/p/def04f46a129",
            "author": "Jason",
            "thumbnail": "",
            "description": "\n<h4>Web Scraping</h4>\n<h4>Explore how to scrape dynamic interactive pages with scrolling and infinite pagination with a practical example.</h4>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*KI3ciuhZYqQ-NwU7\"><figcaption>Photo by <a href=\"https://unsplash.com/@lucabravo?utm_source=medium&amp;utm_medium=referral\">Luca Bravo</a> on\u00a0<a href=\"https://unsplash.com/?utm_source=medium&amp;utm_medium=referral\">Unsplash</a></figcaption></figure><p>In this article, we are going to explore how to scrape dynamic page with scrolling and infinite pagination. We scrape pages with Playwright in\u00a0Python.</p>\n<p>We are going to build a scraper to scrape the historical Snapshot of 21 January 2024 from <a href=\"https://coinmarketcap.com/historical/20240121/\">CoinMarketCap</a>. At the end of this article, we will get a CSV file as\u00a0below.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Smq1wbAWf4QJu-yGHoq7Pg.png\"><figcaption>CSV File\u00a0Snapshot</figcaption></figure><h3>What is Playwright</h3>\n<p>Playwright is an open-source cross-platform library built on Node.js. But it is compatible with most popular programming languages, such as Node.js, Python, Java, and\u00a0.NET. You can use playwright with any of these languages you\u00a0like.</p>\n<p>Playwright was created for end-to-end testing, it is perfectly capable of browser automation and web scraping. Playwright web scraping has become one of the most popular searched topics recently.</p>\n<h3><strong>Installing Playwright</strong></h3>\n<p>Install playwright is very simple. All we need is install the playwright library by pipcommand and the install the necessary browsers byplaywright install command:\u00a0pip</p>\n<pre>pip install playwright<br>playwright install</pre>\n<h3>First Playwright script.</h3>\n<p>Playwright supports both synchronous api and asynchronous api. Let\u2019s using asynchronous api to create a basic script to open a dynamic page as\u00a0follows.</p>\n<a href=\"https://medium.com/media/504f6982c229c3f3a8471f4585e388d3/href\">https://medium.com/media/504f6982c229c3f3a8471f4585e388d3/href</a><p><strong>Codes walk\u00a0through:</strong></p>\n<ol>\n<li>Imports playwright asynchronous API. (line\u00a01)</li>\n<li>Launches a chromium browser and open a new page. (line 5\u200a\u2014\u200aline\u00a07).</li>\n<li>Navigates to the target page by page.goto() function. (line\u00a08)</li>\n<li>Captures the screenshot and saves into \u201cscreenshot.png\u201d. (line\u00a09)</li>\n<li>Close the browser at the end. \uff08line\u00a010\uff09</li>\n</ol>\n<p>Run the script, we will get a screenshot as\u00a0below:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*rtU6gpe0zu8AgcNC_htPqg.png\"><figcaption>Screenshot</figcaption></figure><p>Data in the table is what we are going to scrap in next\u00a0section.</p>\n<h3><strong>Locating elements and Extracting data</strong></h3>\n<p>The first step to extract data from any element is locate the element. Playwright use locators to locate elements on the\u00a0page.</p>\n<p>Locators are the central piece of Playwright\u2019s ability to locate elements and perform actions automated. Some built in locators of playwright sumarized below.</p>\n<p><strong>Built in locators of playwright summary</strong></p>\n<ul>\n<li>page.get_by_role() to locate by explicit and implicit accessibility attributes.</li>\n<li>page.get_by_text() to locate by text\u00a0content.</li>\n<li>page.get_by_label() to locate a form control by associated label\u2019s\u00a0text.</li>\n<li>page.get_by_placeholder() to locate an input by placeholder.</li>\n<li>page.get_by_alt_text()to locate an element, usually image, by its text alternative.</li>\n<li>page.get_by_title() to locate an element by its title attribute.</li>\n<li>page.get_by_test_id() to locate an element based on its data-testid attribute (other attributes can be configured).</li>\n</ul>\n<p>We are going to locate table header element by page.locator() and retireve the header text by locator.inner_text():</p>\n<pre>header = await page.locator(\"thead tr\").inner_text()<br>print(header)</pre>\n<p>If we run the script to check result, we will get an\u00a0error:</p>\n<pre>Error: strict mode violation: locator(\u201cthead tr\u201d) resolved to 3 elements</pre>\n<p>There are three table header elements in the page, we need only the visible one. We filter the rest by locator.locator(\"visible=true). The completed codes as\u00a0below:</p>\n<pre>header = await page.locator(\"thead tr\").locator(\"visible=true\").inner_text()<br>print(header)</pre>\n<p>Rerun the script, we could see the header text printed as\u00a0below:</p>\n<pre>Rank Name Symbol Market Cap Price Circulating Supply volume (24h) % 1h % 24h % 7d</pre>\n<p>Let\u2019s get into the whole scripts than locates table elements and retrieves corresponding text.</p>\n<a href=\"https://medium.com/media/eb42a068b6ca298a3292822233b745ff/href\">https://medium.com/media/eb42a068b6ca298a3292822233b745ff/href</a><p><strong>Codes walk\u00a0through:</strong></p>\n<ol>\n<li>Navigates to the target page. This is the same as first script above. (line 1 - line 10\u00a0)</li>\n<li>Locates the table header and extracts the header text by locator.inner_text() function. (line\u00a011)</li>\n<li>Locates all rows of the table body. (line\u00a013)</li>\n<li>Extracts row text and reformat it to print on the screen in a loop. (line\u00a014\u201318)</li>\n</ol>\n<p>It seems quite simple. Let\u2019s run this example and check the\u00a0result.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*AvYaK4Ie3ep-IcUJvN2mTQ.png\"></figure><p>We got only 20 rows. The rest data is missing. The page load rows visible on screen only. We need to scroll down, so that it could load the rest\u00a0data.</p>\n<h3><strong>Scrolling and Infinite Pagination</strong></h3>\n<p>Scrolling could be done easy by add row.scroll_into_view_if_needed() before inner_text = await row.inner_text().</p>\n<p>The trick part is pagination. At the bottom of the page, there is a \u201cLoad More\u201d\u00a0button.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Wx1OrTPpP2ywHJESunmLGg.png\"></figure><p>What we need to do is keep clicking the \u201cLoad More\u201d button while is clickable. The \u201cLoad More\u201d scripts as\u00a0below:</p>\n<pre>async def has_next_page():<br>    try:<br>        await page.get_by_role(\"button\", name=\"Load More\").click(trial = True)<br>        return True<br>    except:<br>        return False<br><br>async def load_next_page():<br>    current_page = 1<br>    while await has_next_page():<br>        try:<br>            yield current_page<br>            await page.get_by_role(\"button\", name=\"Load More\").click(force=True)<br>            current_page += 1<br>        except:<br>            ...<br>    yield current_page</pre>\n<p><strong>Codes walk\u00a0through</strong></p>\n<ol>\n<li>Function has_next_page() waits for the \u201cLoad More\u201d button to be clickable then return Ture. Or return False if any exception. By setting (trial = True), the click() fucntion perform only actionable checks and skips the click\u00a0action.</li>\n<li>While the \u201cLoad More\u201d button is clickable, each time function load_next_page() is called, it clicks the \u201cLoad More\u201d button to load next page\u00a0data.</li>\n</ol>\n<p>Let\u2019s do some refactoring, extracts locates elements and extracts data codes to a data() function. And put the pagnitions codes together.</p>\n<pre>async def data():  <br><br>    yield await page.locator(\"thead tr\").locator(\"visible=true\").inner_text()<br><br>    current_row = 0<br>    async for _ in load_next_page():<br>        rows = await page.locator(\"tbody tr\").all()<br>        rows = rows[current_row:]<br><br>        for row in rows:<br>            await row.wait_for(timeout=0)<br>            await row.scroll_into_view_if_needed(timeout=0)<br>            yield await row.inner_text()<br>            current_row += 1 </pre>\n<p>The current_row index indicates the next row to be parsed. After the \u201cLoad More\u201d button is clicked, it parses rows start from current_row to the\u00a0end.</p>\n<p>The final thing, we save the extracted data in a csv file instead of print it on screen and add a progress bar by tqdm. The completed codes as\u00a0below:</p>\n<a href=\"https://medium.com/media/c86b8cf1e7087305f5408b6b320c61a7/href\">https://medium.com/media/c86b8cf1e7087305f5408b6b320c61a7/href</a><h3>What\u2019s Next</h3>\n<p>In this article, we store scraped data into a CSV file. But in real scraping practic, we deal with thounds of millions of pages, instead of storing data in CSV files, we usually store data into database. One of the most popular database management system MySQL. For loading CSV data into MySQL efficiently, read my\u00a0article:</p>\n<p><a href=\"https://xuzhusheng.medium.com/how-to-load-millions-of-rows-csv-data-into-mysql-in-seconds-05805e5c1e39\">Loads millions of Records into MySQL in Seconds</a></p>\n<h3>Jason \ud83d\ude80</h3>\n<p><em>Thank you for reading until the end. Before you\u00a0go:</em></p>\n<p>\ud83d\udc4f Please <strong><em>Clap</em></strong> and <strong><em>follow</em></strong>\u00a0me</p>\n<p>\ud83d\udcec <a href=\"https://medium.com/@xuzhusheng/subscribe\">Subscribe</a> to my Medium newsletter for email\u00a0updates!</p>\n<p>\u2615 or just <a href=\"https://www.buymeacoffee.com/jason.xu\">buy me a\u00a0coffee</a></p>\n<h3>In Plain English\u00a0\ud83d\ude80</h3>\n<p><em>Thank you for being a part of the </em><a href=\"https://plainenglish.io/\"><strong><em>In Plain English</em></strong></a><em> community! Before you\u00a0go:</em></p>\n<ul>\n<li>Be sure to <strong>clap</strong> and <strong>follow</strong> the writer\u00a0\ufe0f\ud83d\udc4f<strong>\ufe0f\ufe0f</strong>\n</li>\n<li>Follow us: <a href=\"https://twitter.com/inPlainEngHQ\"><strong>X</strong></a><strong> | </strong><a href=\"https://www.linkedin.com/company/inplainenglish/\"><strong>LinkedIn</strong></a><strong> | </strong><a href=\"https://www.youtube.com/channel/UCtipWUghju290NWcn8jhyAw\"><strong>YouTube</strong></a><strong> | </strong><a href=\"https://discord.gg/in-plain-english-709094664682340443\"><strong>Discord</strong></a><strong> | </strong><a href=\"https://newsletter.plainenglish.io/\"><strong>Newsletter</strong></a>\n</li>\n<li>Visit our other platforms: <a href=\"https://stackademic.com/\"><strong>Stackademic</strong></a><strong> | </strong><a href=\"https://cofeed.app/\"><strong>CoFeed</strong></a><strong> | </strong><a href=\"https://venturemagazine.net/\"><strong>Venture</strong></a><strong> |\u00a0</strong><a href=\"https://blog.cubed.run/\"><strong>Cubed</strong></a>\n</li>\n<li>More content at <a href=\"https://plainenglish.io/\"><strong>PlainEnglish.io</strong></a>\n</li>\n</ul>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=def04f46a129\" width=\"1\" height=\"1\" alt=\"\"><hr>\n<p><a href=\"https://python.plainenglish.io/playwright-web-scrapping-in-python-2024-def04f46a129\">Scraping Interactive Pages with Playwright in Python</a> was originally published in <a href=\"https://python.plainenglish.io/\">Python in Plain English</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n",
            "content": "\n<h4>Web Scraping</h4>\n<h4>Explore how to scrape dynamic interactive pages with scrolling and infinite pagination with a practical example.</h4>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*KI3ciuhZYqQ-NwU7\"><figcaption>Photo by <a href=\"https://unsplash.com/@lucabravo?utm_source=medium&amp;utm_medium=referral\">Luca Bravo</a> on\u00a0<a href=\"https://unsplash.com/?utm_source=medium&amp;utm_medium=referral\">Unsplash</a></figcaption></figure><p>In this article, we are going to explore how to scrape dynamic page with scrolling and infinite pagination. We scrape pages with Playwright in\u00a0Python.</p>\n<p>We are going to build a scraper to scrape the historical Snapshot of 21 January 2024 from <a href=\"https://coinmarketcap.com/historical/20240121/\">CoinMarketCap</a>. At the end of this article, we will get a CSV file as\u00a0below.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Smq1wbAWf4QJu-yGHoq7Pg.png\"><figcaption>CSV File\u00a0Snapshot</figcaption></figure><h3>What is Playwright</h3>\n<p>Playwright is an open-source cross-platform library built on Node.js. But it is compatible with most popular programming languages, such as Node.js, Python, Java, and\u00a0.NET. You can use playwright with any of these languages you\u00a0like.</p>\n<p>Playwright was created for end-to-end testing, it is perfectly capable of browser automation and web scraping. Playwright web scraping has become one of the most popular searched topics recently.</p>\n<h3><strong>Installing Playwright</strong></h3>\n<p>Install playwright is very simple. All we need is install the playwright library by pipcommand and the install the necessary browsers byplaywright install command:\u00a0pip</p>\n<pre>pip install playwright<br>playwright install</pre>\n<h3>First Playwright script.</h3>\n<p>Playwright supports both synchronous api and asynchronous api. Let\u2019s using asynchronous api to create a basic script to open a dynamic page as\u00a0follows.</p>\n<a href=\"https://medium.com/media/504f6982c229c3f3a8471f4585e388d3/href\">https://medium.com/media/504f6982c229c3f3a8471f4585e388d3/href</a><p><strong>Codes walk\u00a0through:</strong></p>\n<ol>\n<li>Imports playwright asynchronous API. (line\u00a01)</li>\n<li>Launches a chromium browser and open a new page. (line 5\u200a\u2014\u200aline\u00a07).</li>\n<li>Navigates to the target page by page.goto() function. (line\u00a08)</li>\n<li>Captures the screenshot and saves into \u201cscreenshot.png\u201d. (line\u00a09)</li>\n<li>Close the browser at the end. \uff08line\u00a010\uff09</li>\n</ol>\n<p>Run the script, we will get a screenshot as\u00a0below:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*rtU6gpe0zu8AgcNC_htPqg.png\"><figcaption>Screenshot</figcaption></figure><p>Data in the table is what we are going to scrap in next\u00a0section.</p>\n<h3><strong>Locating elements and Extracting data</strong></h3>\n<p>The first step to extract data from any element is locate the element. Playwright use locators to locate elements on the\u00a0page.</p>\n<p>Locators are the central piece of Playwright\u2019s ability to locate elements and perform actions automated. Some built in locators of playwright sumarized below.</p>\n<p><strong>Built in locators of playwright summary</strong></p>\n<ul>\n<li>page.get_by_role() to locate by explicit and implicit accessibility attributes.</li>\n<li>page.get_by_text() to locate by text\u00a0content.</li>\n<li>page.get_by_label() to locate a form control by associated label\u2019s\u00a0text.</li>\n<li>page.get_by_placeholder() to locate an input by placeholder.</li>\n<li>page.get_by_alt_text()to locate an element, usually image, by its text alternative.</li>\n<li>page.get_by_title() to locate an element by its title attribute.</li>\n<li>page.get_by_test_id() to locate an element based on its data-testid attribute (other attributes can be configured).</li>\n</ul>\n<p>We are going to locate table header element by page.locator() and retireve the header text by locator.inner_text():</p>\n<pre>header = await page.locator(\"thead tr\").inner_text()<br>print(header)</pre>\n<p>If we run the script to check result, we will get an\u00a0error:</p>\n<pre>Error: strict mode violation: locator(\u201cthead tr\u201d) resolved to 3 elements</pre>\n<p>There are three table header elements in the page, we need only the visible one. We filter the rest by locator.locator(\"visible=true). The completed codes as\u00a0below:</p>\n<pre>header = await page.locator(\"thead tr\").locator(\"visible=true\").inner_text()<br>print(header)</pre>\n<p>Rerun the script, we could see the header text printed as\u00a0below:</p>\n<pre>Rank Name Symbol Market Cap Price Circulating Supply volume (24h) % 1h % 24h % 7d</pre>\n<p>Let\u2019s get into the whole scripts than locates table elements and retrieves corresponding text.</p>\n<a href=\"https://medium.com/media/eb42a068b6ca298a3292822233b745ff/href\">https://medium.com/media/eb42a068b6ca298a3292822233b745ff/href</a><p><strong>Codes walk\u00a0through:</strong></p>\n<ol>\n<li>Navigates to the target page. This is the same as first script above. (line 1 - line 10\u00a0)</li>\n<li>Locates the table header and extracts the header text by locator.inner_text() function. (line\u00a011)</li>\n<li>Locates all rows of the table body. (line\u00a013)</li>\n<li>Extracts row text and reformat it to print on the screen in a loop. (line\u00a014\u201318)</li>\n</ol>\n<p>It seems quite simple. Let\u2019s run this example and check the\u00a0result.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*AvYaK4Ie3ep-IcUJvN2mTQ.png\"></figure><p>We got only 20 rows. The rest data is missing. The page load rows visible on screen only. We need to scroll down, so that it could load the rest\u00a0data.</p>\n<h3><strong>Scrolling and Infinite Pagination</strong></h3>\n<p>Scrolling could be done easy by add row.scroll_into_view_if_needed() before inner_text = await row.inner_text().</p>\n<p>The trick part is pagination. At the bottom of the page, there is a \u201cLoad More\u201d\u00a0button.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Wx1OrTPpP2ywHJESunmLGg.png\"></figure><p>What we need to do is keep clicking the \u201cLoad More\u201d button while is clickable. The \u201cLoad More\u201d scripts as\u00a0below:</p>\n<pre>async def has_next_page():<br>    try:<br>        await page.get_by_role(\"button\", name=\"Load More\").click(trial = True)<br>        return True<br>    except:<br>        return False<br><br>async def load_next_page():<br>    current_page = 1<br>    while await has_next_page():<br>        try:<br>            yield current_page<br>            await page.get_by_role(\"button\", name=\"Load More\").click(force=True)<br>            current_page += 1<br>        except:<br>            ...<br>    yield current_page</pre>\n<p><strong>Codes walk\u00a0through</strong></p>\n<ol>\n<li>Function has_next_page() waits for the \u201cLoad More\u201d button to be clickable then return Ture. Or return False if any exception. By setting (trial = True), the click() fucntion perform only actionable checks and skips the click\u00a0action.</li>\n<li>While the \u201cLoad More\u201d button is clickable, each time function load_next_page() is called, it clicks the \u201cLoad More\u201d button to load next page\u00a0data.</li>\n</ol>\n<p>Let\u2019s do some refactoring, extracts locates elements and extracts data codes to a data() function. And put the pagnitions codes together.</p>\n<pre>async def data():  <br><br>    yield await page.locator(\"thead tr\").locator(\"visible=true\").inner_text()<br><br>    current_row = 0<br>    async for _ in load_next_page():<br>        rows = await page.locator(\"tbody tr\").all()<br>        rows = rows[current_row:]<br><br>        for row in rows:<br>            await row.wait_for(timeout=0)<br>            await row.scroll_into_view_if_needed(timeout=0)<br>            yield await row.inner_text()<br>            current_row += 1 </pre>\n<p>The current_row index indicates the next row to be parsed. After the \u201cLoad More\u201d button is clicked, it parses rows start from current_row to the\u00a0end.</p>\n<p>The final thing, we save the extracted data in a csv file instead of print it on screen and add a progress bar by tqdm. The completed codes as\u00a0below:</p>\n<a href=\"https://medium.com/media/c86b8cf1e7087305f5408b6b320c61a7/href\">https://medium.com/media/c86b8cf1e7087305f5408b6b320c61a7/href</a><h3>What\u2019s Next</h3>\n<p>In this article, we store scraped data into a CSV file. But in real scraping practic, we deal with thounds of millions of pages, instead of storing data in CSV files, we usually store data into database. One of the most popular database management system MySQL. For loading CSV data into MySQL efficiently, read my\u00a0article:</p>\n<p><a href=\"https://xuzhusheng.medium.com/how-to-load-millions-of-rows-csv-data-into-mysql-in-seconds-05805e5c1e39\">Loads millions of Records into MySQL in Seconds</a></p>\n<h3>Jason \ud83d\ude80</h3>\n<p><em>Thank you for reading until the end. Before you\u00a0go:</em></p>\n<p>\ud83d\udc4f Please <strong><em>Clap</em></strong> and <strong><em>follow</em></strong>\u00a0me</p>\n<p>\ud83d\udcec <a href=\"https://medium.com/@xuzhusheng/subscribe\">Subscribe</a> to my Medium newsletter for email\u00a0updates!</p>\n<p>\u2615 or just <a href=\"https://www.buymeacoffee.com/jason.xu\">buy me a\u00a0coffee</a></p>\n<h3>In Plain English\u00a0\ud83d\ude80</h3>\n<p><em>Thank you for being a part of the </em><a href=\"https://plainenglish.io/\"><strong><em>In Plain English</em></strong></a><em> community! Before you\u00a0go:</em></p>\n<ul>\n<li>Be sure to <strong>clap</strong> and <strong>follow</strong> the writer\u00a0\ufe0f\ud83d\udc4f<strong>\ufe0f\ufe0f</strong>\n</li>\n<li>Follow us: <a href=\"https://twitter.com/inPlainEngHQ\"><strong>X</strong></a><strong> | </strong><a href=\"https://www.linkedin.com/company/inplainenglish/\"><strong>LinkedIn</strong></a><strong> | </strong><a href=\"https://www.youtube.com/channel/UCtipWUghju290NWcn8jhyAw\"><strong>YouTube</strong></a><strong> | </strong><a href=\"https://discord.gg/in-plain-english-709094664682340443\"><strong>Discord</strong></a><strong> | </strong><a href=\"https://newsletter.plainenglish.io/\"><strong>Newsletter</strong></a>\n</li>\n<li>Visit our other platforms: <a href=\"https://stackademic.com/\"><strong>Stackademic</strong></a><strong> | </strong><a href=\"https://cofeed.app/\"><strong>CoFeed</strong></a><strong> | </strong><a href=\"https://venturemagazine.net/\"><strong>Venture</strong></a><strong> |\u00a0</strong><a href=\"https://blog.cubed.run/\"><strong>Cubed</strong></a>\n</li>\n<li>More content at <a href=\"https://plainenglish.io/\"><strong>PlainEnglish.io</strong></a>\n</li>\n</ul>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=def04f46a129\" width=\"1\" height=\"1\" alt=\"\"><hr>\n<p><a href=\"https://python.plainenglish.io/playwright-web-scrapping-in-python-2024-def04f46a129\">Scraping Interactive Pages with Playwright in Python</a> was originally published in <a href=\"https://python.plainenglish.io/\">Python in Plain English</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n",
            "enclosure": {},
            "categories": [
                "web-scraping",
                "python",
                "playwrights",
                "programming",
                "web-automation"
            ]
        }
    ]
}
